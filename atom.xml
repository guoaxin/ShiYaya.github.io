<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ShiYaya</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-09-09T01:14:40.538Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ShiYaya</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>video captioning 任务的难点？</title>
    <link href="http://yoursite.com/2019/09/07/video-captioning-%E4%BB%BB%E5%8A%A1%E7%9A%84%E9%9A%BE%E7%82%B9%EF%BC%9F/"/>
    <id>http://yoursite.com/2019/09/07/video-captioning-任务的难点？/</id>
    <published>2019-09-07T06:59:20.000Z</published>
    <updated>2019-09-09T01:14:40.538Z</updated>
    
    <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Just can be seen by yaya.
    
    </summary>
    
      <category term="视频描述" scheme="http://yoursite.com/categories/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0/"/>
    
    
      <category term="视频描述" scheme="http://yoursite.com/tags/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>视频描述任务中用到objects的论文总结</title>
    <link href="http://yoursite.com/2019/09/01/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%94%A8%E5%88%B0objects%E7%9A%84%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/09/01/视频描述任务中用到objects的论文总结/</id>
    <published>2019-09-01T13:44:12.000Z</published>
    <updated>2019-09-02T14:25:17.670Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>CVPR 2018</p><ol><li>Fine-grained Video Captioning for Sports Narrative</li></ol></li><li><p>CVPR 2019</p><ol><li>Grounded Video Description</li><li>Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning</li><li>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning 【再去读一遍】</li><li>Adversarial Inference for Multi-Sentence Video Description</li></ol></li><li><p>ACM 2019</p><ol><li>Hierarchical Global-Local Temporal Modeling for Video Captioning</li></ol></li></ul><h3 id="Grounded-Video-Description"><a href="#Grounded-Video-Description" class="headerlink" title="Grounded Video Description"></a>Grounded Video Description</h3><p><img src="https://i.loli.net/2019/09/02/Hvtk4BJVNQ2WwdM.png" alt="搜狗截图20190902104324.png"></p><ol><li><p>如何使用region feature？</p><p> 仅在language lstm 用到了 region featrue, attention 加权求和之后 与 cat[ fc, motion] features 对应元素相加（cat[fc, motion]也是在经过attention加权求和之后的）</p><p> 但我个人认为对应元素相加，并没有道理，相当于在 cat[ fc, motion] 的基础上增加了一个 bias，没有什么道理</p></li><li><p>region feature 的构成？</p><p>R：是 object detector  在 fc6 输出的 feature</p><p>Ms(R)：是 object detector 在 fc7 输出的feature (这里有一些细节的修改，具体见论文)</p><p>Ml： 是 position embedding</p></li></ol><p><img src="https://i.loli.net/2019/09/02/y4JkxlmLQpqaj5c.png" alt="搜狗截图20190902105022.png"></p><h3 id="Object-aware-Aggregation-with-Bidirectional-Temporal-Graph-for-Video-Captioning"><a href="#Object-aware-Aggregation-with-Bidirectional-Temporal-Graph-for-Video-Captioning" class="headerlink" title="Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning"></a>Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning</h3><p><img src="https://i.loli.net/2019/09/02/TIP7Ww3FnLNKzvu.png" alt="搜狗截图20190902144125.png"></p><ol><li><p>简要介绍本文的结构</p><p> 在encoder 部分，使用 object feature 和 frame feature，分别经过设计的VALD 得到更新的特征向量</p><p> 在 decoder 部分，对object feature 使用两层的attention, 先对 <strong>一个轨迹</strong>上的objects 进行attention 的加权求和，再对N different objects instances进行 attention 的加权求和，这样就可以得到对所有objects 的聚合表达</p><p> 轨迹：对于第一帧的ojects, 根据相似性分别去找其他帧与其对应的objects，而构成的时域轨迹。</p><p>  这里采用了前向轨迹，和后向轨迹两种，在decoder 输出预测的单词之后，进行融合。</p></li><li><p>如何使用region feature？<br> 仅有一个lstm ，在输入lstm前对objects features进行两层attention 加权求和后，与同样经过attention的frames feature进行加和（sum）。<br> 本文没有使用 motion feeture</p></li><li><p>region feature 的构成？<br> 非常简单，只有 appearance feature，但是经过了 obejct VLAD module！</p></li><li><p><font color="#0099ff" size="5" face="黑体">object feature 的 hierarchical attention 值得借鉴呢！<br>计算object 相似性的部分也不错</font></p></li></ol><h3 id="Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning"><a href="#Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning" class="headerlink" title="Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning"></a>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</h3><p><img src="https://i.loli.net/2019/09/02/T5AzpW8DHkVL2Oy.png" alt="搜狗截图20190902152617.png"></p><ul><li>此文没有太看懂</li></ul><ol><li><p>如何使用region feature？</p><p> 得到 obejcts sematics embeddding 一起其他三个信息，经过聚合之后得到特征向量v，再经过一个线性变换得到v，再送入decoder中</p></li><li><p>region feature 的构成？</p><p> 由 object detector 输出的特征，以及其他输出（objetcs 存现的频率、概率），来构建semantics</p></li></ol><h3 id="Hierarchical-Global-Local-Temporal-Modeling-for-Video-Captioning"><a href="#Hierarchical-Global-Local-Temporal-Modeling-for-Video-Captioning" class="headerlink" title="Hierarchical Global-Local Temporal Modeling for Video Captioning"></a>Hierarchical Global-Local Temporal Modeling for Video Captioning</h3><p><img src="https://i.loli.net/2019/09/02/m5xLQnzCJGsjWVc.png" alt="搜狗截图20190902161552.png"></p><ol><li><p>如何使用region features ?</p><p> encoder 部分由两层LSTM，第一层LSTM 构建 frames features 和 c3d features的 隐层状态，并送入第二层LSTM，</p><p>在第二层LSTM 的每一个step, 都对该step 对应帧上的 objetcs进行attention 加权求和，并送入LSTM中，得到该帧的objects 的聚合特征的隐层状态   </p><p> <img src="https://i.loli.net/2019/09/02/q6XNP8iSVzekyCE.png" alt="搜狗截图20190902165813.png"></p></li><li><p>region feature 的构成？</p><p>   每帧 objects features 的加权求和，再经过LSTM得到隐层状态</p></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>当前基于 objects feature 的论文，decoder 部分没有太大的新颖（一般都是Top-Down或者是 Soft-Attention），主要的新颖的地方是在 encoder 部分</li><li>encoder部分有的使用LSTM 以及attention 来更新 objects features；有的使用VLAD 来构建 行为特征，使用 objects 的时域轨迹和两层attention 来聚合特征；使用objetcs 的其他信息，比如 position 以及 label 等信息</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;CVPR 2018&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fine-grained Video Captioning for Sports Narrative&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CVPR 2019&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Grounde
      
    
    </summary>
    
      <category term="视频描述" scheme="http://yoursite.com/categories/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0/"/>
    
    
      <category term="视频描述" scheme="http://yoursite.com/tags/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>目标检测模型中的性能评估——MAP(Mean Average Precision))</title>
    <link href="http://yoursite.com/2019/08/31/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E2%80%94%E2%80%94MAP-Mean-Average-Precision/"/>
    <id>http://yoursite.com/2019/08/31/目标检测模型中的性能评估——MAP-Mean-Average-Precision/</id>
    <published>2019-08-31T01:41:03.000Z</published>
    <updated>2019-08-31T01:43:06.273Z</updated>
    
    <content type="html"><![CDATA[<p>参考：<a href="https://blog.csdn.net/katherine_hsr/article/details/79266880" target="_blank" rel="noopener">https://blog.csdn.net/katherine_hsr/article/details/79266880</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参考：&lt;a href=&quot;https://blog.csdn.net/katherine_hsr/article/details/79266880&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/katherine_
      
    
    </summary>
    
      <category term="目标检测" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="目标检测" scheme="http://yoursite.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>多标签图像分类任务的评价方法-mAP</title>
    <link href="http://yoursite.com/2019/08/31/%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95-mAP/"/>
    <id>http://yoursite.com/2019/08/31/多标签图像分类任务的评价方法-mAP/</id>
    <published>2019-08-31T00:44:47.000Z</published>
    <updated>2019-08-31T01:44:17.241Z</updated>
    
    <content type="html"><![CDATA[<p>转载 from: <a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_9db078090102whzw.html</a></p><p>多标签图像分类（Multi-label   Image  Classification）任务中图片的标签不止一个，因此评价不能用普通单标签图像分类的标准，即mean  accuracy，该任务采用的是和信息检索中类似的方法—mAP（mean  Average  Precision）。mAP虽然字面意思和mean  accuracy看起来差不多，但是计算方法要繁琐得多，以下是mAP的计算方法：</p><p>首先用训练好的模型得到所有测试样本的confidence  score，每一类（如car）的confidence   score保存到一个文件中（如comp1_cls_test_car.txt）。假设共有20个测试样本，每个的id，confidence  score和ground  truth  label如下：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQd58yJ15f" target="_blank" rel="noopener"><img src="http://s16.sinaimg.cn/mw690/002T2ChPgy6XQd58yJ15f" alt="img"></a> </p><p>接下来对confidence  score排序，得到：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQd86isc4c" target="_blank" rel="noopener"><img src="http://s13.sinaimg.cn/mw690/002T2ChPgy6XQd86isc4c" alt="img"></a><em>这张表很重要，接下来的precision和recall都是依照这个表计算的</em>﻿</p><p>然后计算precision和recall，这两个标准的定义如下：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQdjij4Ae8" target="_blank" rel="noopener"><img src="http://s9.sinaimg.cn/mw690/002T2ChPgy6XQdjij4Ae8" alt="img"></a></p><p>上图比较直观，圆圈内（true   positives + false  positives）是我们选出的元素,它对应于分类任务中我们取出的结果，比如对测试样本在训练好的car模型上分类，我们想得到top-5的结果，即：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQdbTpla5c" target="_blank" rel="noopener"><img src="http://s13.sinaimg.cn/mw690/002T2ChPgy6XQdbTpla5c" alt="img"></a></p><p>在这个例子中，true   positives就是指第4和第2张图片，false   positives就是指第13，19，6张图片。方框内圆圈外的元素（false   negatives和true  negatives）是相对于方框内的元素而言，在这个例子中，是指confidence   score排在top-5之外的元素，即：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQdcMwKCea" target="_blank" rel="noopener"><img src="http://s11.sinaimg.cn/mw690/002T2ChPgy6XQdcMwKCea" alt="img"></a> </p><p>其中，false   negatives是指第9，16，7，20张图片，true   negatives是指第1,18,5,15,10,17,12,14,8,11,3张图片。</p><p>那么，这个例子中Precision=2/5=40%，意思是对于car这一类别，我们选定了5个样本，其中正确的有2个，即准确率为40%；Recall=2/6=30%，意思是在所有测试样本中，共有6个car，但是因为我们只召回了2个，所以召回率为30%。</p><p>实际多类别分类任务中，我们通常不满足只通过top-5来衡量一个模型的好坏，而是需要知道从top-1到top-N（N是所有测试样本个数，本文中为20）对应的precision和recall。显然随着我们选定的样本越来也多，recall一定会越来越高，而precision整体上会呈下降趋势。把recall当成横坐标，precision当成纵坐标，即可得到常用的precision-recall曲线。这个例子的precision-recall曲线如下：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQddBz7ze9" target="_blank" rel="noopener"><img src="http://s10.sinaimg.cn/mw690/002T2ChPgy6XQddBz7ze9" alt="img"></a></p><p>接下来说说AP的计算，此处参考的是PASCAL  VOC  CHALLENGE的计算方法。首先设定一组阈值，[0, 0.1, 0.2, …, 1]。然后对于recall大于每一个阈值（比如recall&gt;0.3），我们都会得到一个对应的最大precision。这样，我们就计算出了11个precision。AP即为这11个precision的平均值。这种方法英文叫做11-point interpolated average precision。</p><p>当然PASCAL VOC CHALLENGE自2010年后就换了另一种计算方法。新的计算方法假设这N个样本中有M个正例，那么我们会得到M个recall值（1/M, 2/M, …, M/M）,对于每个recall值r，我们可以计算出对应（r’ &gt; r）的最大precision，然后对这M个precision值取平均即得到最后的AP值。计算方法如下：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPzy76AuWjHOp29" target="_blank" rel="noopener"><img src="http://s10.sinaimg.cn/mw690/002T2ChPzy76AuWjHOp29" alt="img"></a></p><p>相应的Precision-Recall曲线（这条曲线是单调递减的）如下：</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPzy76AuH9Z6010" target="_blank" rel="noopener"><img src="http://s1.sinaimg.cn/mw690/002T2ChPzy76AuH9Z6010" alt="img"></a></p><p>AP衡量的是学出来的模型在每个类别上的好坏，mAP衡量的是学出的模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有AP的平均值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载 from: &lt;a href=&quot;http://blog.sina.com.cn/s/blog_9db078090102whzw.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://blog.sina.com.cn/s/blog_9db
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>到底ResNet在解决一个什么问题呢</title>
    <link href="http://yoursite.com/2019/08/17/%E5%88%B0%E5%BA%95ResNet%E5%9C%A8%E8%A7%A3%E5%86%B3%E4%B8%80%E4%B8%AA%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E5%91%A2/"/>
    <id>http://yoursite.com/2019/08/17/到底ResNet在解决一个什么问题呢/</id>
    <published>2019-08-17T02:21:24.000Z</published>
    <updated>2019-08-17T08:17:14.288Z</updated>
    
    <content type="html"><![CDATA[<p>对知乎上回答的简单总结</p><hr><p><strong>一、引言：为什么会有ResNet？Why ResNet？</strong></p><ul><li><p>过拟合？<br>  不是！因为深层网络表现为训练误差和测试误差都比较高，所以不是过拟合</p></li><li><p>梯度消失？梯度爆炸？<br>  不是！因为已经使用了 batch normalization ，在很大程度上解决了梯度消失、爆炸的问题，（yaya：我个人认为对梯度消失问题有一定的帮助，毕竟梯度值为1）</p></li><li><p>深层网络退化的原因？</p><p>  由于非线性激活函数的存在，使得信息被丢失，而不能完整保留，所以，应该在网络中加入恒等映射</p></li></ul><p>*<em>二、关于resnet网络结构 【没看懂为什么要有两层】  *</em></p><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g62hrnrs6nj30h9048aax.jpg" alt></p><ul><li>yaya 分析：<br>一层：  relu(x +  w1 x)<br>两层：  relu(x +w2 relu(w1 x))</li></ul><p>​       既然非线性激活函数会把信息丢失，为什么不这样：relu(wx) + x ，因为这样是错误的，本身relu是需要放在输出后面，起到非线性的作用，但是这样，就不算作对输出的非线</p><p>*<em>三、更多的理解    *</em></p><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g62hpvudvxj30iu0cc3zi.jpg" alt></p><hr><p>yaya 的总结/理解</p><ol><li>resnet 解决的不是过拟合的问题，因为过拟合的现象是，train loss 小，但是val loss大，但是当前深层网络的问题是train loss大，val loss也大</li><li>resnet 提供了一个梯度为1的反向传播，在一定程度上解决了梯度消失的问题</li><li>FPN中指出，不同深度的网络的结合可以结合不同的分辨率，但是当前resnet 只跨越了一种分辨率，因此，没能很好地利用这一特点，因此desnet便被提出来</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对知乎上回答的简单总结&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;一、引言：为什么会有ResNet？Why ResNet？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;过拟合？&lt;br&gt;  不是！因为深层网络表现为训练误差和测试误差都比较高，所以不是过拟合&lt;/p&gt;
&lt;/l
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>深入理解Batch Normalization批标准化</title>
    <link href="http://yoursite.com/2019/08/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Batch-Normalization%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96/"/>
    <id>http://yoursite.com/2019/08/15/深入理解Batch-Normalization批标准化/</id>
    <published>2019-08-15T10:41:21.000Z</published>
    <updated>2019-08-15T10:43:29.239Z</updated>
    
    <content type="html"><![CDATA[<ul><li>转载 from：<a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/8724433.html</a></li></ul><blockquote><p>这几天面试经常被问到BN层的原理，虽然回答上来了，但还是感觉答得不是很好，今天仔细研究了一下Batch Normalization的原理，以下为参考网上几篇文章总结得出。</p></blockquote><p>　　Batch Normalization作为最近一年来DL的重要成果，已经广泛被证明其有效性和重要性。虽然有些细节处理还解释不清其理论原因，但是实践证明好用才是真的好，别忘了DL从Hinton对深层网络做Pre-Train开始就是一个<strong>经验领先于理论分析</strong>的偏经验的一门学问。本文是对论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》的导读。</p><p>　　机器学习领域有个很重要的假设：<strong>IID独立同分布假设</strong>，就是假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。那BatchNorm的作用是什么呢？<strong>BatchNorm就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的。</strong></p><p>　　接下来一步一步的理解什么是BN。</p><p>　　为什么深度神经网络<strong>随着网络深度加深，训练起来越困难，收敛越来越慢？</strong>这是个在DL领域很接近本质的好问题。很多论文都是解决这个问题的，比如ReLU激活函数，再比如Residual Network，BN本质上也是解释并从某个不同的角度来解决这个问题的。</p><h2 id="一、“Internal-Covariate-Shift”问题"><a href="#一、“Internal-Covariate-Shift”问题" class="headerlink" title="一、“Internal Covariate Shift”问题"></a>一、“Internal Covariate Shift”问题</h2><p>　　从论文名字可以看出，BN是用来解决“Internal Covariate Shift”问题的，那么首先得理解什么是“Internal Covariate Shift”？</p><p>　　论文首先说明Mini-Batch SGD相对于One Example SGD的两个优势：梯度更新方向更准确；并行计算速度快；（为什么要说这些？因为BatchNorm是基于Mini-Batch SGD的，所以先夸下Mini-Batch SGD，当然也是大实话）；然后吐槽下SGD训练的缺点：超参数调起来很麻烦。（作者隐含意思是用BN就能解决很多SGD的缺点）</p><p>　　接着引入<strong>covariate shift的概念</strong>：<strong>如果ML系统实例集合&lt;X,Y&gt;中的输入值X的分布老是变，这不符合IID假设</strong>，网络模型很难<strong>稳定的学规律</strong>，这不得引入迁移学习才能搞定吗，我们的ML系统还得去学习怎么迎合这种分布变化啊。对于深度学习这种包含很多隐层的网络结构，在训练过程中，因为各层参数不停在变化，所以每个隐层都会面临covariate shift的问题，也就是<strong>在训练过程中，隐层的输入分布老是变来变去，这就是所谓的“Internal Covariate Shift”，Internal指的是深层网络的隐层，是发生在网络内部的事情，而不是covariate shift问题只发生在输入层。</strong></p><p>　　然后提出了BatchNorm的基本思想：能不能<strong>让每个隐层节点的激活输入分布固定下来呢</strong>？这样就避免了“Internal Covariate Shift”问题了。</p><p>　　BN不是凭空拍脑袋拍出来的好点子，它是有启发来源的：之前的研究表明如果在图像处理中对输入图像进行白化（Whiten）操作的话——所谓<strong>白化</strong>，<strong>就是对输入数据分布变换到0均值，单位方差的正态分布</strong>——那么神经网络会较快收敛，那么BN作者就开始推论了：图像是深度神经网络的输入层，做白化能加快收敛，那么其实对于深度网络来说，其中某个隐层的神经元是下一层的输入，意思是其实深度神经网络的每一个隐层都是输入层，不过是相对下一层来说而已，那么能不能对每个隐层都做白化呢？这就是启发BN产生的原初想法，而BN也确实就是这么做的，<strong>可以理解为对深层神经网络每个隐层神经元的激活值做简化版本的白化操作。</strong></p><h2 id="二、BatchNorm的本质思想"><a href="#二、BatchNorm的本质思想" class="headerlink" title="二、BatchNorm的本质思想"></a><strong>二、</strong>BatchNorm的本质思想</h2><p>　　BN的基本思想其实相当直观：因为深层神经网络在做非线性变换前的<strong>激活输入值</strong>（就是那个x=WU+B，U是输入）<strong>随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近</strong>（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），所以这<strong>导致反向传播时低层神经网络的梯度消失</strong>，这是训练深层神经网络收敛越来越慢的<strong>本质原因</strong>，<strong>而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布</strong>，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是<strong>这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。</strong></p><p>　　THAT’S IT。其实一句话就是：<strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong>因为梯度一直都能保持比较大的状态，所以很明显对神经网络的参数调整效率比较高，就是变动大，就是说向损失函数最优值迈动的步子大，也就是说收敛地快。BN说到底就是这么个机制，方法很简单，道理很深刻。</p><p>　　上面说得还是显得抽象，下面更形象地表达下这种调整到底代表什么含义。</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405225246905-37854887.png" alt="img"></p><p>  图1  几个正态分布</p><p>　　假设某个隐层神经元原先的激活输入x取值符合正态分布，正态分布均值是-2，方差是0.5，对应上图中最左端的浅蓝色曲线，通过BN后转换为均值为0，方差是1的正态分布（对应上图中的深蓝色图形），意味着什么，意味着输入x的取值正态分布整体右移2（均值的变化），图形曲线更平缓了（方差增大的变化）。这个图的意思是，BN其实就是把每个隐层神经元的激活输入分布从偏离均值为0方差为1的正态分布通过平移均值压缩或者扩大曲线尖锐程度，调整为均值为0方差为1的正态分布。</p><p>　　那么把激活输入x调整到这个正态分布有什么用？首先我们看下均值为0，方差为1的标准正态分布代表什么含义：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405225314624-527885612.png" alt="img"></p><p>图2  均值为0方差为1的标准正态分布图</p><p>　　这意味着在一个标准差范围内，也就是说64%的概率x其值落在[-1,1]的范围内，在两个标准差范围内，也就是说95%的概率x其值落在了[-2,2]的范围内。那么这又意味着什么？我们知道，激活值x=WU+B,U是真正的输入，x是某个神经元的激活值，假设非线性函数是sigmoid，那么看下sigmoid(x)其图形：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143109455-1460017374.png" alt="img"></p><p>图3. Sigmoid(x)</p><p>及sigmoid(x)的导数为：G’=f(x)*(1-f(x))，因为f(x)=sigmoid(x)在0到1之间，所以G’在0到0.25之间，其对应的图如下：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142351924-124461667.png" alt="img"></p><p>图4  Sigmoid(x)导数图</p><p>　　假设没有经过BN调整前x的原先正态分布均值是-6，方差是1，那么意味着95%的值落在了[-8,-4]之间，那么对应的Sigmoid（x）函数的值明显接近于0，这是典型的梯度饱和区，在这个区域里梯度变化很慢，为什么是梯度饱和区？请看下sigmoid(x)如果取值接近0或者接近于1的时候对应导数函数取值，接近于0，意味着梯度变化很小甚至消失。而假设经过BN后，均值是0，方差是1，那么意味着95%的x值落在了[-2,2]区间内，很明显这一段是sigmoid(x)函数接近于线性变换的区域，意味着x的小变化会导致非线性函数值较大的变化，也即是梯度变化较大，对应导数函数图中明显大于0的区域，就是梯度非饱和区。</p><p>　　从上面几个图应该看出来BN在干什么了吧？其实就是把隐层神经元激活输入x=WU+B从变化不拘一格的正态分布通过BN操作拉回到了均值为0，方差为1的正态分布，即原始正态分布中心左移或者右移到以0为均值，拉伸或者缩减形态形成以1为方差的图形。什么意思？就是说<strong>经过BN后，目前大部分Activation的值落入非线性函数的线性区内，其对应的导数远离导数饱和区，这样来加速训练收敛过程。</strong></p><p>　　但是很明显，看到这里，稍微了解神经网络的读者一般会提出一个疑问：如果都通过BN，那么不就跟把非线性函数替换成线性函数效果相同了？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层是没有意义的，因为多层线性网络跟一层线性网络是等价的。这意味着网络的<strong>表达能力</strong>下降了，这也意味着深度的意义就没有了。<strong>所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale*x+shift)</strong>，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把这个值从标准正态分布左移或者右移一点并长胖一点或者变瘦一点，每个实例挪动的程度不一样，这样等价于非线性函数的值从正中心周围的线性区往非线性区动了动。核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢。当然，这是我的理解，论文作者并未明确这样说。但是很明显这里的scale和shift操作是会有争议的，因为按照论文作者论文里写的理想状态，就会又通过scale和shift操作把变换后的x调整回未变换的状态，那不是饶了一圈又绕回去原始的“Internal Covariate Shift”问题里去了吗，感觉论文作者并未能够清楚地解释scale和shift操作的理论原因。</p><h2 id="三、训练阶段如何做BatchNorm"><a href="#三、训练阶段如何做BatchNorm" class="headerlink" title="三、训练阶段如何做BatchNorm"></a>三、训练阶段如何做BatchNorm</h2><p>　　上面是对BN的抽象分析和解释，具体在Mini-Batch SGD下做BN怎么做？其实论文里面这块写得很清楚也容易理解。为了保证这篇文章完整性，这里简单说明下。</p><p>　　假设对于一个深层神经网络来说，其中两层结构如下：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405213859690-1933561230.png" alt="img"></p><p>  图5  DNN其中两层</p><p>　　要对每个隐层神经元的激活值做BN，可以想象成每个隐层又加上了一层BN操作层，它位于X=WU+B激活值获得之后，非线性函数变换之前，其图示如下：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405213955224-1791925244.png" alt="img"></p><p>  图6. BN操作</p><p>　　对于Mini-Batch SGD来说，一次训练过程里面包含m个训练实例，其具体BN操作就是对于隐层内每个神经元的激活值来说，进行如下变换：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142802238-1209499294.png" alt="img"></p><p>　　要注意，这里t层某个神经元的x(k)不是指原始输入，就是说不是t-1层每个神经元的输出，而是t层这个神经元的线性激活x=WU+B，这里的U才是t-1层神经元的输出。变换的意思是：某个神经元对应的原始的激活x通过减去mini-Batch内m个实例获得的m个激活x求得的均值E(x)并除以求得的方差Var(x)来进行转换。</p><p>　　上文说过经过这个<strong>变换后某个神经元的激活x形成了均值为0，方差为1的正态分布，目的是把值往后续要进行的非线性变换的线性区拉动，增大导数值，增强反向传播信息流动性，加快训练收敛速度。**</strong>但是这样会导致网络表达能力下降，为了防止这一点，每个神经元增加两个调节参数（scale和shift），这两个参数是通过训练来学习到的，用来对变换后的激活反变换，使得网络表达能力增强，即对变换后的激活进行如下的scale和shift操作，这其实是变换的反操作：**</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142923190-79595046.png" alt="img"></p><p>　　BN其具体操作流程，如论文中描述的一样：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142956288-903484055.png" alt="img"></p><p>　　过程非常清楚，就是上述公式的流程化描述，这里不解释了，直接应该能看懂。</p><h2 id="四、BatchNorm的推理-Inference-过程"><a href="#四、BatchNorm的推理-Inference-过程" class="headerlink" title="四、BatchNorm的推理(Inference)过程"></a>四、BatchNorm的推理(Inference)过程</h2><p>　　BN在训练的时候可以根据Mini-Batch里的若干训练实例进行激活数值调整，但是在推理（inference）的过程中，很明显输入就只有一个实例，看不到Mini-Batch其它实例，那么这时候怎么对输入做BN呢？因为很明显一个实例是没法算实例集合求出的均值和方差的。这可如何是好？</p><p>　　既然没有从Mini-Batch数据里可以得到的统计量，那就想其它办法来获得这个统计量，就是均值和方差。可以用从所有训练实例中获得的统计量来代替Mini-Batch里面m个训练实例获得的均值和方差统计量，因为本来就打算用全局的统计量，只是因为计算量等太大所以才会用Mini-Batch这种简化方式的，那么在推理的时候直接用全局统计量即可。</p><p>　　决定了获得统计量的数据范围，那么接下来的问题是如何获得均值和方差的问题。很简单，因为每次做Mini-Batch训练时，都会有那个Mini-Batch里m个训练实例获得的均值和方差，现在要全局统计量，只要把每个Mini-Batch的均值和方差统计量记住，然后对这些均值和方差求其对应的数学期望即可得出全局统计量，即：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143405654-1995556833.png" alt="img"></p><p>　　有了均值和方差，每个隐层神经元也已经有对应训练好的Scaling参数和Shift参数，就可以在推导的时候对每个神经元的激活数据计算NB进行变换了，在推理过程中进行BN采取如下方式：</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143658338-63450857.png" alt="img"></p><p>　　这个公式其实和训练时</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143807788-1841864822.png" alt="img"></p><p>　　是等价的，通过简单的合并计算推导就可以得出这个结论。那么为啥要写成这个变换形式呢？我猜作者这么写的意思是：在实际运行的时候，按照这种变体形式可以减少计算量，为啥呢？因为对于每个隐层节点来说：</p><p>　　　　　　　　<img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407144519480-1024698421.png" alt="img">　　<img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407144549010-487189588.png" alt="img"></p><p>　　都是固定值，这样这两个值可以事先算好存起来，在推理的时候直接用就行了，这样比原始的公式每一步骤都现算少了除法的运算过程，乍一看也没少多少计算量，但是如果隐层节点个数多的话节省的计算量就比较多了。</p><h2 id="五、BatchNorm的好处"><a href="#五、BatchNorm的好处" class="headerlink" title="五、BatchNorm的好处"></a>五、BatchNorm的好处</h2><p>　　BatchNorm为什么NB呢，关键还是效果好。<strong>①**</strong>不仅仅极大提升了训练速度，收敛过程大大加快；②还能增加分类效果，一种解释是这是类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；③另外调参过程也简单多了，对于初始化要求没那么高，而且可以使用大的学习率等。**总而言之，经过这么简单的变换，带来的好处多得很，这也是为何现在BN这么快流行起来的原因。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;转载 from：&lt;a href=&quot;https://www.cnblogs.com/guoyaohua/p/8724433.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/guoyaohua
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>linux 文件名中有空格、括号 时如何操作</title>
    <link href="http://yoursite.com/2019/08/14/linux-%E6%96%87%E4%BB%B6%E5%90%8D%E4%B8%AD%E6%9C%89%E7%A9%BA%E6%A0%BC%E3%80%81%E6%8B%AC%E5%8F%B7-%E6%97%B6%E5%A6%82%E4%BD%95%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2019/08/14/linux-文件名中有空格、括号-时如何操作/</id>
    <published>2019-08-14T08:22:53.000Z</published>
    <updated>2019-08-14T08:25:27.662Z</updated>
    
    <content type="html"><![CDATA[<h3 id="如何处理-cd-cp"><a href="#如何处理-cd-cp" class="headerlink" title="如何处理 cd cp"></a>如何处理 <code>cd</code> <code>cp</code></h3><ul><li><p>将文件名用<strong>双引号</strong> 包起来</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmd = 'cp -r <span class="string">"&#123;&#125;"</span> <span class="string">"&#123;&#125;"</span>'.format(source_path, target_path)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;如何处理-cd-cp&quot;&gt;&lt;a href=&quot;#如何处理-cd-cp&quot; class=&quot;headerlink&quot; title=&quot;如何处理 cd cp&quot;&gt;&lt;/a&gt;如何处理 &lt;code&gt;cd&lt;/code&gt; &lt;code&gt;cp&lt;/code&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;将文件
      
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>python 3.3.3 字面量,正则,反斜杠和原始字符串</title>
    <link href="http://yoursite.com/2019/08/14/python-3-3-3-%E5%AD%97%E9%9D%A2%E9%87%8F-%E6%AD%A3%E5%88%99-%E5%8F%8D%E6%96%9C%E6%9D%A0%E5%92%8C%E5%8E%9F%E5%A7%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    <id>http://yoursite.com/2019/08/14/python-3-3-3-字面量-正则-反斜杠和原始字符串/</id>
    <published>2019-08-14T06:59:02.000Z</published>
    <updated>2019-08-14T07:00:06.680Z</updated>
    
    <content type="html"><![CDATA[<ul><li>注明：转载 from <a href="https://www.cnblogs.com/xiangnan/p/3446904.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiangnan/p/3446904.html</a></li></ul><h1 id="两个不起眼但是比较重要的设定"><a href="#两个不起眼但是比较重要的设定" class="headerlink" title="两个不起眼但是比较重要的设定"></a>两个不起眼但是比较重要的设定</h1><ul><li>Python str类型的字面量解释器</li></ul><p>当反斜杠及其紧接字符无法构成一个具有特殊含义的序列(‘recognized escape sequences’)时,Python选择保留全部字符.直接看例子:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\c'</span></span><br><span class="line"><span class="string">'\\c'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\d'</span></span><br><span class="line"><span class="string">'\\d'</span></span><br></pre></td></tr></table></figure><p>官方管’\c’这种序列叫’unrecognized escape sequences’.官方文档相应部分:</p><p>Unlike Standard C, all unrecognized escape sequences are left in the string unchanged, i.e., <em>the backslash is left in the string</em>. (This behavior is useful when debugging: if an escape sequence is mistyped, the resulting output is more easily recognized as broken.) </p><p>按这段英文的意思,估计C语言里面,’c’和’\c’是等同的.Python是’\c’和’\c’等同.这个等以后学C语言再确定.</p><p>与上面对应的是,如果紧接字符能够和反斜杠构成’recognized escape sequences’的<strong>全部</strong>或者<strong>起始部分</strong>,中文就叫’被承认的转义序列’吧.比如:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\b'</span></span><br><span class="line"><span class="string">'\x08'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\n'</span></span><br><span class="line"><span class="string">'\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\x'</span></span><br><span class="line"><span class="symbol">SyntaxError:</span> (unicode error) <span class="string">'unicodeescape'</span> codec can<span class="string">'t decode bytes in position 0-1: truncated \xXX escape</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; '</span>\N<span class="string">'</span></span><br><span class="line"><span class="string">SyntaxError: (unicode error) '</span>unicodeescape<span class="string">' codec can'</span>t decode bytes <span class="keyword">in</span> position <span class="number">0</span>-<span class="number">1</span>: malformed \N character escape</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\U'</span></span><br><span class="line"><span class="symbol">SyntaxError:</span> (unicode error) <span class="string">'unicodeescape'</span> codec can<span class="string">'t decode bytes in position 0-1: truncated \UXXXXXXXX escape</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; '</span>\u<span class="string">'</span></span><br><span class="line"><span class="string">SyntaxError: (unicode error) '</span>unicodeescape<span class="string">' codec can'</span>t decode bytes <span class="keyword">in</span> position <span class="number">0</span>-<span class="number">1</span>: truncated \uXXXX escape</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><ul><li>Python re模块正则表达式解释器</li></ul><p>当反斜杠及其紧接字符无法构成一个具有特殊含义的序列(special sequences)时,re选择忽略反斜杠,例如:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\e'</span>,<span class="string">'eee'</span>)</span><br><span class="line">[<span class="string">'e'</span>, <span class="string">'e'</span>, <span class="string">'e'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'e'</span>,<span class="string">'eee'</span>)</span><br><span class="line">[<span class="string">'e'</span>, <span class="string">'e'</span>, <span class="string">'e'</span>]</span><br></pre></td></tr></table></figure><p>可见,’\e’和’e’起到了完全一样的效果.Python相关文档描述是:</p><p>If the ordinary character is not on the list, then the resulting RE will match the second character. For example, <code>\$</code> matches the character <code>&#39;$&#39;</code>.</p><p>与上面对应的是,如果能够构成special sequences,那么re会解释为相应含义.例如:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\w'</span>,<span class="string">'abcdefghijklmnopqrstuvwxyz'</span>)</span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>, <span class="string">'g'</span>, <span class="string">'h'</span>, <span class="string">'i'</span>, <span class="string">'j'</span>, <span class="string">'k'</span>, <span class="string">'l'</span>, <span class="string">'m'</span>, <span class="string">'n'</span>, <span class="string">'o'</span>, <span class="string">'p'</span>, <span class="string">'q'</span>, <span class="string">'r'</span>, <span class="string">'s'</span>, <span class="string">'t'</span>, <span class="string">'u'</span>, <span class="string">'v'</span>, <span class="string">'w'</span>, <span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'z'</span>]</span><br></pre></td></tr></table></figure><h1 id="字面量"><a href="#字面量" class="headerlink" title="字面量"></a>字面量</h1><p>字面量(Literals),是用于表示一些Python内建类型的常量的符号.最常见的字面量类型是str literals 和 bytes literals.</p><p>比如:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">'abc'</span></span><br><span class="line"><span class="string">'abc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">"abc"</span></span><br><span class="line"><span class="string">'abc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">'啊哦额'</span></span><br><span class="line"><span class="string">'啊哦额'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">b'abc'</span></span><br><span class="line"><span class="string">b'abc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">r'\n'</span></span><br><span class="line"><span class="string">'\\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">b'啊哦额'</span></span><br><span class="line">SyntaxError: bytes can only contain ASCII literal characters.</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><p>反斜杠\的用途按紧接其后的字符种类可划分为3类:</p><p>1.将特殊字符转换为字面量.这特殊字符包括(单引号,双引号,反斜杠):’”\</p><p>2.将普通字符转换为特殊序列.包括:abfNnrtuUvx0123456789.</p><p>(注意,bytes字面量中,NuU这三个普通字符无法被转义成特殊序列)</p><p>3.将”新行”和自身忽略掉.这个比较抽象,举例说明:py文件中,某个字符串太长了,以至于需要分两行写,那么你可以插个反斜杠,紧接着换行,然后写剩余字符串.</p><p>下面是官方文档归纳的表:</p><table><thead><tr><th>Escape Sequence</th><th>Meaning</th><th>Notes</th></tr></thead><tbody><tr><td><code>\newline</code></td><td>Backslash and newline ignored</td><td></td></tr><tr><td><code>\\</code></td><td>Backslash (<code>\</code>)</td><td></td></tr><tr><td><code>\&#39;</code></td><td>Single quote (<code>&#39;</code>)</td><td></td></tr><tr><td><code>\&quot;</code></td><td>Double quote (<code>&quot;</code>)</td><td></td></tr><tr><td><code>\a</code></td><td>ASCII Bell (BEL)</td><td></td></tr><tr><td><code>\b</code></td><td>ASCII Backspace (BS)</td><td></td></tr><tr><td><code>\f</code></td><td>ASCII Formfeed (FF)</td><td></td></tr><tr><td><code>\n</code></td><td>ASCII Linefeed (LF)</td><td></td></tr><tr><td><code>\r</code></td><td>ASCII Carriage Return (CR)</td><td></td></tr><tr><td><code>\t</code></td><td>ASCII Horizontal Tab (TAB)</td><td></td></tr><tr><td><code>\v</code></td><td>ASCII Vertical Tab (VT)</td><td></td></tr><tr><td><code>\ooo</code></td><td>Character with octal value <em>ooo</em></td><td>(1,3)</td></tr><tr><td><code>\xhh</code></td><td>Character with hex value <em>hh</em></td><td>(2,3)</td></tr></tbody></table><p>Escape sequences only recognized in string literals are:</p><table><thead><tr><th>Escape Sequence</th><th>Meaning</th><th>Notes</th></tr></thead><tbody><tr><td><code>\N{name}</code></td><td>Character named <em>name</em> in the Unicode database</td><td>(4)</td></tr><tr><td><code>\uxxxx</code></td><td>Character with 16-bit hex value <em>xxxx</em></td><td>(5)</td></tr><tr><td><code>\Uxxxxxxxx</code></td><td>Character with 32-bit hex value <em>xxxxxxxx</em></td><td>(6)</td></tr></tbody></table><p>举例:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\N&#123;END OF LINE&#125;'</span></span><br><span class="line"><span class="string">'\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\N&#123;HORIZONTAL TABULATION&#125;'</span></span><br><span class="line"><span class="string">'\t'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\u9f6a'</span>==<span class="string">'齪'</span></span><br><span class="line">True</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\1'</span>==<span class="string">'\01'</span></span><br><span class="line">True</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\1'</span>==<span class="string">'\001'</span></span><br><span class="line">True</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\1'</span>==<span class="string">'\0000001'</span></span><br><span class="line">False</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><h1 id="正则"><a href="#正则" class="headerlink" title="正则"></a>正则</h1><ul><li>正则表达式的反斜杠的作用</li></ul><p>一种是使紧跟在后面的元字符(special characters或metacharacters)失去特殊含义,变为字面量.这些元字符有14个:</p><p>.^$*+?{}<a href></a>|</p><p>另一种是使紧跟在后面的普通字符变得具有特殊含义.这些普通字符是:</p><p>AbBdDsSwWZ0123456789</p><p>以及在str字面量中能被反斜杠转义的字符:</p><p>&#39;“abfnrtuUvx0123456789</p><p>例如:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\"'</span>,<span class="string">'"'</span>)</span><br><span class="line">[<span class="string">'"'</span>]</span><br></pre></td></tr></table></figure><p>正则pattern的反斜杠的作用和Python字面量的反斜杠类似,这据说是带来”反斜杠灾难”的根源.最典型的莫过于你需要用正则’\\‘才能匹配字面量反斜杠’\‘.</p><p>为方便说明,我们假设re.search(pattern,string)中,pattern表示正则表达式字符串,string表示待匹配的字符串.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; re.search(<span class="string">'\\\\'</span>,<span class="string">'\\'</span>)</span><br><span class="line">&lt;_sre<span class="selector-class">.SRE_Match</span> <span class="selector-tag">object</span> at <span class="number">0</span>x02858528&gt;</span><br></pre></td></tr></table></figure><p>详细来说就是一个文本层级的反斜杠’&#39;(比如你在txt文件中看到的反斜杠),对应Python str 字面量的’\‘,对应正则pattern的’\\‘.这个确实比较难以理解,实在不行就住这点就好:<strong>如果不是最简单的正则类型(比如’ab’),强烈推荐对pattern使用r前缀符</strong>.这样容易理解:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.search(<span class="string">r'\\'</span>,<span class="string">'\\'</span>)</span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x02858448</span>&gt;</span><br></pre></td></tr></table></figure><p>注意:</p><ul><li>1.多重含义的特殊序列处理机制</li></ul><p>b0123456789比较特殊,它们在Python字面量和re正则中都能和反斜杠构成作用不同的特殊序列.例如\b,在python 字面量中解释为”退格键”.re正则中解释为’单词边界’.<strong>python 字面量有优先解释权</strong>,如下可证:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\b'</span>,<span class="string">'\b'</span>)  <span class="comment">#'\b'被优先解释为退格键,而不是单词边界</span></span><br><span class="line">[<span class="string">'\x08'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b'</span>,<span class="string">'\b'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b'</span>,<span class="string">'b'</span>) </span><br><span class="line">[<span class="string">''</span>, <span class="string">''</span>]</span><br></pre></td></tr></table></figure><p>再比如:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'(a)\1\1'</span>,<span class="string">'aaa'</span>) <span class="comment">#\1按字面量优先解释为八进制字符串,因此无匹配结果</span></span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'(a)\\1\\1'</span>,<span class="string">'aaa'</span>)  <span class="comment">#\\1按正则引擎层级的反斜杠解释为第一个匹配组提取到的字符,相当于'(a)aa'</span></span><br><span class="line">[<span class="string">'a'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'a\1\1'</span>,<span class="string">'a\1\1'</span>) <span class="comment">#\1按字面量优先解释为八进制字符串,所以有匹配结果</span></span><br><span class="line">[<span class="string">'a\x01\x01'</span>]</span><br></pre></td></tr></table></figure><p>了解这个设置有什么用?</p><p>1.当你想使用正则层级的特殊序列\1时,如果你没有使用r作为前缀,那么你必须使用\1才能如愿.</p><p>2.当你想使用字面量层级的特殊序列\1时,则不能使用r作为pattern前缀.</p><p>想想,你有可能在一个r前缀的字符串中写出能够匹配值为1的八进制字符串的pattern吗?</p><p>也许我太较真了,因为实践中好像从没遇到过需要匹配值为1的八进制字符串的情况,但理论上就是这样的.</p><ul><li><strong>2.正则表达式中特殊序列的准确定义的猜想</strong></li></ul><p>官方文档下面的一句话值得推敲:</p><p>Note that <code>\b</code> is used to represent word boundaries, and means “backspace” only inside character classes</p><p>意思是说\b只有在[…]里面时才表示退格键,这显然是错的.比如下面这个例子,\b没有在[]之内,但它是按”退格键”解释的,并非”单词边界”:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\b'</span>,<span class="string">'\b'</span>)</span><br><span class="line">[<span class="string">'\x08'</span>]</span><br></pre></td></tr></table></figure><p>除非官方文档描述的\b是指文本层面的数据(比如你在txt文档里看到的\b).</p><p>由此引出了一个猜想,re的正则pattern中”反斜杠+普通字符”构成特殊序列或”反斜杠+特殊字符”构成字面量–这种描述中的反斜杠准确来说是指两个反斜杠!</p><p>仍然是举例说明:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b\w+\\b'</span>,<span class="string">'one two three'</span>)  <span class="comment">#必须用\\b才能表示单词边界</span></span><br><span class="line">[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b\\w+\\b'</span>,<span class="string">'one two three'</span>)  <span class="comment">#想想,为什么\w和\\w都一样</span></span><br><span class="line">[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\d'</span>,<span class="string">'123'</span>)</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\d'</span>,<span class="string">'123'</span>)</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>]</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><ul><li>3.u和U只在str字面量中才能被转义,bytes字面量中是普通字符.</li></ul><p>以下是我猜测的正则表达式分析器和Python字面量分析器的传递规则表格:</p><table><thead><tr><th>Python string literal</th><th>values passed to regular expression</th><th>number of characters</th><th>what regular expression engine does</th><th>real meaning for regular expression</th></tr></thead><tbody><tr><td>\e</td><td>\e</td><td>2</td><td>ignore the backslash</td><td>e</td></tr><tr><td>\e</td><td>\e</td><td>2</td><td>ignore the backslash</td><td>e</td></tr><tr><td>e</td><td>e</td><td>1</td><td>nothing spacial</td><td>e</td></tr><tr><td>\n</td><td>\n</td><td>1</td><td>nothing spacial</td><td>换行符</td></tr><tr><td>\n</td><td>\n</td><td>2</td><td>\n is special</td><td>换行符</td></tr><tr><td>\b</td><td>\b</td><td>1</td><td>nothing spacial</td><td>退格键</td></tr><tr><td>\b</td><td>\b</td><td>2</td><td>\b is special</td><td>word boundary</td></tr><tr><td>\s</td><td>\s</td><td>2</td><td>\s is special</td><td>Unicode whitespace characters</td></tr><tr><td>\</td><td>\</td><td>1</td><td>must followed by a charcter</td><td>Can’t form any meaning</td></tr><tr><td>\\</td><td>\</td><td>2</td><td>remove all special meanning of \</td><td>\</td></tr><tr><td>*</td><td>*</td><td>1</td><td>* is special</td><td>repeat the left characters 0 or more times</td></tr><tr><td>*</td><td>*</td><td>2</td><td>remove all special meanning of *</td><td>*</td></tr></tbody></table><p>最后是待探究的例子:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[<span class="string">'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[<span class="string">'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[<span class="string">'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[<span class="string">'\x08'</span>, <span class="string">'\x08'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[<span class="string">'\x08'</span>, <span class="string">'\x08'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'c'</span>, <span class="string">'c'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'c'</span>, <span class="string">'c'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'\\c'</span>, <span class="string">'\\c'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'\\c'</span>, <span class="string">'\\c'</span>]</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p><p>参考:</p><p>Python 3.3.3 官方文档</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;注明：转载 from &lt;a href=&quot;https://www.cnblogs.com/xiangnan/p/3446904.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/xiangna
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>glob 之 **</title>
    <link href="http://yoursite.com/2019/08/13/glob-%E4%B9%8B/"/>
    <id>http://yoursite.com/2019/08/13/glob-之/</id>
    <published>2019-08-13T06:25:21.000Z</published>
    <updated>2019-08-14T02:07:02.733Z</updated>
    
    <content type="html"><![CDATA[<ul><li>该篇主要介绍glob的一些使用小技巧</li></ul><h3 id="想要获得某个文件目录下所有-指定文件格式-的所有文件"><a href="#想要获得某个文件目录下所有-指定文件格式-的所有文件" class="headerlink" title="想要获得某个文件目录下所有 指定文件格式 的所有文件"></a>想要获得某个文件目录下所有 <strong><em>指定文件格式</em></strong> 的所有文件</h3><ul><li><p>假设有一个文件环境如下图所示</p><p><img src="https://i.loli.net/2019/08/14/sjTANPfDuV6cord.png" alt="搜狗截图20190814100532.png"></p></li></ul><ul><li><p>比如想要获得<code>/userhome/dataset/MSVD/YouTubeClips/YouTubeClips</code> 下 <code>.avi</code>格式的所有文件</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">path</span> = <span class="string">'/userhome/dataset/MSVD/YouTubeClips/YouTubeClips/'</span></span><br><span class="line">glob.glob(<span class="built_in">path</span> + <span class="string">'*.avi'</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>想要获得某目录下的所有子目录中的所有指定文件格式的所有文件</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">path</span> = <span class="string">'/userhome/dataset/MSVD/YouTubeClips/'</span></span><br><span class="line">glob.glob(<span class="built_in">path</span> + <span class="string">'**/'</span> + <span class="string">'*.avi'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">path</span> = <span class="string">'/userhome/dataset/MSVD/'</span></span><br><span class="line">glob.glob(<span class="built_in">path</span> + <span class="string">'**/'</span> + <span class="string">'**/'</span> + <span class="string">'*.avi'</span>)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;该篇主要介绍glob的一些使用小技巧&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;想要获得某个文件目录下所有-指定文件格式-的所有文件&quot;&gt;&lt;a href=&quot;#想要获得某个文件目录下所有-指定文件格式-的所有文件&quot; class=&quot;headerlink&quot; title=&quot;想
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title> pytorch clone() vs copy_()</title>
    <link href="http://yoursite.com/2019/08/06/pytorch-clone-vs-copy/"/>
    <id>http://yoursite.com/2019/08/06/pytorch-clone-vs-copy/</id>
    <published>2019-08-06T07:05:25.000Z</published>
    <updated>2019-08-06T07:06:02.565Z</updated>
    
    <content type="html"><![CDATA[<p><code>clone</code>() → Tensor</p><ul><li>反向传播时，将会返回到原来的变量上<br>Returns a copy of the <code>self</code> tensor. The copy has the same size and data type as <code>self</code>.</li><li>NOTE</li><li>Unlike copy_(), this function is recorded in the computation graph. Gradients propagating to the cloned tensor will propagate to the original tensor.</li></ul><hr><p><code>copy_</code>(<em>src</em>, <em>non_blocking=False</em>) → Tensor</p><ul><li><p>只是值得复制<br>Copies the elements from <code>src</code> into <code>self</code> tensor and returns <code>self</code>.</p></li><li><p>The <code>src</code> tensor must be <a href="https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics" target="_blank" rel="noopener">broadcastable</a> with the <code>self</code> tensor. It may be of a different data type or reside on a different device.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;clone&lt;/code&gt;() → Tensor&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;反向传播时，将会返回到原来的变量上&lt;br&gt;Returns a copy of the &lt;code&gt;self&lt;/code&gt; tensor. The copy has the same siz
      
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>实验中遇到的问题及解决</title>
    <link href="http://yoursite.com/2019/08/05/%E5%AE%9E%E9%AA%8C%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3/"/>
    <id>http://yoursite.com/2019/08/05/实验中遇到的问题及解决/</id>
    <published>2019-08-05T11:22:00.000Z</published>
    <updated>2019-08-05T11:41:45.360Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题 1"></a>问题 1</h3><ul><li>问题描述：首先表现为：在pycharm debug下和在running模式下的实验结果不一致，<br><br>后来，在训练阶段将预训练的模型保存下来，载入evaluate.py 文件中再次进行评估，得到的分数与在训练阶段评估的分数不一致</li><li>解决思路：由于第二个现象，更加容易解决，因此先解决他，师兄提出一个办法，将保存的模型再次载入，这样就可以有两个网络，然后比较两个网络的数据是在哪里出现差异的，这样可以找到问题。</li><li>解决办法：</li></ul><ol><li>在训练一个epoch 后，将模型保存了下来，然后用两个网络，一个时train.py中重新加载这个网络，一个是在evaluate.py中加载这个网络，将得到的结果，进行比较，（看输出的结果是否一致），然后发现，在一些video 输出的结果是一样的，在一些video是不一样的。<br></li><li>找到那些video对应的结果不一样的所对应的iteration，在该iteration打印出了网络中的部分变量的数据，发现，在dataloader的数据就是不一样的.<br></li><li>那么问题就是出现在数据加载上。通过对数据加载部分的代码进行调试，发现，仅在num_workers=0时，两个dataloader的数据才一样，而采用多线程的话，两个dataloader的数据不完全一样。而又在其他的代码上测试，多线程不会影响数据加载，那么问题就是出现在，自己设计的dataset上，<br></li><li>又发现在加载h5py文件时，没有取切片，而self.critical pytorch代码时加上了的，通过加上切片 <code>[:]</code> 发现在多线程时，是正常的。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题-1&quot;&gt;&lt;a href=&quot;#问题-1&quot; class=&quot;headerlink&quot; title=&quot;问题 1&quot;&gt;&lt;/a&gt;问题 1&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;问题描述：首先表现为：在pycharm debug下和在running模式下的实验结果不一致，&lt;br&gt;&lt;br&gt;后
      
    
    </summary>
    
      <category term="问题总结" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="问题总结" scheme="http://yoursite.com/tags/%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Bridging the Gap between Training and Inference for Neural Machine Translation</title>
    <link href="http://yoursite.com/2019/08/04/Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation/"/>
    <id>http://yoursite.com/2019/08/04/Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation/</id>
    <published>2019-08-04T12:53:17.000Z</published>
    <updated>2019-08-04T13:51:20.419Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Multi-Label Image Recognition with Graph Convolutional Networks</title>
    <link href="http://yoursite.com/2019/08/02/Multi-Label-Image-Recognition-with-Graph-Convolutional-Networks/"/>
    <id>http://yoursite.com/2019/08/02/Multi-Label-Image-Recognition-with-Graph-Convolutional-Networks/</id>
    <published>2019-08-02T13:22:06.000Z</published>
    <updated>2019-08-03T04:07:09.308Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Motivation：建模-label-之间的依赖"><a href="#Motivation：建模-label-之间的依赖" class="headerlink" title="Motivation：建模  label 之间的依赖"></a>Motivation：建模  label 之间的依赖</h3><ul><li>使用GCN来建模label之间的依赖</li><li>有向图</li><li>每个节点用 label 的词向量来表达</li></ul><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><h4 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h4><ul><li><p>GCN 的输入：GCN 的 输入是label的word embedding，使用预训练的glove vector，如果label 是含有多个词的，那么对这多个词的词向量取平均，</p></li><li><p>GCN的输出<code>C*D</code>是为了得到一个分类器，<code>C</code>是类别数，<code>D</code>是image representation的维度，</p></li><li><p>邻接矩阵：a<sub>ij</sub>用条件概率来表示：当label<sub>i</sub>出现时，label<sub>j</sub>出现的概率，因此这不是一个对称矩阵，具体地论文中还给出了更加细节的修改。</p></li></ul><h4 id="image-representation"><a href="#image-representation" class="headerlink" title="image representation"></a>image representation</h4><ul><li>使用 ResNet101 得到 conv5层的输出，再经过全局池化得到一个<code>D</code>维度的特征向量</li></ul><h4 id="multi-label-classifier"><a href="#multi-label-classifier" class="headerlink" title="multi-label classifier"></a>multi-label classifier</h4><ul><li>将上两步的输出进行矩阵相乘，就可以得到 计算的multi-label</li></ul><p><img src="https://i.loli.net/2019/08/03/cdwYEWSF9q6tk3p.png" alt="搜狗截图20190802221229.png"></p><h3 id="不同点-vs-semi-supervised-gcn"><a href="#不同点-vs-semi-supervised-gcn" class="headerlink" title="不同点 vs semi-supervised gcn"></a>不同点 vs semi-supervised gcn</h3><p>1.</p><ul><li>不同于一般的GCN，输入节点的特征，和边，经过GCN之后，得到的是更新后的节点特征</li><li>本文GCN的输出<code>C*D</code>是为了得到一个分类器，<code>C</code>是类别数，<code>D</code>是image representation的维度，</li><li>GCN 的 输入是label的word embedding，使用预训练的glove vector，如果label 是含有多个词的，那么对这多个词的词向量取平均</li></ul><p>2.</p><ul><li>一般的GCN的邻接矩阵是预先定义好的，</li><li>但是本文的邻接矩阵：need to construct the <code>A</code> from scrach</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Motivation：建模-label-之间的依赖&quot;&gt;&lt;a href=&quot;#Motivation：建模-label-之间的依赖&quot; class=&quot;headerlink&quot; title=&quot;Motivation：建模  label 之间的依赖&quot;&gt;&lt;/a&gt;Motivation
      
    
    </summary>
    
      <category term="图卷积网络" scheme="http://yoursite.com/categories/%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="图卷积网络" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>word2vec</title>
    <link href="http://yoursite.com/2019/08/02/word2vec-1/"/>
    <id>http://yoursite.com/2019/08/02/word2vec-1/</id>
    <published>2019-08-02T04:51:02.000Z</published>
    <updated>2019-08-02T04:51:02.386Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>word2vec</title>
    <link href="http://yoursite.com/2019/08/01/word2vec/"/>
    <id>http://yoursite.com/2019/08/01/word2vec/</id>
    <published>2019-08-01T12:56:45.000Z</published>
    <updated>2019-08-02T14:37:15.464Z</updated>
    
    <content type="html"><![CDATA[<h3 id="使用one-hot-来作为词向量"><a href="#使用one-hot-来作为词向量" class="headerlink" title="使用one-hot 来作为词向量"></a>使用one-hot 来作为词向量</h3><ul><li>存在一个缺点，即，两个单词之间的余弦相似度为0，因为one-hot是两两正交的形式。</li><li>但是相似度为0，显然是不对的</li></ul><h3 id="word2vet"><a href="#word2vet" class="headerlink" title="word2vet"></a>word2vet</h3><ul><li><p>跳字模型：中心词生成背景词</p></li><li><p>连续词袋模型：背景词生成中心词</p></li><li><p>这两个模型存在的问题：在softmax中，由于分母是对整个vocab进行求和，导致反向传播的计算量非常大</p></li><li><p><a href="https://www.bilibili.com/video/av18512944/" target="_blank" rel="noopener">相关教程</a></p></li></ul><p>预训练模型</p><ul><li>glove</li><li>fasttext</li><li><a href="https://www.bilibili.com/video/av18795160/?spm_id_from=333.788.videocard.0" target="_blank" rel="noopener">相关教程</a></li><li>spacy</li><li><a href="https://shiyaya.github.io/2019/07/16/Spacy工具包/" target="_blank" rel="noopener">https://shiyaya.github.io/2019/07/16/Spacy%E5%B7%A5%E5%85%B7%E5%8C%85/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;使用one-hot-来作为词向量&quot;&gt;&lt;a href=&quot;#使用one-hot-来作为词向量&quot; class=&quot;headerlink&quot; title=&quot;使用one-hot 来作为词向量&quot;&gt;&lt;/a&gt;使用one-hot 来作为词向量&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;存在一个缺点，即
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>FPN</title>
    <link href="http://yoursite.com/2019/08/01/FPN/"/>
    <id>http://yoursite.com/2019/08/01/FPN/</id>
    <published>2019-08-01T06:47:34.000Z</published>
    <updated>2019-08-17T02:56:53.203Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="https://vision.cornell.edu/se3/wp-content/uploads/2017/07/fpn-poster.pdf" target="_blank" rel="noopener">poster</a></li><li><a href="https://blog.csdn.net/WZZ18191171661/article/details/79494534" target="_blank" rel="noopener">某篇博客</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://vision.cornell.edu/se3/wp-content/uploads/2017/07/fpn-poster.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;poster&lt;/a&gt;&lt;/li&gt;
&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>VideoGraph: Recognizing Minutes-Long Human Activities in Videos</title>
    <link href="http://yoursite.com/2019/07/30/VideoGraph-Recognizing-Minutes-Long-Human-Activities-in-Videos/"/>
    <id>http://yoursite.com/2019/07/30/VideoGraph-Recognizing-Minutes-Long-Human-Activities-in-Videos/</id>
    <published>2019-07-30T13:15:55.000Z</published>
    <updated>2019-08-02T13:23:11.520Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>当前基于CNN或者non-lcoal的方法，可以建模 temporal concepts，但是却不能建模分钟级长的时域依赖。</li><li>学习一个无向图，节点和边都是直接从video中得到，而不需要进行单独的节点标注。</li><li>这里的节点是：组成activity的一个unit-action，比如 “煎鸡蛋” 这个activity里的 “打破鸡蛋” 。</li><li>边，表示 (units-action) 运动单元之间的时域关系</li></ul><h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h3><ul><li>建模长范围的activity</li><li>捕捉到细节信息</li></ul><h3 id="Vs-Video-as-space-time-region-graph"><a href="#Vs-Video-as-space-time-region-graph" class="headerlink" title="Vs  Video as space-time region graph"></a>Vs  <code>Video as space-time region graph</code></h3><ul><li>Video as space-time region graph： 需要提取 key objects</li><li>Video graph：自动的从video中学到 nodes</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;当前基于CNN或者non-lcoal的方法，可以建模 tempo
      
    
    </summary>
    
      <category term="行为识别" scheme="http://yoursite.com/categories/%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="行为识别" scheme="http://yoursite.com/tags/%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>安装pytorch_geometricc</title>
    <link href="http://yoursite.com/2019/07/30/%E5%AE%89%E8%A3%85pytorch-geometricc/"/>
    <id>http://yoursite.com/2019/07/30/安装pytorch-geometricc/</id>
    <published>2019-07-30T07:15:51.000Z</published>
    <updated>2019-08-12T12:49:33.840Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p><a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#frequently-asked-questions" target="_blank" rel="noopener">官方链接</a></p></li><li><p>下面是截取自官方</p></li></ul><h2 id="Directly-Installation"><a href="#Directly-Installation" class="headerlink" title="Directly Installation"></a>Directly Installation</h2><p>We have outsourced a lot of functionality of PyTorch Geometric to other packages, which needs to be installed in advance. These packages come with their own CPU and GPU kernel implementations based on the newly introduced <a href="https://github.com/pytorch/extension-cpp/" target="_blank" rel="noopener">C++/CUDA extensions</a> in PyTorch 0.4.0.</p><p>Note</p><p>We do not recommend installation as root user on your system python. Please setup an <a href="https://conda.io/docs/user-guide/install/index.html/" target="_blank" rel="noopener">Anaconda/Miniconda</a> environment or create a <a href="https://www.docker.com/" target="_blank" rel="noopener">Docker image</a>.</p><p>Please follow the steps below for a successful installation:</p><ol start="0"><li><p>Added  by yaya:</p><ul><li><p>may be you can select a conda environments, will be more fine</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3<span class="number">-5.0</span><span class="number">.0</span>-Linux-x86_64.sh</span><br><span class="line">conda create -n pytorch_geometric python=<span class="number">3.7</span> -y</span><br><span class="line">source activate pytorch_geometric</span><br></pre></td></tr></table></figure></li><li><p>after into env: pytorch_geometric</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">install</span> <span class="selector-tag">torch-1</span><span class="selector-class">.1</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span>  # <span class="selector-tag">download</span> <span class="selector-tag">at</span> <span class="selector-tag">first</span></span><br><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">installl</span> <span class="selector-tag">numpy-1</span><span class="selector-class">.17</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span>  # <span class="selector-tag">download</span> <span class="selector-tag">at</span> <span class="selector-tag">first</span></span><br><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">install</span> <span class="selector-tag">scipy-1</span><span class="selector-class">.3</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span>  # <span class="selector-tag">download</span> <span class="selector-tag">at</span> <span class="selector-tag">first</span></span><br></pre></td></tr></table></figure></li></ul></li></ol><ol><li><p>Ensure that at least PyTorch 1.1.0 is installed:</p><blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; $ python -c <span class="string">"import torch; print(torch.__version__)"</span></span><br><span class="line">&gt; <span class="meta">&gt;&gt;&gt; </span><span class="number">1.1</span>.<span class="number">0</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote></li><li><p>Ensure CUDA is setup correctly (optional):</p><blockquote><ol><li><p>Check if PyTorch is installed with CUDA support:</p><blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;    &gt; $ python -c <span class="string">"import torch; print(torch.cuda.is_available())"</span></span><br><span class="line">&gt;    &gt; <span class="meta">&gt;&gt;&gt; </span>True</span><br><span class="line">&gt;    &gt;</span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="2"><li><p>Add CUDA to <code>$PATH</code> and <code>$CPATH</code> (note that your actual CUDA path may vary from <code>/usr/local/cuda</code>):</p><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda/bin:<span class="variable">$PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/bin:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; </span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> CPATH=/usr/<span class="built_in">local</span>/cuda/include:<span class="variable">$CPATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$CPATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/include:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt;</span></span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="3"><li><p>Add CUDA to <code>$LD_LIBRARY_PATH</code> on Linux and to <code>$DYLD_LIBRARY_PATH</code> on macOS (note that your actual CUDA path may vary from <code>/usr/local/cuda</code>):</p><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$LD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/lib64:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; </span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> DYLD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda/lib:<span class="variable">$DYLD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$DYLD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/lib:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt;</span></span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="4"><li><p>Verify that <code>nvcc</code> is accessible from terminal:</p><blockquote><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="quote">&gt;    &gt; $ nvcc --version</span></span><br><span class="line"><span class="quote">&gt;    &gt; &gt;&gt;&gt; 10.0</span></span><br><span class="line"><span class="quote">&gt;    &gt;</span></span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="5"><li><p>Ensure that PyTorch and system CUDA versions match:</p><blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;    &gt; $ python -c <span class="string">"import torch; print(torch.version.cuda)"</span></span><br><span class="line">&gt;    &gt; <span class="meta">&gt;&gt;&gt; </span><span class="number">10.0</span></span><br><span class="line">&gt;    &gt; </span><br><span class="line">&gt;    &gt; $ nvcc --version</span><br><span class="line">&gt;    &gt; <span class="meta">&gt;&gt;&gt; </span><span class="number">10.0</span></span><br><span class="line">&gt;    &gt;</span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote></li><li><p>Install all needed packages:</p><blockquote><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="symbol">$</span> you can see <span class="number">4.</span> first (optional)</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-scatter</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-sparse</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-cluster</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-spline-conv (optional)</span><br><span class="line">&gt; <span class="symbol">$</span> pip install torch-geometric</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote></li><li><p>added by yaya:<br>may be you can pip install scipy at first ,because above need it.</p></li></ol><h2 id="Docker-install"><a href="#Docker-install" class="headerlink" title="Docker install"></a>Docker install</h2><ul><li><a href="https://github.com/rusty1s/pytorch_geometric/tree/master/docker" target="_blank" rel="noopener">https://github.com/rusty1s/pytorch_geometric/tree/master/docker</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#frequently-asked-questions&quot; target=&quot;_blank&quot; 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GCN_LSTM  vs  SGAE</title>
    <link href="http://yoursite.com/2019/07/30/gcn-on-captioning/"/>
    <id>http://yoursite.com/2019/07/30/gcn-on-captioning/</id>
    <published>2019-07-30T02:55:21.000Z</published>
    <updated>2019-07-31T13:13:19.284Z</updated>
    
    <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Just can be seen by yaya.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Video Description: A Survey of Methods, Datasets and Evaluation Metrics</title>
    <link href="http://yoursite.com/2019/07/29/Video-Description-A-Survey-of-Methods-Datasets-and-Evaluation-Metrics/"/>
    <id>http://yoursite.com/2019/07/29/Video-Description-A-Survey-of-Methods-Datasets-and-Evaluation-Metrics/</id>
    <published>2019-07-29T02:21:32.000Z</published>
    <updated>2019-07-29T13:00:31.749Z</updated>
    
    <content type="html"><![CDATA[<h3 id="视频描述仍然处于起步阶段的原因"><a href="#视频描述仍然处于起步阶段的原因" class="headerlink" title="视频描述仍然处于起步阶段的原因"></a>视频描述仍然处于起步阶段的原因</h3><ul><li>对视频描述模型的分析是困难的，很难去判别是visual feature 亦或是 language model 哪个做的贡献大</li><li>当前的数据集，既没有包含足够的视觉多样性，也没有复杂的语言结构</li><li>当前的凭据指标并不能非常正确的去评估生成的句子与人类生成的句子之间的一致程度</li></ul><h3 id="the-difficulty-of-video-caption"><a href="#the-difficulty-of-video-caption" class="headerlink" title="the difficulty of video caption"></a>the difficulty of video caption</h3><ul><li>并不是在video中的所有object 都是与description相关的，可能其只是背景中的一个元素。    </li><li>此外，还需要objects的运动信息，以及 事件，动作，对象之间的因果关系。   </li><li>视频中的action可能有不同的长度，不同的action之间，可能有重叠。    </li></ul><h3 id="Sequence-Learning-based-Video-Captioning-Methods"><a href="#Sequence-Learning-based-Video-Captioning-Methods" class="headerlink" title="Sequence Learning based Video Captioning Methods"></a>Sequence Learning based Video Captioning Methods</h3><h4 id="CNN-RNN-based"><a href="#CNN-RNN-based" class="headerlink" title="CNN-RNN-based"></a>CNN-RNN-based</h4><ul><li><p>第一个 end-to-end：</p><p>S. Venugopalan, H. Xu, J. Donahue, M. Rohrbach, R. Mooney, and K. Saenko. 2014. Translating videos to natural language using deep recurrent neural networks. arXiv preprint arXiv:1412.4729, (2014).    </p><img src="https://i.loli.net/2019/07/29/5d3ea016090c918345.png" alt="图片1.png" title="图片1.png"></li><li><p>S2VT （变长输入，变长输出）</p><p>I. Sutskever, O. Vinyals, and Q. V. Le. 2014. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems. 3104-3112.    </p><img src="https://i.loli.net/2019/07/29/5d3ea01536b3144846.png" alt="图片2.png" title="图片2.png">   </li><li><p>TA ( 加入C3D[1] )</p><p>L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, and A.Courville. 2015. Describing videos by exploiting temporal structure. In IEEE ICCV    </p><img src="https://i.loli.net/2019/07/29/5d3ea016a248c95582.png" alt="图片3.png" title="图片3.png">  </li><li><p>LSTM-E （making a common visual-semantic-embedding ）</p><p>Y. Pan, T. Mei, T. Yao, H. Li, and Y. Rui. 2016. Jointly modeling embedding and translation to bridge video and language. In IEEE CVPR. </p><img src="https://i.loli.net/2019/07/29/5d3ea421aaf9013065.png" alt="图片4.png" title="图片4.png"></li></ul><ul><li><p>GRU-EVE  ( short fourier transform)</p><p>N. Aafaq, N. Akhtar, W. Liu, S. Z. Gilani and A. Mian. 2019. Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning. In IEEE CVPR.    </p><img src="https://i.loli.net/2019/07/29/5d3ea0163113561600.png" alt="搜狗截图20190729152752.png" title="搜狗截图20190729152752.png">   </li><li><p>h-RNN<br>H. Yu, J. Wang, Z. Huang, Y. Yang, and W. Xu. 2016. Video paragraph captioning using hierarchical recurrent neural networks. In IEEE CVPR.</p><img src="https://i.loli.net/2019/07/29/5d3ea63af2e0354548.png" alt="图片5.png" title="图片5.png"></li></ul><h4 id="RL-based"><a href="#RL-based" class="headerlink" title="RL-based"></a>RL-based</h4><ul><li><p>Z. Ren, X. Wang, N. Zhang, X. Lv, and L. Li. 2017. Deep reinforcement learning-based image captioning with embedding reward. arXiv preprint arXiv:1704.03899, (2017).</p></li><li><p>Y. Chen, S. Wang, W. Zhang, and Q. Huang. 2018.  ==Less Is More: Picking Informative Frames for Video Captioning.==  arXiv preprint arXiv:1803.01457, (2018).</p><p>提出了一个基于强化学习的方法，来选择 key informative frames 来表达一个 complete video ，希望这样的操作可以忽略掉噪声和不必要的计算。</p></li><li><p>L. Li and B. Gong. 2018. End-to-End Video Captioning with Multitask Reinforcement Learning. arXiv preprint arXiv:1803.07950,<br>(2018).</p></li><li><p>R. Pasunuru and M. Bansal. 2017. Reinforced video captioning with entailment rewards. arXiv preprint arXiv:1708.02300, (2017).</p></li><li><p>S. Phan, G. E. Henter, Y. Miyao, and S. Satoh. 2017. Consensusbased Sequence Training for Video Captioning. arXiv preprint arXiv:1712.09532, (2017).</p></li><li><p>X. Wang, W. Chen, J. Wu, Y. Wang, and W. Y. Wang. 2017.  ==Video Captioning via Hierarchical Reinforcement Learning.==  arXiv preprint arXiv:1711.11135, (2017).</p><p>在 decoder阶段，使用 深度强化学习，这个方法证明可以捕捉到视频内容中的细节，并生成细粒度的description，但是！这个方法相对于当前的baseline 没有多大的提高。（我自己还需要再看看， 使用DRL的motivation）</p></li></ul><h3 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h3><ul><li><p><a href="https://blog.csdn.net/joshuaxx316/article/details/58696552" target="_blank" rel="noopener">参考链接</a></p></li><li><p>BLEU、ROUGE、METEOR  来源于 机器翻译</p></li><li><p>CIDEr、SPICE 来源于图像描述   </p></li></ul><h4 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h4><ul><li><a href="https://blog.csdn.net/allocator/article/details/79657792" target="_blank" rel="noopener">BLEU参考链接</a></li><li>==BLEU实质是对两个句子的共现词频率计算==，但计算过程中使用好些技巧，追求计算的数值可以衡量这两句话的一致程度。 </li><li>BLEU容易陷入常用词和短译句的陷阱中，而给出较高的评分值。本文主要是对解决BLEU的这两个弊端的优化方法介绍。</li><li>缺点</li></ul><ol><li>　不考虑语言表达（语法）上的准确性； </li><li>　 测评精度会受常用词的干扰； </li><li>　 短译句的测评精度有时会较高； </li><li>　没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定；</li></ol><h4 id="ROUGE"><a href="#ROUGE" class="headerlink" title="ROUGE"></a>ROUGE</h4><img src="https://i.loli.net/2019/07/29/5d3ed71f2086769963.png" alt="20170228224903951.png" title="20170228224903951.png"><h4 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h4><img src="https://i.loli.net/2019/07/29/5d3edcce1761442736.png" alt="20170228225011405.png" title="20170228225011405.png">   <h4 id="CIDEr"><a href="#CIDEr" class="headerlink" title="CIDEr"></a>CIDEr</h4><img src="https://i.loli.net/2019/07/29/5d3edcce646d089162.png" alt="20170228225056046.png" title="20170228225056046.png"><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><img src="https://i.loli.net/2019/07/29/5d3edd503479c20027.png" alt="搜狗截图20190729194921.png" title="搜狗截图20190729194921.png">    <h3 id="当前的瓶颈："><a href="#当前的瓶颈：" class="headerlink" title="当前的瓶颈："></a>当前的瓶颈：</h3><h4 id="缺乏有效的评价指标"><a href="#缺乏有效的评价指标" class="headerlink" title="缺乏有效的评价指标"></a>缺乏有效的评价指标</h4><ul><li><p>我们的调查显示，阻碍这一研究进展的一个主要瓶颈是缺乏有效和有目的设计的视频描述评价指标。目前，无论是从机器翻译还是从图像字幕中，都采用了现有的度量标准，无法衡量机器生成的视频字幕的质量及其与人类判断的一致性。改进这些指标的一种方法是增加引用语句的数量。我们认为，从数据本身学习的目的构建的度量标准是推进视频描述研究的关键。    </p></li><li><p>王鑫也曾说：human evaluation在video captioning任务中是有必要的       </p><h4 id="视觉特征部分的瓶颈"><a href="#视觉特征部分的瓶颈" class="headerlink" title="视觉特征部分的瓶颈"></a>视觉特征部分的瓶颈</h4></li><li><p>在一个video中，可能出现多个activity，但是caption model只能检测出部分几个，导致性能下降。   </p></li><li><p>可能这个video中 action 的持续时间较长，但是，当前的video representation方法只能捕捉时域较短的运动信息（eg:C3D），因此不能很好地提取视频特征。   </p></li><li><p>大多数特征提取器只适用于静态或平稳变化的图像，因此难以处理突然的场景变化。目前的方法通过表示整体视频或帧来简化视觉编码部分。可能需要进一步探索注意力模型，以关注视频中具有重要意义的空间和时间部分。   </p></li><li><p>当前的encoder 与 decoder 部分，并 ==不是端到端的==，需要先提取 video representation再进行decoder，这样分布进行，而不是端到端的训练是不好的！    </p></li></ul><h3 id="captioning-model-的可解释性不足"><a href="#captioning-model-的可解释性不足" class="headerlink" title="captioning model 的可解释性不足"></a>captioning model 的可解释性不足</h3><ul><li>举个例子：当我们从包含“白色消防栓”的帧中看到视频描述模型生成的标题“红色消防栓”时，很难确定颜色特征是视觉特征提取器编码错误还是由于使用的语言模型bias( 由于有过多的训练数据是“红色消防栓)。<img src="https://i.loli.net/2019/07/29/5d3ee4996cf7480633.png" alt="搜狗截图20190729202028.png" title="搜狗截图20190729202028.png"></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li>[1] D. Tran, L. D. Bourdev, R. Fergus, L. Torresani, and M. Paluri. 2014. C3D: Generic Features for Video Analysis. CoRR abs/1412.0767, (2014). </li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;视频描述仍然处于起步阶段的原因&quot;&gt;&lt;a href=&quot;#视频描述仍然处于起步阶段的原因&quot; class=&quot;headerlink&quot; title=&quot;视频描述仍然处于起步阶段的原因&quot;&gt;&lt;/a&gt;视频描述仍然处于起步阶段的原因&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;对视频描述模型的分析是困
      
    
    </summary>
    
      <category term="视频描述" scheme="http://yoursite.com/categories/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0/"/>
    
    
      <category term="视频描述" scheme="http://yoursite.com/tags/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0/"/>
    
  </entry>
  
</feed>
