<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Instructions</title>
      <link href="/2020/06/20/Instructions/"/>
      <url>/2020/06/20/Instructions/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GithubMarkdown</title>
      <link href="/2020/06/20/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E8%A7%86%E9%A2%91%E6%98%BE%E7%A4%BA%E5%9C%A8Github%E7%9A%84Markdown%E9%A1%B5%E6%96%B9%E6%B3%95/"/>
      <url>/2020/06/20/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E8%A7%86%E9%A2%91%E6%98%BE%E7%A4%BA%E5%9C%A8Github%E7%9A%84Markdown%E9%A1%B5%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<ul><li></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>--</title>
      <link href="/2020/06/06/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%B6%E9%9B%86%E8%BF%87%E7%A8%8B-%E5%90%84%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB/"/>
      <url>/2020/06/06/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%B6%E9%9B%86%E8%BF%87%E7%A8%8B-%E5%90%84%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h3 id="Stanford-Natural-Language-Inference"><a href="#Stanford-Natural-Language-Inference" class="headerlink" title=" Stanford Natural Language Inference "></a><font color="red"> Stanford Natural Language Inference </font></h3><h4 id=""><a href="#" class="headerlink" title=""></a><strong></strong></h4><p>Flickr human written captions  <strong>premises</strong> </p><p>1AMT workers   premises labelAsked AMT workers to supply hypotheses for each of our three labels entailment, neutral, and contradiction. <strong>hypotheses</strong>  (label,  author label)</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfhjx642jrj30k90pk441.jpg" style="zoom:50%"><p>2premises-hypotheses pair4 AMT workerslabellabelpremises-hypotheses pair5labelpairlabel gold label.</p><h4 id="Data-validation"><a href="#Data-validation" class="headerlink" title="*Data validation  *"></a>*<em>Data validation  *</em></h4><p><strong></strong>5%AMT workers2AMT workers label  Individual label Individual label  gold label/ authors label </p><ul><li><font color="red"><strong>yaya</strong> </font></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfhl3kdkdtj30gj0na42d.jpg" style="zoom:50%"><h3 id="Visual-Entailment-Dataset"><a href="#Visual-Entailment-Dataset" class="headerlink" title=" Visual Entailment Dataset  "></a><font color="red"> Visual Entailment Dataset  </font></h3><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><p> Flickr  SNLI dataset </p><p>image-text pairmodel pair [Entailment, Contradiction, Neutral]</p><p> SNLI dataset  Flickr30k image captions </p><ul><li><strong>Entailment</strong> holds if there is enough evidence in image to conclude that text is true.</li><li><strong>Contradiction</strong> holds if there is enough evidence in image to conclude that text is false.</li><li><strong>Neutral</strong>, implying the evidence in image is insufficient to draw a conclusion about text.  </li></ul><h4 id=""><a href="#" class="headerlink" title=""></a><strong></strong></h4><p>SNLI, VQA-v1.0, VQA-v2.0, and CLEVR,  :</p><ul><li><strong>Structured set of real-world images.</strong> The dataset should be based on real-world images and the same image can be paired with different hypotheses to form different labels. </li><li><strong>Fine-grained.</strong> The dataset should enforce fine-grained reasoning about subtle changes in hypotheses that could lead to distinct labels. </li><li><strong>Sanitization.</strong> No instance overlapping across different dataset partitions. One image can only exist in a single partition.  </li><li><strong>Account for any bias.</strong> Measure the dataset bias and  provide baselines to serve as the performance lower bound for potential future evaluations.  </li></ul><h3 id="WMT-Shared-Task"><a href="#WMT-Shared-Task" class="headerlink" title="WMT Shared Task  "></a><font color="red">WMT Shared Task  </font></h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfijyrn8qsj30zw0gvwl7.jpg" style="zoom:50%"><h4 id="Human-judgement-quality-control"><a href="#Human-judgement-quality-control" class="headerlink" title="Human judgement quality control"></a>Human judgement quality control</h4><ul><li><p>HIT100 reference+ candidatepair, reference, candidate</p></li><li><p>100pair60quality control40participating systems </p><p>160pairrepeat pairs (expecting a similar judgment), damage MT outputs/ bad reference (expecting significantly worse scores) and use references instead of MT outputs (expecting high scores). 20%bad reference; good reference</p><p>SpecificallyMT system  30 reference, MT outputpair table 5  original system output 1)1-1010211-20MT outputreference caption10321-30corresponding reference&gt; (reference_1, reference_2)10</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gepxhtqcpgj311h052abz.jpg"><p>2within each 100-translation HIT articipating system<strong></strong>awithin each 100-translation HIT, the same proportion of translations are included from each participating system for that language pair.   1workersHIT, human judgement2workerworker3DA HIT</p></li></ul><h4 id="Annotator-Agreement"><a href="#Annotator-Agreement" class="headerlink" title="Annotator Agreement"></a>Annotator Agreement</h4><p>1 bad reference pairs pairs human assessors</p><p>setA, bad reference   setA, translatin_Bp-value p-value&gt;0.05 human assessor</p><p>2 repeat pairs,  repeat assessments</p><h4 id="Producing-the-Human-Ranking"><a href="#Producing-the-Human-Ranking" class="headerlink" title="Producing the Human Ranking"></a>Producing the Human Ranking</h4><ul><li><p>Standardized </p><p><strong></strong></p></li></ul><h3 id="VIOLIN-Video-and-Language-Inference"><a href="#VIOLIN-Video-and-Language-Inference" class="headerlink" title="[VIOLIN] Video-and-Language Inference "></a><font color="red">[VIOLIN] Video-and-Language Inference </font></h3><p>yaya blog: <a href="https://shiyaya.github.io/2020/03/28/VIOLIN-A-Large-Scale-Dataset-for-Video-and-Language-Inference/" target="_blank" rel="noopener">https://shiyaya.github.io/2020/03/28/VIOLIN-A-Large-Scale-Dataset-for-Video-and-Language-Inference/</a></p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>  Subtitles   video statement  video [entailed (label 1) contradicts (label 0) ]</p><p><strong>positive statements </strong> subtitles + videoannotators  statements</p><p><strong>negative statements </strong>1annotatorspositive statements negative statements2<strong></strong>video_i/j  positive statement H_i/j , H_i H_j  negative statements  human bias</p><h4 id="-Instruction"><a href="#-Instruction" class="headerlink" title=" Instruction"></a> Instruction</h4><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfil6timz7j31c60van7q.jpg"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfil6tix9ij313e150na4.jpg"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfil6tj9shj30ts14mtl2.jpg"><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfilt0g35qj316o128n4z.jpg" style="zoom:50%"><h3 id="VCR"><a href="#VCR" class="headerlink" title="VCR"></a><font color="red">VCR</font></h3><p>yaya blog: <a href="https://shiyaya.github.io/2020/05/16/From-Recognition-to-Cognition-Visual-Commonsense-Reasoning/" target="_blank" rel="noopener">https://shiyaya.github.io/2020/05/16/From-Recognition-to-Cognition-Visual-Commonsense-Reasoning/</a></p><h4 id="-2"><a href="#-2" class="headerlink" title=""></a></h4><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfioadgc3qj30r20pbn3e.jpg"><h4 id="Crowdsourcing-quality-data"><a href="#Crowdsourcing-quality-data" class="headerlink" title="Crowdsourcing quality data"></a>Crowdsourcing quality data</h4><p><strong>Automated quality checks</strong></p><p>UI<strong></strong>workers  questionanswerrationale detection</p><p>*<em>Instructions  *</em></p><p>workersquestionhigh-levelgeneral questions, image </p><p>workers </p><p>*<em>Qualification exam  *</em></p><p>worker VCR</p><p>The qualification test included a mix of multiple-choice graded answers as well as a short written section, which was to provide a single question, answer, and rationale for an image.  </p><p>requester(VCR)worker</p><p><strong>Work verification</strong>  </p><p> workers  questionanswerrationales HIT outstanding workers in previous annotation work ,  another worker $0.4</p><h3 id="Composite-dataset"><a href="#Composite-dataset" class="headerlink" title="Composite dataset"></a><font color="red">Composite dataset</font></h3><p>From: <code>From Images to Sentences through Scene Description Graphs using Commonsense Reasoning and Knowledge</code></p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p> image captioning captioning model AMTour_captioning_model gold-standard description  the output from a state-of-the-art image captioning system.  </p><p>:  <strong>how much the description conveys the image content</strong> (relevance) and <strong>how much of the image content is conveyed by the description</strong> (thoroughness)</p><h4 id="Instruction"><a href="#Instruction" class="headerlink" title="Instruction"></a>Instruction</h4><ul><li> Instruction</li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfiysqscgfj316r0e943t.jpg"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gfiysr0uf8j317i0g2an3.jpg"><ul><li>workers captioning model</li></ul><h3 id="Reinforcement-Learning-in-Image-QE"><a href="#Reinforcement-Learning-in-Image-QE" class="headerlink" title="Reinforcement Learning in Image QE"></a>Reinforcement Learning in Image QE</h3><p>From: Reinforcing an Image Caption Generator Using Off-Line Human Feedback  </p><p>human judgement score,  image captioning </p><p>captioning model Single-caption evaluation   Side-by-side caption evaluation  </p><p><strong>Single-caption evaluation</strong></p><p>image-captioning pair,6raters[good, bad], 6majority votingpair </p><p><strong>Side-by-side caption evaluation</strong>  </p><p> (image, our_model_prediction, baseline_model_prediction) raters, imagesentence<strong></strong></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>--</title>
      <link href="/2020/06/04/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87-%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B1%87%E6%80%BB/"/>
      <url>/2020/06/04/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87-%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<p> metric  human judgementimage-text-human_score,  metric_evaluation  human_score </p><h1 id="Caption-level-Correlation"><a href="#Caption-level-Correlation" class="headerlink" title="Caption-level Correlation"></a>Caption-level Correlation</h1><h2 id="Flickr-8k-Dataset"><a href="#Flickr-8k-Dataset" class="headerlink" title="Flickr 8k Dataset"></a>Flickr 8k Dataset</h2><ul><li>website: <a href="http://academictorrents.com/details/9dea07ba660a722ae1008c4c8afdd303b6f6e53b" target="_blank" rel="noopener">http://academictorrents.com/details/9dea07ba660a722ae1008c4c8afdd303b6f6e53b</a></li><li>: Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics   </li></ul><p><font size="2"> <strong></strong> </font></p><ul><li><p>Cite: Framing image description as a ranking task: Data, models and evaluation metrics.  </p></li><li><p>8092image600010001000image 5</p></li><li><p> </p><p><strong>1000</strong><font color="blue"><strong>image-text retrieval </strong></font> candidate captionimagegroundtruth</p><p>image-text pairpair<strong></strong>imagetext( give a score from 1 (not related to the image content) to 4 (very related))</p><p>metric  human judgement </p></li></ul><p><font size="2"> <strong> Note</strong> </font></p><ul><li>TIGER [1] : <strong>Because 158 candidates are actual references of target images, we excluded these for further analysis</strong> <font color="red">TIGER Flickr 8kimagereference</font></li></ul><p><font size="2"> <strong></strong></font></p><p><code>Kendall</code> and <code>Spearman</code> rank correlations reflect the similarity of the pairwise rankings whereas <code>Pearsons</code> p captures the linear association between data points.</p><h2 id="Composite-Dataset"><a href="#Composite-Dataset" class="headerlink" title="Composite Dataset"></a>Composite Dataset</h2><p>From Images to Sentences through Scene Description Graphs using Commonsense Reasoning and Knowledge  </p><p><font size="2"> <strong></strong> </font></p><p>testing captions for 2007 MS-COCO images, 997 Flickr 8k pictures, and 991 Flickr 30k images.  </p><p>3candidate captions1human written reference 2machine generated</p><p>11,985 candidates, image from 1 (not relevant) to 5 (very relevant)</p><p><font size="2"> <strong></strong></font></p><p><code>Kendall</code> and <code>Spearman</code> rank correlations reflect the similarity of the pairwise rankings whereas <code>Pearsons</code> p captures the linear association between data points.</p><h2 id="Pascal-50s-Dataset"><a href="#Pascal-50s-Dataset" class="headerlink" title="Pascal 50s Dataset"></a>Pascal 50s Dataset</h2><ul><li>website: <a href="http://vrama91.github.io/cider/" target="_blank" rel="noopener">http://vrama91.github.io/cider/</a></li></ul><p><font size="2"> <strong></strong> </font></p><p>Cite: <code>CIDEr: Consensus-based Image Description Evaluation</code></p><p> UIUC PASCAL Sentence Dataset1000imageimage5human written sentence</p><p> </p><p>image  AMT workers50captionspascal 50s </p><p>image-text candidate  referenceimage148 of 50 human written caption as <strong>reference</strong>2human written caption as <strong>candidate</strong> machine generated caption as <strong>candidate</strong>other image  human written caption candidate<strong>candidate</strong></p><p>A, (B, C)(reference, (candidate_1, candidate_2)) (B, C) HCHIHMMM1humanhuman correct pairs (HC), where we pick two human sentences describing the same image. 2 humanhuman incorrect pairs (HI), where one of the sentences is a human description for the image and the other is also a human sentence but describing some other image from the dataset picked at random. 3humanmachine (HM) pairs formed by pairing a human sentence describing an image with a machine generated sentence describing the same image. 4machinemachine (MM) pairs, where we compare two machine generated sentences describing the same image</p><p> 1000image  48reference(A)  4(B,C) = 192000</p><p><strong>human judgement </strong> (A, B, C)A reference sentence, (B, C) candidate captions pair. BCAhuman judgements for each triplet. BCB is winner.</p><p><font size="2"> <strong> Note</strong> </font></p><ul><li>acuracyPASCAL-50s4HCHIHMMM A,(B, C)pairB, CAMT workerspair(B, C)proposed metricBC sentencesBCscoresentence, GT proposed metric pairHC/HI/HM/MM</li></ul><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gcdc0x4s91j30ex04uaas.jpg" alt="20200229160306.png"></p><p><font size="2"> <strong></strong></font></p><p>Pairwise Classification Accuracy</p><h1 id="System-Level-Correlation"><a href="#System-Level-Correlation" class="headerlink" title="System-Level Correlation"></a>System-Level Correlation</h1><h2 id="the-2015-COCO-Captioning-Challenge-for-12-teams"><a href="#the-2015-COCO-Captioning-Challenge-for-12-teams" class="headerlink" title="the 2015 COCO Captioning Challenge for 12 teams"></a>the 2015 COCO Captioning Challenge for 12 teams</h2><p><font size="2"> <strong></strong> </font></p><ul><li><p>Cite: The coco 2015 captioning challenge. <a href="http://mscoco.org/dataset/#captions-challenge2015" target="_blank" rel="noopener">http://mscoco.org/dataset/#captions-challenge2015</a>.  </p></li><li><p>use human judgements collected in the 2015 COCO Captioning Challenge for 12 teams who participated in this captioning challenge.</p></li><li><p>We report</p><ul><li><p>M1: Percentage of captions that are evaluated as better or equal to human caption,</p></li><li><p>M2: Percentage of captions that pass the Turing Test,</p></li><li><p>M3: Average correctness of the captions on a scale of 1-5 (incorrect - correct),</p></li><li><p>M4: Average amount of detail of the captions on a scale of 1-5 (lack of details - very detailed) and</p></li><li><p>M5: Percentage of captions that are similar to human description.</p></li><li><p>While M1 and M2 were used to rank the captioning models in the COCO challenge.   </p><p>M3, M4 and M5  are not used to rank image captioning models , but are intended for an ablation study to understand the various aspects of caption quality.  </p></li></ul></li></ul><p><font size="2"><strong> Note</strong> </font></p><p>system-level correlation, 1 caption model metric score, model caption  metric socre2 captio model aggregate metric score  system-level human assessments</p><p><font size="2"> <strong></strong></font></p><ul><li>Compare proposed metric with others on the <strong>Pearsons  correlation</strong> between all common metrics and human judgments collected in the 2015 COCO Captioning Challenge. </li></ul><h1 id=""><a href="#" class="headerlink" title=""></a></h1><table><thead><tr><th></th><th>Caption-level Correlation</th><th></th><th></th><th>System-Level Correlation</th></tr></thead><tbody><tr><td></td><td>Flickr 8k</td><td>Composite</td><td>pascal-50s</td><td>2015 COCO Captioning Challenge</td></tr><tr><td>CIDEr</td><td></td><td></td><td></td><td></td></tr><tr><td>SPICE</td><td></td><td></td><td></td><td></td></tr><tr><td>(CVPR 2018) Learning to Evaluate Image Captioning</td><td></td><td></td><td></td><td></td></tr><tr><td>(EMNLP-IJCNLP 2019) REO-Relevance, Extraness, Omission A Fine-grained Evaluation for Image Captioning</td><td></td><td></td><td></td><td></td></tr><tr><td>(ACL 2019) VIFIDEL Evaluating the visual fidelity of image descriptions</td><td></td><td></td><td></td><td></td></tr><tr><td>(EMNLP2019) TIGEr Text-to-Image Grounding for Image Caption Evaluation</td><td></td><td></td><td></td><td></td></tr><tr><td>(IJCV)Learning-based Composite Metrics for Improved Caption Evaluation</td><td></td><td></td><td></td><td></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
      <link href="/2020/05/31/Sentence-BERT-Sentence-Embeddings-using-Siamese-BERT-Networks/"/>
      <url>/2020/05/31/Sentence-BERT-Sentence-Embeddings-using-Siamese-BERT-Networks/</url>
      
        <content type="html"><![CDATA[<h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>BERT  RoBERTa  sentence-pair regression tasks (eg: semantic textual similarity ) 1000050 million10000+1*10000/2, BERT 65 hours</p><p><strong>the construction of BERTsemantic similarity search information retrieval via semantic search</strong></p><p><strong></strong>  sentence-BERT,  BERTsiamese  triplet sentence embeddings, cosine similarity.</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p></p><h4 id="yaya-"><a href="#yaya-" class="headerlink" title="yaya "></a>yaya </h4><p> BERT video-text retrieval </p><p>We showed in (Reimers et al., 2016)[1] that Pearson correlation is badly suited for  STS. Instead, we compute the Spearmans rank correlation between the cosine-similarity of the sentence embeddings and the gold labels  </p><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>[1] Nils Reimers, Philip Beyer, and Iryna Gurevych. 2016.<br><strong>Task-Oriented Intrinsic Evaluation of Semantic Textual Similarity.</strong><br>In Proceedings of the 26th International Conference on Computational Linguistics (COLING), pages 8796.      </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title> tips</title>
      <link href="/2020/05/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87-tips/"/>
      <url>/2020/05/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87-tips/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p></p><p></p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p><strong></strong> <strong></strong><strong></strong><strong></strong></p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p><strong></strong><strong></strong><strong></strong></p><p></p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gf9in4p85tj30f8088t92.jpg"><p></p><p></p><p></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>From Recognition to Cognition: Visual Commonsense Reasoning</title>
      <link href="/2020/05/16/From-Recognition-to-Cognition-Visual-Commonsense-Reasoning/"/>
      <url>/2020/05/16/From-Recognition-to-Cognition-Visual-Commonsense-Reasoning/</url>
      
        <content type="html"><![CDATA[<h4 id="Visual-Commonsense-Reasoning-VCR"><a href="#Visual-Commonsense-Reasoning-VCR" class="headerlink" title="Visual Commonsense Reasoning (VCR)"></a>Visual Commonsense Reasoning (VCR)</h4><p>VCR: Given an image, a list of regions, and a question, a model must answer the question and provide a rationale explaining why its answer is right. </p><p> <strong></strong> imagequestionanswercorrect answerAMT workers questionanswerwrong answeradversarial matching negative answer</p><h4 id="The-Motivation-of-Adversarial-Matching"><a href="#The-Motivation-of-Adversarial-Matching" class="headerlink" title="The Motivation of Adversarial Matching"></a>The Motivation of Adversarial Matching</h4><p></p><ul><li><p><strong>A crucial challenge</strong> in constructing a dataset of this complexity at this scale is how to avoid <strong>annotation artifacts</strong>. </p></li><li><p><strong>A recurring challenge</strong> in most recent QA datasets has been that human-written answers contain unexpected but distinct <strong>biases</strong> that models can easily exploit. </p></li></ul><p><strong></strong></p><h4 id="Adversarial-Matching"><a href="#Adversarial-Matching" class="headerlink" title="Adversarial Matching"></a>Adversarial Matching</h4><p>negative answercorrect answerannotation artifactssubtle patterns that are by themselves highly predictive of the correct or incorrect label. 123</p><p>The key idea of Adversarial Matching is to <strong>recycle</strong> each correct answer for a question exactly three times  as a <strong>negative answer</strong> for three other questions.  answer 1/4<strong> answer-only bais </strong> most generic answer. </p><p>image negative answer<strong>negative answer: relevant as possible to the context/question (so that they appeal to machines), while they cannot be overly similar to the correct response (so that they dont become correct answers incidentally).</strong> </p><p>weightqueryquesteionquery correct answerbertESIM+ELM</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1geuprb6zmvj310305qwfg.jpg"><p>negative answernagetive pairsnegative answerimagenegative answernegative answerreplace the similarity term with the maximum similarity between a candidate response rj and all responses currently assigned to qi.</p><h4 id="Language-Priors-and-Annotation-Artifacts-Discussion"><a href="#Language-Priors-and-Annotation-Artifacts-Discussion" class="headerlink" title="Language Priors and Annotation Artifacts Discussion"></a>Language Priors and Annotation Artifacts Discussion</h4><p><strong>Answer Priors</strong>: A model can select a correct answer without even looking at the question. </p><p><strong>Non-Visual Priors </strong>A model can select a correct answer using only non-visual elements of the question. </p><p>priors </p><p>annotation artifacts  class-conditioned answers </p><ul><li><strong> artificial bias</strong> </li></ul><h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><ol><li>The effect of different writing tasks on linguistic style: A case study of the ROC story cloze task.  </li><li>Annotation artifacts in natural language inference data. </li><li>Hypothesis Only Baselines in Natural Language Inference. </li></ol>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WMT Shared Tasks -- Human Evaluation </title>
      <link href="/2020/05/14/WMT-Shared-Tasks-Human-Evaluation/"/>
      <url>/2020/05/14/WMT-Shared-Tasks-Human-Evaluation/</url>
      
        <content type="html"><![CDATA[<h3 id="WMT-Shared-Tasks--Human-Evaluation"><a href="#WMT-Shared-Tasks--Human-Evaluation" class="headerlink" title="WMT Shared Tasks  Human Evaluation"></a>WMT Shared Tasks  Human Evaluation</h3><h4 id="Human-Evaluation"><a href="#Human-Evaluation" class="headerlink" title="Human Evaluation"></a>Human Evaluation</h4><p>direct assessments (DA); language pairs evaluated with relative ranking (RR)</p><p>DARRnamely absolute score <strong>quality control</strong> </p><h4 id="Human-judgement-quality-control"><a href="#Human-judgement-quality-control" class="headerlink" title="Human judgement quality control"></a>Human judgement quality control</h4><ul><li><p>100 reference+ candidatepair, reference, candidate</p></li><li><p>100pair60quality control40participating systems </p><p>160pairrepeat pairs (expecting a similar judgment), damage MT outputs/ bad reference (expecting significantly worse scores) and use references instead of MT outputs (expecting high scores). 20%bad reference; good reference</p><p>SpecificallyMT system  30 reference, MT outputpair table 5  original system output 1)1-1010211-20MT output10321-30corresponding reference&gt; (reference_1, reference_2)10</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gepxhtqcpgj311h052abz.jpg"><p>2within each 100-translation HIT articipating system<strong></strong>awithin each 100-translation HIT, the same proportion of translations are included from each participating system for that language pair.   1workersHIT, human judgement2workerworker3DA HIT</p></li></ul><h4 id="Annotator-Agreement"><a href="#Annotator-Agreement" class="headerlink" title="Annotator Agreement"></a>Annotator Agreement</h4><ul><li><p><strong>bad reference pairs</strong>  bad reference pairs pairs human assessors</p><p>setA, bad reference   setA, translatin_Bp-value p-value&gt;0.05 human assessor</p></li><li><p><strong>repeat pairs</strong>  repeat pairs,  repeat assessments</p></li></ul><h4 id="Producing-the-Human-Ranking"><a href="#Producing-the-Human-Ranking" class="headerlink" title="Producing the Human Ranking"></a>Producing the Human Ranking</h4><ul><li><p>Standardized </p><p><strong></strong></p></li><li><p>system  score </p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning</title>
      <link href="/2020/05/10/Attacking-Visual-Language-Grounding-with-Adversarial-Examples-A-Case-Study-on-Neural-Image-Captioning/"/>
      <url>/2020/05/10/Attacking-Visual-Language-Grounding-with-Adversarial-Examples-A-Case-Study-on-Neural-Image-Captioning/</url>
      
        <content type="html"><![CDATA[<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1genh1kz7svj30i40dpag7.jpg" alt="Fig_stopsign_2_small.png"></p><p>1image RGB captioning model1tested image captioning systems2captioning model  visual language grounding </p><h4 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h4><ul><li><strong></strong></li><li>captioning model -</li><li> </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Evaluate Image Captioning</title>
      <link href="/2020/05/09/Learning-to-Evaluate-Image-Captioning/"/>
      <url>/2020/05/09/Learning-to-Evaluate-Image-Captioning/</url>
      
        <content type="html"><![CDATA[<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p></p><p><strong>Motivation</strong>: SPICESPICE</p><p></p><h4 id="How-to-Use-the-Proposed-Metric-in-Practice"><a href="#How-to-Use-the-Proposed-Metric-in-Practice" class="headerlink" title="How to Use the Proposed Metric in Practice"></a>How to Use the Proposed Metric in Practice</h4><p>   captioning dataset </p><p>:  coco  <strong>test</strong> captioning, submission scratch </p><h4 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h4><ul><li>(1) One direction of future work could aim to capture the heterogeneous nature of human annotated captions and incorporate such information into captioning evaluation.  <strong>Human annotated captions </strong></li><li>(2) Another direction for future work could be training a caption generator together with the proposed evaluation metric (discriminator) in a generative adversarial setting. <strong>captioning model </strong></li><li>(3) Finally, gameability is definitely a concern, not only for our learning based metric, but also for other rule-based metrics. Learning to be more robust to adversarial examples is also a future direction of learning based evaluation metrics.  <strong> </strong></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross-modal Coherence Modeling for Caption Generation</title>
      <link href="/2020/04/22/Cross-modal-Coherence-Modeling-for-Caption-Generation/"/>
      <url>/2020/04/22/Cross-modal-Coherence-Modeling-for-Caption-Generation/</url>
      
        <content type="html"><![CDATA[<h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul><li>image text</li><li>1Unfortunately, such dedicated annotation efforts cannot yield enough data for training robust generation models; the resulting generated captions are plagued by content<br>hallucinations (Rohrbach et al., 2018; Sharma et al., 2018) that effectively preclude them for being used in real-world applications. </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks</title>
      <link href="/2020/04/16/Oscar-Object-Semantics-Aligned-Pre-training-for-Vision-Language-Tasks/"/>
      <url>/2020/04/16/Oscar-Object-Semantics-Aligned-Pre-training-for-Vision-Language-Tasks/</url>
      
        <content type="html"><![CDATA[<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><ul><li>bert vision-language task image region features  text features 1<strong>region  text poses</strong> 2vision region(region)regionvision-language task</li><li>imagesobject tags anchor pointsimages  text </li><li>vision-language pre-training method <strong>OSCAR</strong> word sequence, a set of object tags, and a set of image region features. </li><li>Motivated by: the salient objects in an image can be accurately detected by modern object detectors, and that these objects are often mentioned in the paired text.</li></ul><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gdvtabmqe2j30qh0f247k.jpg" alt="20200416190213.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>A negative case analysis of visual grounding methods for VQA</title>
      <link href="/2020/04/15/A-negative-case-analysis-of-visual-grounding-methods-for-VQA/"/>
      <url>/2020/04/15/A-negative-case-analysis-of-visual-grounding-methods-for-VQA/</url>
      
        <content type="html"><![CDATA[<h4 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h4><p>VQA [1] [2]. vision grounding grounding VQA</p><p>Grounding using irrelevant cuesGrounding using fixed random cuesGrounding using variable random cues </p><p>Regularization by zeroing out answers  training accuracyVQAgrounding grounding</p><h4 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h4><ul><li><p>spurious source.</p></li><li><p>  if methods are able to focus on relevant information.</p></li><li><p>Use tasks  that explicitly test grounding, e.g., in visual query detection an agent must output boxes around any regions of a scene that match the natural language query .</p></li></ul><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>[1] Ramprasaath R Selvaraju, Stefan Lee, Yilin Shen, Hongxia Jin, Shalini Ghosh, Larry Heck, Dhruv Batra, and Devi Parikh. <strong>Taking a hint: Leveraging explanations to make vision and language models more grounded.</strong>  In ICCV 2019. </p><p>[2] Jialin Wu and Raymond Mooney. <strong>Self-critical reasoning for robust visual question answering.</strong> In NeurIPS 2019</p>]]></content>
      
      
      <categories>
          
          <category> Grounding  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Grounding  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models</title>
      <link href="/2020/04/01/Egoshots-an-ego-vision-life-logging-dataset-and-semantic-fidelity-metric-to-evaluate-diversity-in-image-captioning-models/"/>
      <url>/2020/04/01/Egoshots-an-ego-vision-life-logging-dataset-and-semantic-fidelity-metric-to-evaluate-diversity-in-image-captioning-models/</url>
      
        <content type="html"><![CDATA[<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><ul><li><p>image caption dataset </p><p><em>Egoshots</em>978</p></li><li><p>standard metric</p><p><em></em>SFreference captionsSF</p></li></ul><h4 id="SF"><a href="#SF" class="headerlink" title="SF"></a>SF</h4><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gdel85qhz8j30se0g97eb.jpg" alt="20200401212845.png"></p><h4 id="Annotation-Pipline-and-Sementic-Fidelity-Metric"><a href="#Annotation-Pipline-and-Sementic-Fidelity-Metric" class="headerlink" title="Annotation Pipline and Sementic Fidelity Metric"></a>Annotation Pipline and Sementic Fidelity Metric</h4><ul><li><p>annotation pipline</p><p>caption model: Show Attend And Tell (SAT), nocaps: novel object captioning at scale (NOC), and Decoupled Novel Object Captioner (DNOC) Egoshotscaptioning </p></li><li><p>sementic fidelity metric</p><p><em></em>SF1 2captionimage sceneobjects</p><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gdelh0afpej3055021a9x.jpg" alt="20200401213725.png"></p><p>isic iODOO O DNin N icaption iSF[01]SF1</p><p>siRecent works (Mikolov et al., 2013; Conneau et al., 2017) show the ability of word embeddings that is transforming a word into its vectored form efficiently capture the semantic closeness of two given words. The SF metric uses this approach to calculate such semantic similarity between the noun words and objects in an image.</p><p>that #O  #N (Assumption 1) for all images. This approach to compute SF will work only assuming robust object detectors satisfying enough scene annotation granularity.  </p><p>0Assumption 2: #O = 0 (i.e., the object detector can at least detect one object in the image). </p><h4 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h4></li><li><p>metricSFa well generalized and robust object detection model plays the most important role if<br>the evaluation of captions is performed using SF. </p></li><li><p>SFO = 02SF</p></li></ul><h4 id="Appendix-"><a href="#Appendix-" class="headerlink" title="Appendix: "></a>Appendix: </h4><ul><li><p>/12Cohen17</p><p></p></li></ul><h4 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h4><ul><li>open-domain dataset  in-domain captioning modelmodelmodel<code>eg: </code></li></ul><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><ul><li><p>Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. </p><p>Distributed Representations of Words and Phrases and their  Compositionality. In NIPS, 2013. </p></li><li><p>Alexis Conneau, Guillaume Lample, MarcAurelio Ranzato, Ludovic Denoyer, and Herve J  egou. <br>Word Translation Without Parallel Data. ArXiv, abs/1710.04087, 2017 </p></li><li><p>Joseph Paul Cohen, Genevieve Boucher, Craig A. Glastonbury, Henry Z. Lo, and Yoshua Bengio.<br>Count-ception: Counting by Fully Convolutional Redundant Counting. In The IEEE International<br>Conference on Computer Vision (ICCV) Workshops, Oct 2017. </p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(ACL 2019)Putting Evaluation in Context: Contextual Embeddings improve Machine Translation Evaluation</title>
      <link href="/2020/04/01/ACL-2019-Putting-Evaluation-in-Context-Contextual-Embeddings-improve-Machine-Translation-Evaluation/"/>
      <url>/2020/04/01/ACL-2019-Putting-Evaluation-in-Context-Contextual-Embeddings-improve-Machine-Translation-Evaluation/</url>
      
        <content type="html"><![CDATA[<ul><li><p>Human judgements</p><p> 1We treat the human reference translation and the MT output as the premise and hypothesis, respectively </p><p>2Using squared error as part of regression loss  being better suited to Pearsons r  and might be resolved through a different loss. Using hinge loss over pairwise preferences which would better reflect Kendalls Tau</p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BERTScore: Evaluating Text Generation with BERT</title>
      <link href="/2020/04/01/BERTScore-Evaluating-Text-Generation-with-BERT/"/>
      <url>/2020/04/01/BERTScore-Evaluating-Text-Generation-with-BERT/</url>
      
        <content type="html"><![CDATA[<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>BERTScore</p><p>BERTScoretokentokenBERT embedding </p><p>BERTScore</p><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>BERTScoreBERT bert BERTScore</p><p>n-gram matching metric </p><ul><li><p>semantically-correct phrases are penalized because they differ from the surface form of the reference.</p><p> In contrast to string matching (e.g., in BLEU) or matching heuristics (e.g., in METEOR), we compute similarity using contextualized token embeddings, which have been shown to be effective for paraphrase detection  </p></li><li><p>n-gram models fail to capture distant dependencies and penalize semantically-critical ordering changes.</p><p> contextualized embeddings are trained to effectively capture distant dependencies and ordering  </p></li></ul><p>1In machine translation, BERTSCORE shows stronger system-level and segment-level correlations<br>with human judgments than existing metrics on multiple common benchmarks.2BERTSCORE is well-correlated with human annotators for image captioning, surpassing SPICE.</p><h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><ul><li></li></ul><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><ul><li>Moverscore: Text generation evaluating with contextualized embeddings and earth mover distance  <ul><li>contextual word embeddings  metric.</li></ul></li><li>Putting evaluation in context: Contextual embeddings improve machine translation evaluation. In ACL, 2019.  </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Grounded Situation Recognition</title>
      <link href="/2020/03/31/Grounded-Situation-Recognition/"/>
      <url>/2020/03/31/Grounded-Situation-Recognition/</url>
      
        <content type="html"><![CDATA[<h4 id="Grounded-Situation-Recognition-Task"><a href="#Grounded-Situation-Recognition-Task" class="headerlink" title="Grounded Situation Recognition Task"></a>Grounded Situation Recognition <strong>Task</strong></h4><h5 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h5><ul><li><p>situation recognition task: </p><p><strong>Situation Recognition</strong> is the task of recognizing the activity happening in an image, the actors and objects involved in this activity, and the roles they play. Semantic roles describe how objects in the image participate in the activity described by the verb. </p><p>While situation recognition addresses <strong><em>what</em></strong> is happening in an image, <strong><em>who</em></strong> is playing a part in this and <strong><em>what</em></strong> their roles are, it does not address a critical aspect of visual understanding: <strong>where</strong> the involved entities lie in the image. </p></li><li><p>We address this shortcoming and present <strong>Grounded Situation Recognition (GSR)</strong>, a task that builds upon situation recognition and requires one to not just identify the situation observed in the image but also visually ground the identified roles within the corresponding image.</p></li></ul><h4 id="Challenge-of-Grounded-Situation-Recognition-GSR"><a href="#Challenge-of-Grounded-Situation-Recognition-GSR" class="headerlink" title="Challenge of Grounded Situation Recognition (GSR)"></a>Challenge of Grounded Situation Recognition (GSR)</h4><ul><li><em></em><strong></strong></li><li><em></em>GSR  role and groundings </li><li><em>Ambiguity</em></li><li><em>Scale</em>grounded entities </li><li><em>Hallucination</em>grounding </li></ul><h4 id="Situations-With-Groundings-SWiG-dataset"><a href="#Situations-With-Groundings-SWiG-dataset" class="headerlink" title="Situations With Groundings (SWiG) dataset"></a>Situations With Groundings (SWiG) dataset</h4><p><a href="https://prior.allenai.org/assets/project-content/gsr/gsr_banner.png" target="_blank" rel="noopener"><img src="https://prior.allenai.org/assets/project-content/gsr/gsr_banner.png" alt="SWiG examples">A sample of images from the SWiG dataset</a></p><p>We present the Situations With Groundings (SWiG) Dataset for training and evalutation on the GSR task. This dataset builds upon the <a href="https://homes.cs.washington.edu/~ali/papers/SituationRecognition.pdf" target="_blank" rel="noopener">Situation Recognition dataset</a> presented by Yatskar et al. The SWiG dataset contains approximately 125,000 images. Each image is associated with one verb. Three different annotators then label each <strong>entity</strong> in the frame associated with that <strong>verb</strong> and mark the <strong>location</strong> of the entity in the image. All three labels for each role are given in the SWiG dataset as well as an average of the three localizations.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Multi-task Collaborative Network for Joint Referring Expression Comprehension and Segmentation</title>
      <link href="/2020/03/30/Multi-task-Collaborative-Network-for-Joint-Referring-Expression-Comprehension-and-Segmentation/"/>
      <url>/2020/03/30/Multi-task-Collaborative-Network-for-Joint-Referring-Expression-Comprehension-and-Segmentation/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VIOLIN: A Large-Scale Dataset for Video-and-Language Inference</title>
      <link href="/2020/03/28/VIOLIN-A-Large-Scale-Dataset-for-Video-and-Language-Inference/"/>
      <url>/2020/03/28/VIOLIN-A-Large-Scale-Dataset-for-Video-and-Language-Inference/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Object Hallucination in Image Captioning </title>
      <link href="/2020/03/25/Object-Hallucination-in-Image-Captioning/"/>
      <url>/2020/03/25/Object-Hallucination-in-Image-Captioning/</url>
      
        <content type="html"><![CDATA[<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><ul><li>captioning task <ul><li>caption model object corresponding vision scene </li><li> candidate caption  gt captions candidate caption  image informationrelevance. </li></ul></li></ul><ul><li><ul><li>We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucination.  </li></ul></li></ul><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><ul><li><p> object hallucination </p><ul><li><p></p><ul><li> failure modecaptions is summaries<strong>objects.</strong> scene objects</li><li>human judgements captionimage content object*<em>Correctness is more important to human judges than specificity.   *</em></li><li>Many visually impaired who *<em>value correctness over coverage, *</em>hallucination is an obvious concern.  </li></ul></li><li><p></p><ul><li>object hallucination  caption model caption model</li></ul></li></ul></li><li><p></p><ul><li>captioning modelsobject hallucination</li><li><ul><li>(1) <strong>Which models are more prone to hallucination?</strong>  spanning different architectures and learning objectives.   <ul><li>object hallucinationCHAIR (Caption Hallucination Assessment with Image Relevance)  </li></ul></li><li>(2) *<em>What are the likely causes of hallucination?   *</em><ul><li>object hallucinationvisual misclassification and over-reliance on language priors  <ul><li>image and language model consistency scores  </li></ul></li></ul></li><li>(3) <strong>How well do the standard metrics capture hallucination?</strong>  <ul><li>object hallucination </li></ul></li></ul></li></ul></li></ul><h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><h5 id="CHAIR-Metric"><a href="#CHAIR-Metric" class="headerlink" title="CHAIR Metric"></a>CHAIR Metric</h5><ul><li>GT sentence  coco image segmentation to measure object hallucination</li></ul><p>  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1gd7d25xmjcj30h605k0te.jpg" alt="20200326152719.png"></p><h5 id="Image-Consistency"><a href="#Image-Consistency" class="headerlink" title="Image Consistency"></a>Image Consistency</h5><ul><li> <strong>caption model  image (alone) model</strong> objects </li></ul><h5 id="Language-Consistency"><a href="#Language-Consistency" class="headerlink" title="Language Consistency"></a>Language Consistency</h5><ul><li> <strong>caption model  sentence (alone) model</strong> word </li></ul><h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><h5 id="Which-Models-Are-More-Prone-To-Hallucination"><a href="#Which-Models-Are-More-Prone-To-Hallucination" class="headerlink" title="Which Models Are More Prone To Hallucination?"></a>Which Models Are More Prone To Hallucination?</h5><ul><li> evaluation metrics CHAIR metric object hallucination cider </li><li>1attention object hallucinationNBTevaluation metrics topdown-BB CHAIRpre-trained  detector  captioning dataset is in a same domain </li><li>2 cider hallucination </li><li>3LRCN Model  FC Modelobject hallucination time step object hallucination </li><li>4the GAN loss actually helps decrease hallucination.  the GAN loss encourages sentences to be human-like</li><li>5CE loss: beam size 5, object hallucination  lower beam size self-critical loss: beam size sometimes leads to worse performance on CHAIR.   object hallucination </li></ul><h5 id="What-Are-The-Likely-Causes-Of-Hallucination"><a href="#What-Are-The-Likely-Causes-Of-Hallucination" class="headerlink" title="What Are The Likely Causes Of Hallucination?"></a>What Are The Likely Causes Of Hallucination?</h5><ul><li><p>We rely on the deconstructed TopDown models to analyze the impact of model components on hallucination  </p><ul><li>  deconstructed TopDown models object hallucination due to access to feature maps with spatial locality, not the actual attention mechanism.  </li><li>LRCN Model  FC Model object hallucination time step object hallucination  fc_feature,  spatial feature, </li></ul></li><li><p>Investigate what causes hallucination using the deconstructed TopDown models and the image consistency and language consistency scores. </p><ul><li>We note that models with less hallucination tend to make errors consistent with the image model, whereas models with more hallucination tend to make errors consistent with the  language model.  object hallutition models Image </li><li>Robust split modelslanguage consistency  Karpathy splitmodels image consistency  Robust split  novel compositions of objects at test time. language prior.</li></ul></li><li><p>FC model image/language consistencylanguage model  image model </p><h5 id="How-Well-Do-The-Standard-Metrics-Capture-Hallucination"><a href="#How-Well-Do-The-Standard-Metrics-Capture-Hallucination" class="headerlink" title="How Well Do The Standard Metrics Capture Hallucination?"></a>How Well Do The Standard Metrics Capture Hallucination?</h5></li><li><p> standard metric  CHAIRs   pearsom correlation coefficient  SPICE </p></li><li><p>object hallucination can not be always predicted based on the traditional sentence metrics.  </p></li><li><p><strong>standard metrci </strong></p><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1gd8997jm24j30gi08375g.jpg" alt="20200327100117.png"></p><p>automatic metric  human judgement /1-CHs/ 1-CHi human judgement  <strong>CHAIR is complementary to standard metrics</strong></p></li></ul><h5 id="Does-hallucination-impact-generation-of-other-words"><a href="#Does-hallucination-impact-generation-of-other-words" class="headerlink" title="Does hallucination impact generation of other words?"></a>Does hallucination impact generation of other words?</h5><ul><li>Hallucinating objects  object hallucinated word words.</li><li>TopDown  TD-Restrict We find that after the hallucinated word is generated, the following words in the sentence are different 47.3% of  the time.  </li><li>hallucination words language prior(hallucinating a cat leading to hallucinating<br>a chair  )hallucination words </li></ul><h4 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h4><ul><li><p>the popular self critical loss increases CIDEr score, but also the amount of hallucination. </p></li><li><p>CHAIR complements the standard sentence metrics in capturing human preference( judgements ).  </p></li><li><p>Models with stronger image consistency frequently hallucinate fewer objects, suggesting that strong visual processing is important for  avoiding hallucination.  </p></li><li><p><strong>Advises for captioning task:</strong> CE-loss/ standard sentence metricsobject hallucination  image relevance </p></li></ul><h4 id="yaya-"><a href="#yaya-" class="headerlink" title="yaya "></a>yaya </h4><ul><li><p></p><ul><li>(1) machine generated caption objects which have been occurred in the vision scene</li><li>(2) machine generated caption </li></ul></li><li><p></p><ul><li>object hallucinationCOCO80candidata caption token COCO 80</li><li>GT sentenceslist  </li></ul></li><li><p>GVD </p></li><li><p>the image consistency and language consistency scores.</p><ul><li></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP:  and </title>
      <link href="/2020/03/24/NLP-%E8%87%AA%E7%BC%96%E7%A0%81-and-%E8%87%AA%E5%9B%9E%E5%BD%92/"/>
      <url>/2020/03/24/NLP-%E8%87%AA%E7%BC%96%E7%A0%81-and-%E8%87%AA%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://www.infoq.cn/article/4SRM7UMVS4GdD9A90wff" target="_blank" rel="noopener">https://www.infoq.cn/article/4SRM7UMVS4GdD9A90wff</a>      </p></li><li><p><br><a href="https://www.infoq.cn/article/4SRM7UMVS4GdD9A90wff" target="_blank" rel="noopener">https://www.infoq.cn/article/4SRM7UMVS4GdD9A90wff</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VIFIDEL: Evaluating the Visual Fidelity of Image Descriptions</title>
      <link href="/2020/01/16/VIFIDEL-Evaluating-the-Visual-Fidelity-of-Image-Descriptions/"/>
      <url>/2020/01/16/VIFIDEL-Evaluating-the-Visual-Fidelity-of-Image-Descriptions/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>BLEU, ROUGE, Meteor, CIDEr   condidate referencesurface-level  n-gram  references  reference metric reference Meteor  languageSPICE and BAST  exact string matching parsers, semantic role labellers, tailored rules, </li></ul><h3 id="-reference-description---image-description-"><a href="#-reference-description---image-description-" class="headerlink" title=" reference description   image description "></a> reference description   image description </h3><ul><li> reference <strong></strong></li><li>reference description <strong></strong> image  image content <strong> object labels </strong> </li><li>references </li></ul><h3 id="-object-information--"><a href="#-object-information--" class="headerlink" title=" object information  "></a> object information  </h3><ul><li><strong></strong>  multiple descriptions   image   descriptions image description </li><li> object imformation   predicted objects  object annotations</li></ul><h3 id="Modelling-object-importance-with-reference-descriptions"><a href="#Modelling-object-importance-with-reference-descriptions" class="headerlink" title="Modelling object importance with reference descriptions"></a>Modelling object importance with reference descriptions</h3><ul><li><p>human reference guidance   </p></li><li><p> CIDEr  human reference consensus   </p><p>1reference object  <br>2word embedding word matchingeg: n-gram   </p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TIGEr: Text-to-Image Grounding for Image Caption Evaluation</title>
      <link href="/2020/01/15/TIGEr-Text-to-Image-Grounding-for-Image-Caption-Evaluation/"/>
      <url>/2020/01/15/TIGEr-Text-to-Image-Grounding-for-Image-Caption-Evaluation/</url>
      
        <content type="html"><![CDATA[<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li><p> automatic metric  gt  pred sentence 1 references   fully cover the image content2</p></li><li><p> TIGEr1 pred caption   image content 2 pred caption  gt caption </p></li><li><p>1   pred caption  gt caption  image-text grounding model  grounds the content of texts relevance ranking  distribution of grounding weights</p></li><li><p>2 pred  gt caption  n-gram matching</p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</title>
      <link href="/2019/12/20/Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects/"/>
      <url>/2019/12/20/Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects/</url>
      
        <content type="html"><![CDATA[<ul><li>ICML 2019</li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li> </li><li> graph vectorgraph </li><li>  graph vector  cross graph matching vector  graph vector  graph similarity.</li></ul><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><ul><li>Graph Edit DistanceGEDgraphG1, G2, edge(i, j)  edge(i, j) graph  GED=1 </li></ul><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1ga3ats0xyzj308p07jaaw.jpg" alt="20191220170651.png"></p><ul><li>graph  graph edit distance<code>positive pair:GGG1</code><code>negative pair: GGG1</code></li><li>positive pair  graph label=1; negative pairgraph , label=-1</li></ul><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1ga3b3udt8bj30pe0bsgnq.jpg" alt="20191220171642.png"></p><ul><li><p>graph graph vector vector space similarity</p></li><li><p>graphcross-graph matching vector <strong>discriminative</strong>  graph representation graph </p></li><li><p>yaya:  <code>difference between node_i and its closest neighbor in the other graph</code>    <code>cross-graph matching vector</code> </p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Quality Estimation for Image Captions Based on Large-scale Human Evaluations</title>
      <link href="/2019/12/12/Quality-Estimation-for-Image-Captions-Based-on-Large-scale-Human-Evaluations/"/>
      <url>/2019/12/12/Quality-Estimation-for-Image-Captions-Based-on-Large-scale-Human-Evaluations/</url>
      
        <content type="html"><![CDATA[<h3 id="Quality-Estimation-QE-of-image-captions"><a href="#Quality-Estimation-QE-of-image-captions" class="headerlink" title="Quality Estimation (QE) of image-captions"></a>Quality Estimation (QE) of image-captions</h3><ul><li>Quality Estimation automatic metric  ground-truth references unseen images which dont have gt sentence     </li></ul><h3 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul><li>1 Conceptual Captions dataset   image-captioning model  cococaptioning model captioning model image feature extraction modelobject detectionobject caption decoder    </li><li>2 image-captioning model image  sentenceimage     </li></ul><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul><li><p>1 image-caption pairs  crowdsource.google captioningimage-captioning pair 10     </p></li><li><p>2 rating image-captioning pairs  unique image10 using the equation y = round(mean(ri)  8)/8.     </p></li></ul><h4 id="QE-Model"><a href="#QE-Model" class="headerlink" title="QE Model"></a>QE Model</h4><ul><li> QE task image-captioning model   </li><li>1image-captioning model<strong>Confidence-based Features QE Model</strong><br><img src="http://ww1.sinaimg.cn/large/006uWRWVgy1g9txhzr2swj30yc0i642k.jpg" alt="20191212143453.png"></li><li>2  image-captioning model<strong>Generation-independent Bilinear QE model</strong><br><img src="http://ww1.sinaimg.cn/large/006uWRWVgy1g9txhzmt4rj30xs0apq5u.jpg" alt="20191212143515.png"></li></ul><h4 id="Spearmans--Analysis"><a href="#Spearmans--Analysis" class="headerlink" title="Spearmans  Analysis"></a>Spearmans  Analysis</h4><ul><li> gt sentence  unseen-image caption captioning </li><li> machine learning metric similar to human evaluation trained-metric</li><li>predict image-caption pair  Gt:  </li><li>Spearmans correlation.  <a href="https://github.com/ShiYaya/spearman-rank" target="_blank" rel="noopener">my github explanation</a></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pth: save in py2, but load in py3</title>
      <link href="/2019/12/11/pth-save-in-py2-but-load-in-py3/"/>
      <url>/2019/12/11/pth-save-in-py2-but-load-in-py3/</url>
      
        <content type="html"><![CDATA[<h3 id="torch-load-pth-UnicodeDecodeError-39-utf-8-39-codec-can-39-t-decode-byte-0xba-in-position-0-invalid-start-byte"><a href="#torch-load-pth-UnicodeDecodeError-39-utf-8-39-codec-can-39-t-decode-byte-0xba-in-position-0-invalid-start-byte" class="headerlink" title="torch.load(*.pth) UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xba in position 0: invalid start byte"></a>torch.load(*.pth) <code>UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xba in position 0: invalid start byte</code></h3><ul><li><p> python2 python3</p></li><li><p>()    </p><p><a href="https://github.com/CSAILVision/places365/issues/25" target="_blank" rel="noopener">https://github.com/CSAILVision/places365/issues/25</a></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools import partial</span><br><span class="line">import pickle</span><br><span class="line">pickle.load = partial(pickle.load, <span class="attribute">encoding</span>=<span class="string">"latin1"</span>)</span><br><span class="line">pickle.Unpickler = partial(pickle.Unpickler, <span class="attribute">encoding</span>=<span class="string">"latin1"</span>)</span><br><span class="line">model = torch.load(model_file, <span class="attribute">map_location</span>=lambda storage, loc: storage, <span class="attribute">pickle_module</span>=pickle)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong></strong>   </p><p>1 python2  pickle   </p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tmp_data = torch.<span class="built_in">load</span>(model_file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'tmp.pickle'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> <span class="built_in">file</span>:</span><br><span class="line">    pickle.dump(tmp_data, <span class="built_in">file</span>, protocol=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>2python3pickletorch.load</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'tmp.pickle'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> <span class="built_in">file</span>:</span><br><span class="line">    tmp_data = pickle.<span class="built_in">load</span>(<span class="built_in">file</span>, encoding=<span class="string">'latin1'</span>)</span><br><span class="line">    </span><br><span class="line">torch.save(tmp_data, tmp_model.pth)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video</title>
      <link href="/2019/12/02/Weakly-Supervised-Spatio-Temporally-Grounding-Natural-Sentence-in-Video/"/>
      <url>/2019/12/02/Weakly-Supervised-Spatio-Temporally-Grounding-Natural-Sentence-in-Video/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>ACL 2019</strong></li></ul><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li><p>image groundingregion</p></li><li><p><strong>weakly-supervised</strong> video grouding12video-sentence pairs fine-grained regional annotations video grounding grounding</p></li><li><p> groundingsentence: A brown and white dog is lying on the grass and then it stands up.  dogobject</p></li><li><p>video grounding weakly-supervised <strong>weakly-supervised spatio-temporally grounding sentence in video (WSSTG).</strong>    </p></li></ul><h3 id="Weakly-supervised-spatio-temporally-grounding-sentence-in-video"><a href="#Weakly-supervised-spatio-temporally-grounding-sentence-in-video" class="headerlink" title="Weakly-supervised spatio-temporally grounding sentence in video"></a>Weakly-supervised spatio-temporally grounding sentence in video</h3><ul><li>Specifically, given a natural sentence and a video, we aim to localize a spatio-temporal tube (i.e., a sequence of bounding boxes) ,tube  instance</li><li>yaya: video-grounding weakly-supervised1noun2 spatial-temporal tubebbox</li><li></li><li>1video2bbox, videotube,objecttube</li><li>compared with 2: different from 2whose text input consists of nouns/pronouns and output is a bounding box in a specific frame, we aim  to ground a natural sentence and output a spatio-temporal tube in the video. </li></ul><h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><ul><li>weakly-supervised spatio-temporally grounding sentence in video</li><li>methodAttentive interactor tube(instance)  sentence diversity loss reliable instance-sentence pairs  unreliable ones</li><li>VID object detection dataset tube(instance) description</li></ul><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h4><ul><li>  a natural sentence query <strong>q</strong> and a video <strong>v</strong> spatial-temporal tubetube  instance</li><li> video-sentence pairregional annotations</li><li> Multiple instance learning problemvideoinstance generator3instance proposals natural sentence query  instance  </li></ul><h4 id="Instance-Extraction"><a href="#Instance-Extraction" class="headerlink" title="Instance Extraction"></a>Instance Extraction</h4><ul><li><strong>Instance Generation</strong>   faster rcnnobject proposalsNproposal  3Nspatial-temporal tube</li><li><strong>Feature Representation</strong> I3D-RGB I3D-Flow frame-level RoI pooled feature   </li></ul><h4 id="Attentive-Interactor"><a href="#Attentive-Interactor" class="headerlink" title="Attentive Interactor"></a>Attentive Interactor</h4><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g9io2sodynj30i40hk0v9.jpg" alt="20191202204720.png"></p><ul><li>1 sequential visual features  sequential textual features LSTMLSTMsteprepresentationvisual feature  sentence representation</li><li>2visual feature sentence key  valueAttention<strong>visual guided sentence feature</strong>attentionword  </li></ul><h4 id="Matching-Behavior-Characterization"><a href="#Matching-Behavior-Characterization" class="headerlink" title="Matching Behavior Characterization"></a>Matching Behavior Characterization</h4><ul><li> <code>i-th</code> visual feature  visual guided sentence features  </li><li>step instance proposal  sentence </li></ul><h3 id="Training-Loss"><a href="#Training-Loss" class="headerlink" title="Training Loss"></a>Training Loss</h3><ul><li><p></p></li><li><p><strong>ranking loss</strong> aiming at distinguishing aligned video-sentence pairs from the unaligned ones.  video-sentence</p></li><li><p><strong>novel diversity loss</strong> to strengthen the matching behaviors between reliable instance-sentence pairs and penalize the unreliable ones from the aligned video-sentence pair.  videotube  sentence tubediversity</p></li></ul><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><ul><li>video N tube proposalproposalGT overlap4overlap </li></ul><h3 id="Yaya-Analysis"><a href="#Yaya-Analysis" class="headerlink" title="Yaya Analysis"></a>Yaya Analysis</h3><ul><li><p><strong>point</strong></p></li><li><p> detector object proposal</p></li><li><p> tube proposal</p></li><li><p> sentence  tube proposal </p></li><li><p> rank loss novel  diversity loss</p></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li>1De-An Huang, Shyamal Buch, Lucio Dery, Animesh Garg, Li Fei-Fei, and Juan Carlos Niebles. 2018. <strong>Finding it: Weakly-supervised reference-aware visual grounding in instructional videos</strong>. In CVPR. </li><li>2Luowei Zhou, Nathan Louis, and Jason J Corso. 2018. <strong>Weakly-supervised video object grounding from text by loss weighting and object interaction</strong>. BMVC. </li><li>3Georgia Gkioxari and Jitendra Malik. 2015. <strong>Finding action tubes</strong>. In CVPR, pages 759768. </li><li>4Masataka Yamaguchi, Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. 2017. <strong>Spatio-temporal person retrieval via natural language queries</strong>. In ICCV. </li></ul>]]></content>
      
      
      <categories>
          
          <category> Visual Grounding </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Viusal Grounding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Finding It: Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos</title>
      <link href="/2019/12/02/Finding-It-Weakly-Supervised-Reference-Aware-Visual-Grounding-in-Instructional-Videos/"/>
      <url>/2019/12/02/Finding-It-Weakly-Supervised-Reference-Aware-Visual-Grounding-in-Instructional-Videos/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Generate Grounded Visual Captions without Localization Supervision</title>
      <link href="/2019/12/01/Learning-to-Generate-Grounded-Visual-Captions-without-Localization-Supervision/"/>
      <url>/2019/12/01/Learning-to-Generate-Grounded-Visual-Captions-without-Localization-Supervision/</url>
      
        <content type="html"><![CDATA[<h3 id="ICLR-2020-under-view"><a href="#ICLR-2020-under-view" class="headerlink" title="ICLR 2020 under view"></a>ICLR 2020 under view</h3><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li><p>captioning Groudpriors</p></li><li><p> groud 1 language model  attention  regionregion  [1] attentionregion2 attention RNN  hidden_state RNN individual word  </p></li></ul><h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><ul><li> GVD annotation bbox  decoder + localizer + redecoderself-supervision</li><li>infrequent word</li><li> object class  grounding accuracy sentence grounding accuracy</li></ul><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><ul><li><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g9heo6n8glj318k0lp0ze.jpg" alt="20191201183637.png"></p></li><li><p><strong></strong></p></li><li><p>1 encoder-decoder ~30epoch</p></li><li><p>2 a<strong>re-localize</strong>: language_lstm y1, y2, , yT attention regionattentionstepattentionmotivationattentionindividual word bstep attentionattention_region language_LSTM<strong>sequence of word</strong></p></li><li><p>loss </p></li><li><p>visual-words  non-visual-wordsre-localizeon a image grounded region  eg, non-visual words reconstruction loss, localized region representationinvalid representaionFlickr30 caption and ground activitycaption ground</p></li><li><p></p></li></ul><h3 id="Measuring-grounding-per-generated-sentence"><a href="#Measuring-grounding-per-generated-sentence" class="headerlink" title="Measuring grounding per generated sentence"></a>Measuring grounding per generated sentence</h3><ul><li>Such metrics F1all, F1loc are extremely stringent as captioning models are generally biased toward certain words in the vocabulary, given the long-tailed distribution of words. </li></ul><h3 id="Analysis-Grounding-performance-when-using-a-better-object-detector"><a href="#Analysis-Grounding-performance-when-using-a-better-object-detector" class="headerlink" title="Analysis:  Grounding performance when using a better object detector."></a>Analysis:  Grounding performance when using a better object detector.</h3><ul><li> Flickr30k Entities  better detector  grounding</li><li>1 GT box (ubrealistically)  caption metric  grounding accuracy</li><li>2 Flickr30kdetector visual genomecaption metirc the ROI features and their associated object predictions    the annotated object words  diverse captions captioning </li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Abhishek Das, Harsh Agrawal, Larry Zitnick, Devi Parikh, and Dhruv Batra.  <strong>Human attention in visual question answering: Do humans and deep networks look at the same regions?</strong>  Computer Vision and Image Understanding, 163:90100, 2017. </p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vatex_challenge_solutions</title>
      <link href="/2019/10/20/vatex-challenge-solutions/"/>
      <url>/2019/10/20/vatex-challenge-solutions/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX19xC27VYE27o0kLd3c2+fJMnnf2ULfHyWBkUpC/28wvwECO1wRaPZzlsMymHwuK5qQzlWGpxT3NfXls0DTebsysOgkNYMUc3oWsQKypE3hcnpyiPnQBNEz/kgV6VErzr0XjMWCT7LikpceCpdIH6bAAZW8C4swCcankFwfi3ewDGbS+pGXUQh0URR716dFpuL73+sQWOr8MatajDF316/cghMUonpAH4Hjb3v9pIyX4b9E52lyEWKYpQMYJeZe+pSEu1E3gsfK/RCQtYKC5zwzKYQ5mK2SsgHErnmDVbAs2biTDYcBB9ky0ESHaS2XvuQ7tGCsV0QUrHB+MrvhnOO0P4nINVv1FEw6p33Ej+oBEJqhg/uOKSOKzUVl57JsJDN60ZKTBYkKHSMQDbMouwVcQCcP2qijwPT0Qdzfh6Ilv6v/ybj6A0sqyM/eqArnwLUbNq/1BbiGO9Vs2rdJ7yPfkvsR468nZMweZUGr8xSU/bEo9ZHxN7NXTGp5L2YxHqUCe861rX2quq3gAlqtMvVmal0v19LhAwsY+GtMWe1jBk5HFhqMS0j/YWPOjpRwBBVcAdpjpDX4A+n/kzo8ikeZUSuE7rwsf49shcUfBFBtsMdP6+srBYOJF0Ih1Zem8c1OcTcIe6Arnep17u3Zz0DGeBSKKDsXXAPTUEA6oXTKCWLFeSV+ASCp0BKn+rKtJoNJh6dtlGfEsDNJ7wV4Mniwdh7Q5Z1uUbMXNvQFfQuiKpCuc+YkCISdjlew1C19mo5S14N8qVHptG93Ae1d8bBtQirdqqWDD0+nCADL+SGquVIUkr6VFqXuRfM2kOuxbT2dD2j0h/ZJ4Gg1qT3dfR1B5PnSydklOzx/F877/M9qooAT7y22kZlAs6/mTESMF0riH1BDH6RXgtRK2gED1v5NNizyettTdYgAJ4Q6hXa3evaAJKgJdsZFh3c8Pj3S9GsNkw2mcK+P5tcqGKQqYVOzKOueHuYXfAxfysC70d+q+iy9ByVUgkG7kMnkpA6CgXWpWrhOFaG/VzYdMwy4tZsHgrudzq4If2i2VjCt38ewiaLeGgg3NdzvND69OxBa524ElrJaXjQfH077FSl3gwh1nJ1yZojalRtJE154CU6gfhfdpfEYiaXsFG3CLXbPkXT4OOXfTAsBb5WLeV3HvfP0+NRxq8/PZJlziZq+YwMiQaLcxogm/wUEFiG0QohOX2/qoc5uestelXe9T8m1xxHz/xko3W4uO/cF6HkABglRWJMS0xbvgnitNEtWfbBVkuBz2FZbraGDDTwWXJ3I0WZej8g5xNPAhc112f4kX0cjTvWW7xVj8x1gagX5lToTvYka4AZ2H9jgDTHOBuOSOAnseTtHSH2RmXzUwb60dRiZhsNDu2L2Wx3WjL9l05d+Y3SeIg+q/q61VnDOGT6QWZXWFBq3dkIU3EpuoLBSEFArerWDjLT0hW9o/80FkQ8Lp8Qrl78ya+ud9Nhw4M2vbvjGz+OlH9+cYv2Ia1h/jmSGQI/+IJpme86BAZFepyr5s6i5qtvA/MjmFJQNP67YluCgnGT9aC2vrs7zFJQJZZWONBliFoRCiQGxf0NWhSOnI2e3ZWV6m4NxMa/vK238LWBp59+tt3DIDvaywdVhofJzy9QThopIJQ6tAfW6s3UZ7D9JGRp4pPM3RvZN+tJSPdzPRnK+FGV+1wyWjxbdUWF3dGokU6UXKhVycwv+MlWxisEAHIAejcsrwwTU5cXrD98kqBHXKO4FN58gzlxB80QOVGLynWYm7GZnalv61AVkaNQ/+hQm+utePZI5KD175WkOFseia6nryN5gtKPNb/Ykx4H+3bgKR8WKLKBYnwAPpomMf4rchMU1Af86CpbrLO7jPnJ/y6sC3/01ivyWr78HFWAh6YJthOfT6x/HajOeqcErY5XZ54s29c7R4n1B7cU//GosdNilrIOhb8xJIj5KNsmUljUyPuUmqJzz7TpFPDyW+E4Qn0TC1MCwCN7wNerw0xY2BiuELTCpc39WB0bG6YdjhXAGJlr2nV+21MNMTl6sKObMwQQqzDPZKmNAAa3DOtvrrCPGbNEF6Eq/L5sjP3lWdXkEpqe9MsfngoQ9+upkubU/ErqJLKMGKvHAALiUCWffXX+4o3zD9Fny8zOsRTIy6Kb3URQQ12E27j/YIY0MzLIyyftzEajuFv+u9xDztazJl9C/S/CgSt4UoH37JPGMcy+e/rX/8N7BRzaVu47eckW9LDi7OlXxwwTS8uNSsWszq8RJhC3uJlOcEZJkRIkYHHmXyHOAWzLuJwYXmHWRU40btsRP+nnkTQu4iR1EklKMnU8mqKwaOMnvnlHg/Y9okDGjg/Y3vY9OU/Hlyd+dcouI/6HP9aEXTtNsJiT+06IPeDiGi4xyrTbj0/TjCfxJRUquuvOKb1FKLqgoCPX2XzZkjyNcWach7lrPX7RFgddIS4eP2kw3rj1U7dUW4SXmIandBzM0eMVv+tJtB+OB8lLiOkGncXUz+o4ZasUNC8awyV4RSgs8z6BVnenXPkEVrcBvREybmQzmRo+vD1UINquoTLIHEhBE+NDVe1GYOXW90kGeSKX5Rno1GbVlunQd80iqk1KvU+di8I97eNxZLkjcim0VP+pwYaU3f9XpV8+alcKKgsPBGTI4vPo6ytYDNMJW4yq0DruZ4DPdWI+MlogKNvx/VXASZsffR/JPgIEz3pSkv414JMRmxFddI7BVQcBVhMmSJZRSMatsHJfIA+HJYSqlM2yXExVqeIbXBg1TcTPU0dxx/aazQTMOjKAZQchblyM6HzAqq4D+PBOBaI4KY5vQIMLn35blLYwqNi9vjcyO34eboIBZEMhVFSVdmf4uNUpZcIFDw8NUT1nPa+8sGYckP4MU3Sv++U+kbPEq5Byr9PjTBFzBH6EKlnrz7+3VyoE/xQzpFgpm4gwvOGwqwFRWVzY1z82zk81aUUJzO9L34JRaKxsv0vbO22Lk6fhiRn/teerf/xWgKW6Uw44s3hp/rCXU2xvZArh4MeVWVj3Yw+p7c94G5UJcjapqRNsY1u7UwKRqPuBA2B9AzR3mpZjHq0gNVPdQbUKSQuiXUDhvv9DRBHftDKoeRBt97Cm7M66Z5kad5GuRDIfdCcFVeozeE/Sz0ebSKeZcjFrjnDGbl+HVCDynpa2ub296vxMlVDM+LNvzedgyyn7pIl7z664iULKncdxVS7JzFHlZ/wY+ZD8fXUNLqxJ8Ki0PczuwLJ22PzhH8cfierZBwYsQVtWVirlHgcYTKGdHjw5bPChxmyWYofACpHtECgE4WlNyyGCsJsFkKDFd45rSr0vavrdN0pyCYKf/MWas4WqTdUwvM1aOVL2c8XlxiLKDBLjl2pO6lbD0VEy3gTfPkRLy9/q1Qkh7oxdtZeiUB43Tti8In57cQlHQNKa6ot1KKOcigMvQPw4YPgztcymYy5AxtX+zAvTM0TtImzJnlUfsCDBSLAb7/yWsfEIixAnWy31s1DOxedVB4qPyrU9DABAG2Ir0eYxFejSEw6mXO7ISlJfTZDNUqXA9KzSgz+e2/aRYF2+ezTLxT3G0s1AdgPUALqcEhJoWDQLJFAib+6IrN2tx3eTqjRB6fxqp4QF92a0C5FNmuy3OnRuf07C88vVgh96eUJ/ogF76SDoFOWdnJ04h3loHcpnnDzEl4mlMLuMceagA4OQHbWSRlY9ehyH1wdPvpoIkqoiIThBZ3P5EWwJVwFPzSBUvP/2UoT63+CZI0zWJLLDo/XOblSSCPDlNmg+ZW+YzMy47hNxFCAfWYjdvUV/wtTjn30D5078/qOgSm5JLqffoBOIS+BNqYrJBDEgX2Ygihgc/a9XHnvAFWqZxag39XMW9Y5+XmoL034rCFtLgY/mYh+qls2Fw110AvoGUIP8mmnvJmrdImRiLVmnjbkaZ8POyK+cqASvlW9enHbfMg2Qq1Zg/IYfVtmq0FV6pddfJ98sL1yZTMUuPnbOCvbUoZgJUVBsI5Jt7WHMkSdNNwbQ4MfCuUirUwn8fzVHKWfYKLyN9EfMvJ10dpM14qGih7K0r39MJNR3gHtRGTXdqgTsg+yxiXx/BoV36/e5Lpc3D1PT627cJ8WM19P5PVTM1C5y3i67tdSrTyXOvdmqYuNf5Z1cMg8p1hk8M0mou73ryVYyZioCNZ36XE3U5ahd4JS8oTG0LIRQXY+/l7qcMT5i7dQsBki/CkjFq2rhpZZA9H8TGuOtPF6utdcy7Dx8/MZ/BIAGWb/5x+nMgcO+tLstwDup+99qcm2Q/94WlMKzra1RHOVseX1fhBK3kR8znMvhjPYUh9HxxLocMSLfPihPmz1AqWXNZ6hAdequryi83H9gVUqOLS1F0edG9/xYDwkRbDoZe+Ar0CQocos7dpVy60ZKddm1ecRkx/W0gCRyL+3brzANbjly1J0w72rsR7c1a1vU8ojc26D1MAjfDLnb/OtQe9AE/FXzzgaxUdR5x97wEC71Kne1mK3NDYzh6drdXMHP58EcxF4GdX5mmOHUMeG+NM7o76Opml2NKjs1wR93y/KDb+0uWseQ7SvataGi7FYGZ+1741lOZMemEkF0Dkz7KBcKRdgUUBbTa1VCeSDiMKy/JDG5tRx9gvYGaL643gvhAJnLCFogRznBJcdaYnnw7WsRBjeMsHl8ID20rvtHyF7madRZP+1ubIv1O5fiX6A/FrkTP7AET/rfHAmGR1viTtDQBb1LEl4XarOOVPjHgV1M4k/uR/EhqgFZUuAGNXE2h1d4PVZSXd0vpoYFWkt/bvWnF5phH+gxHGVodQ4Les/X4G1vtTrBLFGZ0OAqSDnwycXXaSIv50flhwu4GxmZu6xQaOm6vCrUNmOkdJS4SVt29jqdWagXDQPn2DtO6//y3u8XVYdmDHW56Cc3etm/CdkAhdMlUBYrhGoeFiFGGYJgJO+8kZwR6TqqXVKVyzvsm6N510LcUksx2EbNhkdUX3Azn7Wt4tv4WinTJxoJyLHptsPwT9/wPwsOK0u0Wasvciy9gF/lL0fy4hfWr/Vmi++Pxrun1mZY4yrPoafpJWukOumtso/5pGLFVmqNnt3YrGgl0RnIDQyF8r/CUsn5tMcZmOATzgK+ydZgrPrJEVUCJ5X5SWpSj0MMfBMITdjwkVJWMquUrO/uU7/b6YzP6tvtEnMtyhLS+bYdDYxTzbjR8UtAH8tgY22/0ZuZU2leNcuKJUnKBuqBErDVJXWtUbg9Jcv54EHfBGez35w1viQVBRyvcs9yGvLuzbw3PARC6VIpqQuCXu9F8ijQRlGal8Q+kGT/UcmgHAhfoPkHP5Z7aVWbeSWAU9gmO7zMYhvJ1kDDu9Rjk6Z7ZxC5gOBbkJAy6lHneAqcxsrGN1UPKdk4x1C9cRqd9as8mO2gN3dS4ILsZFNbqwg9er7UYfd4rVT6C7bN56iMHPD7McB+ID2fRhQDBs94furYdjZiW73+oZCLGcbOO1oclGEl6LNjLjnjxJVKJnL+eINHswy+QKWcX9Rn88DfM0kUiQFjCyc9ppx3MlaUplEY4MjfJmpzTNi8zdtpgNTwAxTs3JDPd2Y9/tYgp761WZE2OVvUf6upQM8Ovs4sVdY3ICvnqAzrVdR5IYIbBoxKJAr9lzQzYDpgSgUzgOhMH/jHX6qU369PsKmP/7c2yECQuSCuolOyShLhVP2QST0uBDi/s46nWKeYpOE2GHKvtQG5ZsbsBA0KT9IFX0q3qWXMO4Xj7KFDSl7uPpw6bJK1Qg2c/njzXJWvW8HEZvVZRM2SMe7i/YxVxGZWWARfHvcckXicu4rRMCUqWyvNR7s7Ssl5o9hCqEAJVjYzBLieqq1lxKkDGXUDsC828oU1V6mnN1zzQHagSJIZyNCJEOcYXb6pksBRxjOtz1rPZOPw9aGrjEGWGROyoTHfbglr2Ie9d21zWgqJz0mO7nax/ULzZyVQRtyO7vsjfxEJnU4M3aKc03i/9EsB4S7/Jd+lGuLqYsbX0tS1lyc1rNBDLkL6CZMt/ob7495OBSJzlP4hIaW8A/iTFbgxoskNi+pie2dNwHNwz7Q/bOLzYxwL6OqIl+puqUK4DTsX15O9LZttBNFWLOCBts9LbUH3hg2uoQUbVDIy2YagwgY/kq9BHsp6/zKKGsq41UCsFXN/o3AVovU/T7KS0cGaJpTImSaGHsCxn2ChXENw0Hbs1IlbbgVrcM5GtQ6a06HLT4qLMuvLvinkt0CSgWy/21wFMAIGpqUk8h6hqhHBaKXqNrM3G3MedUlUYv1RTutzAsbCj7thYz/MW+SZ+AxZkGZ0FrDlRXCaEhFNATgHLzfMbVTgv++gIxBM+NZMDo4Y/6ZpTN9Z4WZxXKEEqW/VL+wvsl0Xgy0EY60Uq+dy4tTmTTIN0sRHfym6IDbbkZkmgEb0c2tOO/Db/F2BGMXSxvXqiM3zkbwWsk80tdaKdaMo2v1J85ia/7prc333Gcu3/Bbm9y5Assa+I3TPNxi3pgNJFxX5xc9RumH11asFocrZLtp8aDTEr26/ckZt5bXBUcDji4K+UkA5qa7dkE4DCuLJ0Q9Qwj0wrLJvecVtBVpdifC/NtKQz9gWKIbYMaO6gxOEe1McQeOfH6aM2aU71iQQaOKc+z930WH22uCazxp2ffpuSlrkoMtZHFpCEBYQfVBgxF3SR9UZqtCJhtBHRYwbV9RkRR7QQjxfQUbxlMLcGyqsNMFIT1sEtCW4+WuP/v10HSrNe04EglzXB3aHXHuLY2JesYBeGFGN5K3sNBNfs4+53ujfmFgTYIhVedEDZJQ80Of++B+l50nH3cHIPBOoXCgY2PyP/Tn4URQlv1eXM1WkUGPq9yt4GF/Lf3hnXT491qumjCC26TYJNW/etSKdWzroLsSgyi5r8/XrPZpANQheqgKRZ2i/iNoqPOdoT7mPQ6UvQwLulmntpiGlvuCvyE5kRp7UsaoCdFz++CeH9jQsB4STR/sgOXJDnUBW84qEDvFTx2brEupXuMnQhO2IRVD3YxZv81fzDVces7b7e5h4YQ+WxXkKIa6Mfar5FvVAN2a3BJb3bguLQturo+EDQTAbFpaNdKDY3CuT93Ao5Lzh3ewrOo/EohThmFphFghbXzrQNuAbhjdOwnLhOvNmmXbHGO9mb8r1RCEejMRFuaNwExzcgVbm5gnFUT+GDMwshtjQrYPiuQ9dJ5K6JRbhpbx7+9QzcIoUKhY0oTev8PrKyQqReBN9iI7aP7vIdFGHv6v3FA3oZBg+z8DNDAEF8jc0XF6W0g/EToQjHlD9XLwncrwN1V2aK21Yy+GXsNiXkUUAkzSePqR68Fh2jCh38tyW+OBHmzF7Y4f6kma7tSs1hIqGZ9QOhvv4up2ewvphKO4PAkxq/6G4hEyMOJZi0t/RLbe5DYFDQHuIba3hHz3AsULu6KVlA365pWefba7kA/zJfIYWKVMQRoJ1LdPuTfj4HJyuzbjkWeu6dvO3HKI8VtvRrc+Q==</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch  </title>
      <link href="/2019/10/10/pytorch-%E7%B4%A2%E5%BC%95-%E5%88%87%E7%89%87/"/>
      <url>/2019/10/10/pytorch-%E7%B4%A2%E5%BC%95-%E5%88%87%E7%89%87/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li><p>object_feats.shape = [bs, 28, 5, 1024]video 285object, 1024</p></li><li><p>traj_idx.shape = [bs, 28, 5] frame 5object anchoranchor objects</p></li><li><p> object feature</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">traj_feats = object_feats.gather(<span class="number">2</span>, traj_idx.unsqueeze(<span class="number">3</span>).expand_as(object_feats))</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> objects position </title>
      <link href="/2019/10/10/%E4%BD%BF%E7%94%A8-objects-position-%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E7%9A%84%E8%AE%BA%E6%96%87/"/>
      <url>/2019/10/10/%E4%BD%BF%E7%94%A8-objects-position-%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E7%9A%84%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/09/23/%E5%AF%B9%E5%88%86%E7%B1%BB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E4%BC%98%E5%8C%96/"/>
      <url>/2019/09/23/%E5%AF%B9%E5%88%86%E7%B1%BB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/09/21/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E7%9A%84%E5%88%86%E6%9E%90/"/>
      <url>/2019/09/21/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E7%9A%84%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Neural Motifs: Scene Graph Parsing with Global Context</title>
      <link href="/2019/09/18/Neural-Motifs-Scene-Graph-Parsing-with-Global-Context/"/>
      <url>/2019/09/18/Neural-Motifs-Scene-Graph-Parsing-with-Global-Context/</url>
      
        <content type="html"><![CDATA[<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li> repeated structures </li><li>1object label relation label2image grapheg  XX has YY</li></ul><h2 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h2><ul><li> object feature  object label  relation label</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>video captioning </title>
      <link href="/2019/09/07/video-captioning-%E4%BB%BB%E5%8A%A1%E7%9A%84%E9%9A%BE%E7%82%B9%EF%BC%9F/"/>
      <url>/2019/09/07/video-captioning-%E4%BB%BB%E5%8A%A1%E7%9A%84%E9%9A%BE%E7%82%B9%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>objects</title>
      <link href="/2019/09/01/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%94%A8%E5%88%B0objects%E7%9A%84%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"/>
      <url>/2019/09/01/%E8%A7%86%E9%A2%91%E6%8F%8F%E8%BF%B0%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%94%A8%E5%88%B0objects%E7%9A%84%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<ul><li><p>CVPR 2018</p><ol><li>Fine-grained Video Captioning for Sports Narrative</li></ol></li><li><p>CVPR 2019</p><ol><li>Grounded Video Description</li><li>Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning</li><li>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning </li><li>Adversarial Inference for Multi-Sentence Video Description</li></ol></li><li><p>ACM 2019</p><ol><li>Hierarchical Global-Local Temporal Modeling for Video Captioning</li></ol></li></ul><h3 id="Grounded-Video-Description"><a href="#Grounded-Video-Description" class="headerlink" title="Grounded Video Description"></a>Grounded Video Description</h3><p><img src="https://i.loli.net/2019/09/02/Hvtk4BJVNQ2WwdM.png" alt="20190902104324.png"></p><ol><li><p>region feature</p><p> language lstm  region featrue, attention   cat[ fc, motion] features cat[fc, motion]attention</p><p>  cat[ fc, motion]  bias</p></li><li><p>region feature </p><p>R object detector   fc6  feature</p><p>Ms(R) object detector  fc7 feature ()</p><p>Ml  position embedding</p></li></ol><p><img src="https://i.loli.net/2019/09/02/y4JkxlmLQpqaj5c.png" alt="20190902105022.png"></p><h3 id="Object-aware-Aggregation-with-Bidirectional-Temporal-Graph-for-Video-Captioning"><a href="#Object-aware-Aggregation-with-Bidirectional-Temporal-Graph-for-Video-Captioning" class="headerlink" title="Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning"></a>Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning</h3><p><img src="https://i.loli.net/2019/09/02/TIP7Ww3FnLNKzvu.png" alt="20190902144125.png"></p><ol><li><p></p><p> encoder  object feature  frame featureVALD </p><p>  decoder object feature attention,  <strong></strong>objects attention N different objects instances attention objects </p><p> ojects, objects</p><p>  decoder </p></li><li><p>region feature<br> lstm lstmobjects featuresattention attentionframes featuresum<br>  motion feeture</p></li><li><p>region feature <br>  appearance feature obejct VLAD module</p></li><li><p><font color="#0099ff" size="5" face="">object feature  hierarchical attention <br>object </font></p></li></ol><h3 id="Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning"><a href="#Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning" class="headerlink" title="Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning"></a>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</h3><p><img src="https://i.loli.net/2019/09/02/T5AzpW8DHkVL2Oy.png" alt="20190902152617.png"></p><ul><li></li></ul><ol><li><p>region feature</p><p>  obejcts sematics embeddding vvdecoder</p></li><li><p>region feature </p><p>  object detector objetcs semantics</p></li></ol><h3 id="Hierarchical-Global-Local-Temporal-Modeling-for-Video-Captioning"><a href="#Hierarchical-Global-Local-Temporal-Modeling-for-Video-Captioning" class="headerlink" title="Hierarchical Global-Local Temporal Modeling for Video Captioning"></a>Hierarchical Global-Local Temporal Modeling for Video Captioning</h3><p><img src="https://i.loli.net/2019/09/02/m5xLQnzCJGsjWVc.png" alt="20190902161552.png"></p><ol><li><p>region features ?</p><p> encoder LSTMLSTM  frames features  c3d features LSTM</p><p>LSTM step, step  objetcsattention LSTMobjects    </p><p> <img src="https://i.loli.net/2019/09/02/q6XNP8iSVzekyCE.png" alt="20190902165813.png"></p></li><li><p>region feature </p><p>    objects features LSTM</p></li></ol><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li> objects feature decoder Top-Down Soft-Attention encoder </li><li>encoderLSTM attention  objects featuresVLAD   objects attention objetcs  position  label </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MAP(Mean Average Precision))</title>
      <link href="/2019/08/31/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E2%80%94%E2%80%94MAP-Mean-Average-Precision/"/>
      <url>/2019/08/31/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E2%80%94%E2%80%94MAP-Mean-Average-Precision/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/katherine_hsr/article/details/79266880" target="_blank" rel="noopener">https://blog.csdn.net/katherine_hsr/article/details/79266880</a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>-mAP</title>
      <link href="/2019/08/31/%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95-mAP/"/>
      <url>/2019/08/31/%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95-mAP/</url>
      
        <content type="html"><![CDATA[<p> from: <a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_9db078090102whzw.html</a></p><p>Multi-label   Image  Classificationmean  accuracymAPmean  Average  PrecisionmAPmean  accuracymAP</p><p>confidence  scorecarconfidence   scorecomp1_cls_test_car.txt20idconfidence  scoreground  truth  label</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQd58yJ15f" target="_blank" rel="noopener"><img src="http://s16.sinaimg.cn/mw690/002T2ChPgy6XQd58yJ15f" alt="img"></a> </p><p>confidence  score</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQd86isc4c" target="_blank" rel="noopener"><img src="http://s13.sinaimg.cn/mw690/002T2ChPgy6XQd86isc4c" alt="img"></a><em>precisionrecall</em></p><p>precisionrecall</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQdjij4Ae8" target="_blank" rel="noopener"><img src="http://s9.sinaimg.cn/mw690/002T2ChPgy6XQdjij4Ae8" alt="img"></a></p><p>true   positives + false  positives,cartop-5</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQdbTpla5c" target="_blank" rel="noopener"><img src="http://s13.sinaimg.cn/mw690/002T2ChPgy6XQdbTpla5c" alt="img"></a></p><p>true   positives42false   positives13196false   negativestrue  negativesconfidence   scoretop-5</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQdcMwKCea" target="_blank" rel="noopener"><img src="http://s11.sinaimg.cn/mw690/002T2ChPgy6XQdcMwKCea" alt="img"></a> </p><p>false   negatives916720true   negatives1,18,5,15,10,17,12,14,8,11,3</p><p>Precision=2/5=40%car5240%Recall=2/6=30%6car230%</p><p>top-5top-1top-NN20precisionrecallrecallprecisionrecallprecisionprecision-recallprecision-recall</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPgy6XQddBz7ze9" target="_blank" rel="noopener"><img src="http://s10.sinaimg.cn/mw690/002T2ChPgy6XQddBz7ze9" alt="img"></a></p><p>APPASCAL  VOC  CHALLENGE[0, 0.1, 0.2, , 1]recallrecall&gt;0.3precision11precisionAP11precision11-point interpolated average precision</p><p>PASCAL VOC CHALLENGE2010NMMrecall1/M, 2/M, , M/M,recallrr &gt; rprecisionMprecisionAP</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPzy76AuWjHOp29" target="_blank" rel="noopener"><img src="http://s10.sinaimg.cn/mw690/002T2ChPzy76AuWjHOp29" alt="img"></a></p><p>Precision-Recall</p><p><a href="http://blog.photo.sina.com.cn/showpic.html#url=http://album.sina.com.cn/pic/002T2ChPzy76AuH9Z6010" target="_blank" rel="noopener"><img src="http://s1.sinaimg.cn/mw690/002T2ChPzy76AuH9Z6010" alt="img"></a></p><p>APmAPAPmAPAP</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet</title>
      <link href="/2019/08/17/%E5%88%B0%E5%BA%95ResNet%E5%9C%A8%E8%A7%A3%E5%86%B3%E4%B8%80%E4%B8%AA%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E5%91%A2/"/>
      <url>/2019/08/17/%E5%88%B0%E5%BA%95ResNet%E5%9C%A8%E8%A7%A3%E5%86%B3%E4%B8%80%E4%B8%AA%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E5%91%A2/</url>
      
        <content type="html"><![CDATA[<p></p><hr><p><strong>ResNetWhy ResNet</strong></p><ul><li><p><br>  </p></li><li><p><br>   batch normalization yaya1</p></li><li><p></p><p>  </p></li></ul><p>*<em>resnet   *</em></p><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g62hrnrs6nj30h9048aax.jpg" alt></p><ul><li>yaya <br>  relu(x +  w1 x)<br>  relu(x +w2 relu(w1 x))</li></ul><p>       relu(wx) + x relu</p><p>*<em>    *</em></p><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g62hpvudvxj30iu0cc3zi.jpg" alt></p><hr><p>yaya /</p><ol><li>resnet train loss val losstrain lossval loss</li><li>resnet 1</li><li>FPNresnet desnet</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Batch Normalization</title>
      <link href="/2019/08/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Batch-Normalization%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96/"/>
      <url>/2019/08/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Batch-Normalization%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<ul><li> from<a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/8724433.html</a></li></ul><blockquote><p>BNBatch Normalization</p></blockquote><p>Batch NormalizationDLDLHintonPre-Train<strong></strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</p><p><strong>IID</strong>BatchNorm<strong>BatchNorm</strong></p><p>BN</p><p><strong></strong>DLReLUResidual NetworkBN</p><h2 id="Internal-Covariate-Shift"><a href="#Internal-Covariate-Shift" class="headerlink" title="Internal Covariate Shift"></a>Internal Covariate Shift</h2><p>BNInternal Covariate ShiftInternal Covariate Shift</p><p>Mini-Batch SGDOne Example SGDBatchNormMini-Batch SGDMini-Batch SGDSGDBNSGD</p><p><strong>covariate shift</strong><strong>ML&lt;X,Y&gt;XIID</strong><strong></strong>MLcovariate shift<strong>Internal Covariate ShiftInternalcovariate shift</strong></p><p>BatchNorm<strong></strong>Internal Covariate Shift</p><p>BNWhiten<strong></strong><strong>0</strong>BNBNBN<strong></strong></p><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a><strong></strong>BatchNorm</h2><p>BN<strong></strong>x=WU+BU<strong></strong>SigmoidWU+B<strong></strong><strong></strong><strong>BN01</strong><strong></strong></p><p>THATS IT<strong>01</strong>BN</p><p></p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405225246905-37854887.png" alt="img"></p><p>  1  </p><p>x-20.5BN01x2BN0101</p><p>x01</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405225314624-527885612.png" alt="img"></p><p>2  01</p><p>64%x[-1,1]95%x[-2,2]x=WU+B,Uxsigmoidsigmoid(x)</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143109455-1460017374.png" alt="img"></p><p>3. Sigmoid(x)</p><p>sigmoid(x)G=f(x)*(1-f(x))f(x)=sigmoid(x)01G00.25</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142351924-124461667.png" alt="img"></p><p>4  Sigmoid(x)</p><p>BNx-6195%[-8,-4]Sigmoidx0sigmoid(x)010BN0195%x[-2,2]sigmoid(x)x0</p><p>BNx=WU+BBN0101<strong>BNActivation</strong></p><p>BN<strong></strong><strong>BN01xscaleshift(y=scale*x+shift)</strong>scaleshiftscaleshiftscaleshiftscaleshiftxInternal Covariate Shiftscaleshift</p><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><p>BNMini-Batch SGDBN</p><p></p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405213859690-1933561230.png" alt="img"></p><p>  5  DNN</p><p>BNBNX=WU+B</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180405213955224-1791925244.png" alt="img"></p><p>  6. BN</p><p>Mini-Batch SGDmBN</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142802238-1209499294.png" alt="img"></p><p>tx(k)t-1tx=WU+BUt-1xmini-BatchmmxE(x)Var(x)</p><p><strong>x01**</strong>scaleshiftscaleshift**</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142923190-79595046.png" alt="img"></p><p>BN</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407142956288-903484055.png" alt="img"></p><p></p><h2 id="BatchNorm-Inference-"><a href="#BatchNorm-Inference-" class="headerlink" title="BatchNorm(Inference)"></a>BatchNorm(Inference)</h2><p>BNMini-BatchinferenceMini-BatchBN</p><p>Mini-BatchMini-BatchmMini-Batch</p><p>Mini-BatchMini-BatchmMini-Batch</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143405654-1995556833.png" alt="img"></p><p>ScalingShiftNBBN</p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143658338-63450857.png" alt="img"></p><p></p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407143807788-1841864822.png" alt="img"></p><p></p><p><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407144519480-1024698421.png" alt="img"><img src="https://images2018.cnblogs.com/blog/1192699/201804/1192699-20180407144549010-487189588.png" alt="img"></p><p></p><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><p>BatchNormNB<strong>**</strong>DropoutDropout**BN</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux  </title>
      <link href="/2019/08/14/linux-%E6%96%87%E4%BB%B6%E5%90%8D%E4%B8%AD%E6%9C%89%E7%A9%BA%E6%A0%BC%E3%80%81%E6%8B%AC%E5%8F%B7-%E6%97%B6%E5%A6%82%E4%BD%95%E6%93%8D%E4%BD%9C/"/>
      <url>/2019/08/14/linux-%E6%96%87%E4%BB%B6%E5%90%8D%E4%B8%AD%E6%9C%89%E7%A9%BA%E6%A0%BC%E3%80%81%E6%8B%AC%E5%8F%B7-%E6%97%B6%E5%A6%82%E4%BD%95%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h3 id="-cd-cp"><a href="#-cd-cp" class="headerlink" title=" cd cp"></a> <code>cd</code> <code>cp</code></h3><ul><li><p><strong></strong> </p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmd = 'cp -r <span class="string">"&#123;&#125;"</span> <span class="string">"&#123;&#125;"</span>'.format(source_path, target_path)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python 3.3.3 ,,</title>
      <link href="/2019/08/14/python-3-3-3-%E5%AD%97%E9%9D%A2%E9%87%8F-%E6%AD%A3%E5%88%99-%E5%8F%8D%E6%96%9C%E6%9D%A0%E5%92%8C%E5%8E%9F%E5%A7%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
      <url>/2019/08/14/python-3-3-3-%E5%AD%97%E9%9D%A2%E9%87%8F-%E6%AD%A3%E5%88%99-%E5%8F%8D%E6%96%9C%E6%9D%A0%E5%92%8C%E5%8E%9F%E5%A7%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<ul><li> from <a href="https://www.cnblogs.com/xiangnan/p/3446904.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiangnan/p/3446904.html</a></li></ul><h1 id=""><a href="#" class="headerlink" title=""></a></h1><ul><li>Python str</li></ul><p>(recognized escape sequences),Python.:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\c'</span></span><br><span class="line"><span class="string">'\\c'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\d'</span></span><br><span class="line"><span class="string">'\\d'</span></span><br></pre></td></tr></table></figure><p>\cunrecognized escape sequences.:</p><p>Unlike Standard C, all unrecognized escape sequences are left in the string unchanged, i.e., <em>the backslash is left in the string</em>. (This behavior is useful when debugging: if an escape sequence is mistyped, the resulting output is more easily recognized as broken.) </p><p>,C,c\c.Python\c\c.C.</p><p>,recognized escape sequences<strong></strong><strong></strong>,.:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\b'</span></span><br><span class="line"><span class="string">'\x08'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\n'</span></span><br><span class="line"><span class="string">'\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\x'</span></span><br><span class="line"><span class="symbol">SyntaxError:</span> (unicode error) <span class="string">'unicodeescape'</span> codec can<span class="string">'t decode bytes in position 0-1: truncated \xXX escape</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; '</span>\N<span class="string">'</span></span><br><span class="line"><span class="string">SyntaxError: (unicode error) '</span>unicodeescape<span class="string">' codec can'</span>t decode bytes <span class="keyword">in</span> position <span class="number">0</span>-<span class="number">1</span>: malformed \N character escape</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\U'</span></span><br><span class="line"><span class="symbol">SyntaxError:</span> (unicode error) <span class="string">'unicodeescape'</span> codec can<span class="string">'t decode bytes in position 0-1: truncated \UXXXXXXXX escape</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; '</span>\u<span class="string">'</span></span><br><span class="line"><span class="string">SyntaxError: (unicode error) '</span>unicodeescape<span class="string">' codec can'</span>t decode bytes <span class="keyword">in</span> position <span class="number">0</span>-<span class="number">1</span>: truncated \uXXXX escape</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><ul><li>Python re</li></ul><p>(special sequences),re,:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\e'</span>,<span class="string">'eee'</span>)</span><br><span class="line">[<span class="string">'e'</span>, <span class="string">'e'</span>, <span class="string">'e'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'e'</span>,<span class="string">'eee'</span>)</span><br><span class="line">[<span class="string">'e'</span>, <span class="string">'e'</span>, <span class="string">'e'</span>]</span><br></pre></td></tr></table></figure><p>,\ee.Python:</p><p>If the ordinary character is not on the list, then the resulting RE will match the second character. For example, <code>\$</code> matches the character <code>&#39;$&#39;</code>.</p><p>,special sequences,re.:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\w'</span>,<span class="string">'abcdefghijklmnopqrstuvwxyz'</span>)</span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>, <span class="string">'g'</span>, <span class="string">'h'</span>, <span class="string">'i'</span>, <span class="string">'j'</span>, <span class="string">'k'</span>, <span class="string">'l'</span>, <span class="string">'m'</span>, <span class="string">'n'</span>, <span class="string">'o'</span>, <span class="string">'p'</span>, <span class="string">'q'</span>, <span class="string">'r'</span>, <span class="string">'s'</span>, <span class="string">'t'</span>, <span class="string">'u'</span>, <span class="string">'v'</span>, <span class="string">'w'</span>, <span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'z'</span>]</span><br></pre></td></tr></table></figure><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>(Literals),Python.str literals  bytes literals.</p><p>:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">'abc'</span></span><br><span class="line"><span class="string">'abc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">"abc"</span></span><br><span class="line"><span class="string">'abc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">''</span></span><br><span class="line"><span class="string">''</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">b'abc'</span></span><br><span class="line"><span class="string">b'abc'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">r'\n'</span></span><br><span class="line"><span class="string">'\\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">b''</span></span><br><span class="line">SyntaxError: bytes can only contain ASCII literal characters.</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><p>\3:</p><p>1..(,,):\</p><p>2..:abfNnrtuUvx0123456789.</p><p>(,bytes,NuU)</p><p>3..,:py,,,,,.</p><p>:</p><table><thead><tr><th>Escape Sequence</th><th>Meaning</th><th>Notes</th></tr></thead><tbody><tr><td><code>\newline</code></td><td>Backslash and newline ignored</td><td></td></tr><tr><td><code>\\</code></td><td>Backslash (<code>\</code>)</td><td></td></tr><tr><td><code>\&#39;</code></td><td>Single quote (<code>&#39;</code>)</td><td></td></tr><tr><td><code>\&quot;</code></td><td>Double quote (<code>&quot;</code>)</td><td></td></tr><tr><td><code>\a</code></td><td>ASCII Bell (BEL)</td><td></td></tr><tr><td><code>\b</code></td><td>ASCII Backspace (BS)</td><td></td></tr><tr><td><code>\f</code></td><td>ASCII Formfeed (FF)</td><td></td></tr><tr><td><code>\n</code></td><td>ASCII Linefeed (LF)</td><td></td></tr><tr><td><code>\r</code></td><td>ASCII Carriage Return (CR)</td><td></td></tr><tr><td><code>\t</code></td><td>ASCII Horizontal Tab (TAB)</td><td></td></tr><tr><td><code>\v</code></td><td>ASCII Vertical Tab (VT)</td><td></td></tr><tr><td><code>\ooo</code></td><td>Character with octal value <em>ooo</em></td><td>(1,3)</td></tr><tr><td><code>\xhh</code></td><td>Character with hex value <em>hh</em></td><td>(2,3)</td></tr></tbody></table><p>Escape sequences only recognized in string literals are:</p><table><thead><tr><th>Escape Sequence</th><th>Meaning</th><th>Notes</th></tr></thead><tbody><tr><td><code>\N{name}</code></td><td>Character named <em>name</em> in the Unicode database</td><td>(4)</td></tr><tr><td><code>\uxxxx</code></td><td>Character with 16-bit hex value <em>xxxx</em></td><td>(5)</td></tr><tr><td><code>\Uxxxxxxxx</code></td><td>Character with 32-bit hex value <em>xxxxxxxx</em></td><td>(6)</td></tr></tbody></table><p>:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\N&#123;END OF LINE&#125;'</span></span><br><span class="line"><span class="string">'\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\N&#123;HORIZONTAL TABULATION&#125;'</span></span><br><span class="line"><span class="string">'\t'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\u9f6a'</span>==<span class="string">''</span></span><br><span class="line">True</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\1'</span>==<span class="string">'\01'</span></span><br><span class="line">True</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\1'</span>==<span class="string">'\001'</span></span><br><span class="line">True</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; <span class="string">'\1'</span>==<span class="string">'\0000001'</span></span><br><span class="line">False</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><ul><li></li></ul><p>(special charactersmetacharacters),.14:</p><p>.^$*+?{}<a href></a>|</p><p>.:</p><p>AbBdDsSwWZ0123456789</p><p>str:</p><p>&#39;abfnrtuUvx0123456789</p><p>:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\"'</span>,<span class="string">'"'</span>)</span><br><span class="line">[<span class="string">'"'</span>]</span><br></pre></td></tr></table></figure><p>patternPython,.\\\.</p><p>,re.search(pattern,string),pattern,string.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; re.search(<span class="string">'\\\\'</span>,<span class="string">'\\'</span>)</span><br><span class="line">&lt;_sre<span class="selector-class">.SRE_Match</span> <span class="selector-tag">object</span> at <span class="number">0</span>x02858528&gt;</span><br></pre></td></tr></table></figure><p>&#39;(txt),Python str \,pattern\\.,:<strong>(ab),patternr</strong>.:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.search(<span class="string">r'\\'</span>,<span class="string">'\\'</span>)</span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x02858448</span>&gt;</span><br></pre></td></tr></table></figure><p>:</p><ul><li>1.</li></ul><p>b0123456789,Pythonre.\b,python .re.<strong>python </strong>,:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\b'</span>,<span class="string">'\b'</span>)  <span class="comment">#'\b',</span></span><br><span class="line">[<span class="string">'\x08'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b'</span>,<span class="string">'\b'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b'</span>,<span class="string">'b'</span>) </span><br><span class="line">[<span class="string">''</span>, <span class="string">''</span>]</span><br></pre></td></tr></table></figure><p>:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'(a)\1\1'</span>,<span class="string">'aaa'</span>) <span class="comment">#\1,</span></span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'(a)\\1\\1'</span>,<span class="string">'aaa'</span>)  <span class="comment">#\\1,'(a)aa'</span></span><br><span class="line">[<span class="string">'a'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'a\1\1'</span>,<span class="string">'a\1\1'</span>) <span class="comment">#\1,</span></span><br><span class="line">[<span class="string">'a\x01\x01'</span>]</span><br></pre></td></tr></table></figure><p>?</p><p>1.\1,r,\1.</p><p>2.\1,rpattern.</p><p>,r1pattern?</p><p>,1,.</p><ul><li><strong>2.</strong></li></ul><p>:</p><p>Note that <code>\b</code> is used to represent word boundaries, and means backspace only inside character classes</p><p>\b[],.,\b[],,:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\b'</span>,<span class="string">'\b'</span>)</span><br><span class="line">[<span class="string">'\x08'</span>]</span><br></pre></td></tr></table></figure><p>\b(txt\b).</p><p>,repattern++!</p><p>:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b\w+\\b'</span>,<span class="string">'one two three'</span>)  <span class="comment">#\\b</span></span><br><span class="line">[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b\\w+\\b'</span>,<span class="string">'one two three'</span>)  <span class="comment">#,\w\\w</span></span><br><span class="line">[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\d'</span>,<span class="string">'123'</span>)</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\d'</span>,<span class="string">'123'</span>)</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>]</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><ul><li>3.uUstr,bytes.</li></ul><p>Python:</p><table><thead><tr><th>Python string literal</th><th>values passed to regular expression</th><th>number of characters</th><th>what regular expression engine does</th><th>real meaning for regular expression</th></tr></thead><tbody><tr><td>\e</td><td>\e</td><td>2</td><td>ignore the backslash</td><td>e</td></tr><tr><td>\e</td><td>\e</td><td>2</td><td>ignore the backslash</td><td>e</td></tr><tr><td>e</td><td>e</td><td>1</td><td>nothing spacial</td><td>e</td></tr><tr><td>\n</td><td>\n</td><td>1</td><td>nothing spacial</td><td></td></tr><tr><td>\n</td><td>\n</td><td>2</td><td>\n is special</td><td></td></tr><tr><td>\b</td><td>\b</td><td>1</td><td>nothing spacial</td><td></td></tr><tr><td>\b</td><td>\b</td><td>2</td><td>\b is special</td><td>word boundary</td></tr><tr><td>\s</td><td>\s</td><td>2</td><td>\s is special</td><td>Unicode whitespace characters</td></tr><tr><td>\</td><td>\</td><td>1</td><td>must followed by a charcter</td><td>Cant form any meaning</td></tr><tr><td>\\</td><td>\</td><td>2</td><td>remove all special meanning of \</td><td>\</td></tr><tr><td>*</td><td>*</td><td>1</td><td>* is special</td><td>repeat the left characters 0 or more times</td></tr><tr><td>*</td><td>*</td><td>2</td><td>remove all special meanning of *</td><td>*</td></tr></tbody></table><p>:</p><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[<span class="string">'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[<span class="string">'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[<span class="string">'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\\n'</span>,<span class="string">'\n\n'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[<span class="string">'\x08'</span>, <span class="string">'\x08'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[<span class="string">'\x08'</span>, <span class="string">'\x08'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\\b'</span>,<span class="string">'\b\b'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'c'</span>, <span class="string">'c'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'c'</span>, <span class="string">'c'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'\\c'</span>, <span class="string">'\\c'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; re.findall(<span class="string">'\\\\c'</span>,<span class="string">'\c\c'</span>)</span><br><span class="line">[<span class="string">'\\c'</span>, <span class="string">'\\c'</span>]</span><br></pre></td></tr></table></figure><p><a href="javascript:void(0);" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt=""></a></p><p>:</p><p>Python 3.3.3 </p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>glob  **</title>
      <link href="/2019/08/13/glob-%E4%B9%8B/"/>
      <url>/2019/08/13/glob-%E4%B9%8B/</url>
      
        <content type="html"><![CDATA[<ul><li>glob</li></ul><h3 id="--"><a href="#--" class="headerlink" title="  "></a> <strong><em></em></strong> </h3><ul><li><p></p><p><img src="https://i.loli.net/2019/08/14/sjTANPfDuV6cord.png" alt="20190814100532.png"></p></li></ul><ul><li><p><code>/userhome/dataset/MSVD/YouTubeClips/YouTubeClips</code>  <code>.avi</code></p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">path</span> = <span class="string">'/userhome/dataset/MSVD/YouTubeClips/YouTubeClips/'</span></span><br><span class="line">glob.glob(<span class="built_in">path</span> + <span class="string">'*.avi'</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p></p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">path</span> = <span class="string">'/userhome/dataset/MSVD/YouTubeClips/'</span></span><br><span class="line">glob.glob(<span class="built_in">path</span> + <span class="string">'**/'</span> + <span class="string">'*.avi'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">path</span> = <span class="string">'/userhome/dataset/MSVD/'</span></span><br><span class="line">glob.glob(<span class="built_in">path</span> + <span class="string">'**/'</span> + <span class="string">'**/'</span> + <span class="string">'*.avi'</span>)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> pytorch clone() vs copy_()</title>
      <link href="/2019/08/06/pytorch-clone-vs-copy/"/>
      <url>/2019/08/06/pytorch-clone-vs-copy/</url>
      
        <content type="html"><![CDATA[<p><code>clone</code>()  Tensor</p><ul><li><br>Returns a copy of the <code>self</code> tensor. The copy has the same size and data type as <code>self</code>.</li><li>NOTE</li><li>Unlike copy_(), this function is recorded in the computation graph. Gradients propagating to the cloned tensor will propagate to the original tensor.</li></ul><hr><p><code>copy_</code>(<em>src</em>, <em>non_blocking=False</em>)  Tensor</p><ul><li><p><br>Copies the elements from <code>src</code> into <code>self</code> tensor and returns <code>self</code>.</p></li><li><p>The <code>src</code> tensor must be <a href="https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics" target="_blank" rel="noopener">broadcastable</a> with the <code>self</code> tensor. It may be of a different data type or reside on a different device.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/08/05/%E5%AE%9E%E9%AA%8C%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3/"/>
      <url>/2019/08/05/%E5%AE%9E%E9%AA%8C%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3/</url>
      
        <content type="html"><![CDATA[<h3 id="-1"><a href="#-1" class="headerlink" title=" 1"></a> 1</h3><ul><li>pycharm debugrunning<br><br>evaluate.py </li><li></li><li></li></ul><ol><li>epoch train.pyevaluate.pyvideo video<br></li><li>videoiterationiterationdataloader.<br></li><li>num_workers=0dataloaderdataloaderdataset<br></li><li>h5pyself.critical pytorch <code>[:]</code> </li></ol>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bridging the Gap between Training and Inference for Neural Machine Translation</title>
      <link href="/2019/08/04/Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation/"/>
      <url>/2019/08/04/Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Label Image Recognition with Graph Convolutional Networks</title>
      <link href="/2019/08/02/Multi-Label-Image-Recognition-with-Graph-Convolutional-Networks/"/>
      <url>/2019/08/02/Multi-Label-Image-Recognition-with-Graph-Convolutional-Networks/</url>
      
        <content type="html"><![CDATA[<h3 id="Motivation-label-"><a href="#Motivation-label-" class="headerlink" title="Motivation  label "></a>Motivation  label </h3><ul><li>GCNlabel</li><li></li><li> label </li></ul><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><h4 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h4><ul><li><p>GCN GCN  labelword embeddingglove vectorlabel </p></li><li><p>GCN<code>C*D</code><code>C</code><code>D</code>image representation</p></li><li><p>a<sub>ij</sub>label<sub>i</sub>label<sub>j</sub></p></li></ul><h4 id="image-representation"><a href="#image-representation" class="headerlink" title="image representation"></a>image representation</h4><ul><li> ResNet101  conv5<code>D</code></li></ul><h4 id="multi-label-classifier"><a href="#multi-label-classifier" class="headerlink" title="multi-label classifier"></a>multi-label classifier</h4><ul><li> multi-label</li></ul><p><img src="https://i.loli.net/2019/08/03/cdwYEWSF9q6tk3p.png" alt="20190802221229.png"></p><h3 id="-vs-semi-supervised-gcn"><a href="#-vs-semi-supervised-gcn" class="headerlink" title=" vs semi-supervised gcn"></a> vs semi-supervised gcn</h3><p>1.</p><ul><li>GCNGCN</li><li>GCN<code>C*D</code><code>C</code><code>D</code>image representation</li><li>GCN  labelword embeddingglove vectorlabel </li></ul><p>2.</p><ul><li>GCN</li><li>need to construct the <code>A</code> from scrach</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>word2vec</title>
      <link href="/2019/08/02/word2vec-1/"/>
      <url>/2019/08/02/word2vec-1/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>word2vec</title>
      <link href="/2019/08/01/word2vec/"/>
      <url>/2019/08/01/word2vec/</url>
      
        <content type="html"><![CDATA[<h3 id="one-hot-"><a href="#one-hot-" class="headerlink" title="one-hot "></a>one-hot </h3><ul><li>0one-hot</li><li>0</li></ul><h3 id="word2vet"><a href="#word2vet" class="headerlink" title="word2vet"></a>word2vet</h3><ul><li><p></p></li><li><p></p></li><li><p>softmaxvocab</p></li><li><p><a href="https://www.bilibili.com/video/av18512944/" target="_blank" rel="noopener"></a></p></li></ul><p></p><ul><li>glove</li><li>fasttext</li><li><a href="https://www.bilibili.com/video/av18795160/?spm_id_from=333.788.videocard.0" target="_blank" rel="noopener"></a></li><li>spacy</li><li><a href="https://shiyaya.github.io/2019/07/16/Spacy/" target="_blank" rel="noopener">https://shiyaya.github.io/2019/07/16/Spacy%E5%B7%A5%E5%85%B7%E5%8C%85/</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FPN</title>
      <link href="/2019/08/01/FPN/"/>
      <url>/2019/08/01/FPN/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://vision.cornell.edu/se3/wp-content/uploads/2017/07/fpn-poster.pdf" target="_blank" rel="noopener">poster</a></li><li><a href="https://blog.csdn.net/WZZ18191171661/article/details/79494534" target="_blank" rel="noopener"></a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VideoGraph: Recognizing Minutes-Long Human Activities in Videos</title>
      <link href="/2019/07/30/VideoGraph-Recognizing-Minutes-Long-Human-Activities-in-Videos/"/>
      <url>/2019/07/30/VideoGraph-Recognizing-Minutes-Long-Human-Activities-in-Videos/</url>
      
        <content type="html"><![CDATA[<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>CNNnon-lcoal temporal concepts</li><li>video</li><li>activityunit-action  activity  </li><li> (units-action) </li></ul><h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h3><ul><li>activity</li><li></li></ul><h3 id="Vs-Video-as-space-time-region-graph"><a href="#Vs-Video-as-space-time-region-graph" class="headerlink" title="Vs  Video as space-time region graph"></a>Vs  <code>Video as space-time region graph</code></h3><ul><li>Video as space-time region graph  key objects</li><li>Video graphvideo nodes</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_geometricc</title>
      <link href="/2019/07/30/%E5%AE%89%E8%A3%85pytorch-geometricc/"/>
      <url>/2019/07/30/%E5%AE%89%E8%A3%85pytorch-geometricc/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#frequently-asked-questions" target="_blank" rel="noopener"></a></p></li><li><p></p></li></ul><h2 id="Directly-Installation"><a href="#Directly-Installation" class="headerlink" title="Directly Installation"></a>Directly Installation</h2><p>We have outsourced a lot of functionality of PyTorch Geometric to other packages, which needs to be installed in advance. These packages come with their own CPU and GPU kernel implementations based on the newly introduced <a href="https://github.com/pytorch/extension-cpp/" target="_blank" rel="noopener">C++/CUDA extensions</a> in PyTorch 0.4.0.</p><p>Note</p><p>We do not recommend installation as root user on your system python. Please setup an <a href="https://conda.io/docs/user-guide/install/index.html/" target="_blank" rel="noopener">Anaconda/Miniconda</a> environment or create a <a href="https://www.docker.com/" target="_blank" rel="noopener">Docker image</a>.</p><p>Please follow the steps below for a successful installation:</p><ol start="0"><li><p>Added  by yaya:</p><ul><li><p>may be you can select a conda environments, will be more fine</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3<span class="number">-5.0</span><span class="number">.0</span>-Linux-x86_64.sh</span><br><span class="line">conda create -n pytorch_geometric python=<span class="number">3.7</span> -y</span><br><span class="line">source activate pytorch_geometric</span><br></pre></td></tr></table></figure></li><li><p>after into env: pytorch_geometric</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">install</span> <span class="selector-tag">torch-1</span><span class="selector-class">.1</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span>  # <span class="selector-tag">download</span> <span class="selector-tag">at</span> <span class="selector-tag">first</span></span><br><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">installl</span> <span class="selector-tag">numpy-1</span><span class="selector-class">.17</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span>  # <span class="selector-tag">download</span> <span class="selector-tag">at</span> <span class="selector-tag">first</span></span><br><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">install</span> <span class="selector-tag">scipy-1</span><span class="selector-class">.3</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span>  # <span class="selector-tag">download</span> <span class="selector-tag">at</span> <span class="selector-tag">first</span></span><br></pre></td></tr></table></figure></li></ul></li></ol><ol><li><p>Ensure that at least PyTorch 1.1.0 is installed:</p><blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; $ python -c <span class="string">"import torch; print(torch.__version__)"</span></span><br><span class="line">&gt; <span class="meta">&gt;&gt;&gt; </span><span class="number">1.1</span>.<span class="number">0</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote></li><li><p>Ensure CUDA is setup correctly (optional):</p><blockquote><ol><li><p>Check if PyTorch is installed with CUDA support:</p><blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;    &gt; $ python -c <span class="string">"import torch; print(torch.cuda.is_available())"</span></span><br><span class="line">&gt;    &gt; <span class="meta">&gt;&gt;&gt; </span>True</span><br><span class="line">&gt;    &gt;</span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="2"><li><p>Add CUDA to <code>$PATH</code> and <code>$CPATH</code> (note that your actual CUDA path may vary from <code>/usr/local/cuda</code>):</p><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda/bin:<span class="variable">$PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/bin:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; </span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> CPATH=/usr/<span class="built_in">local</span>/cuda/include:<span class="variable">$CPATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$CPATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/include:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt;</span></span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="3"><li><p>Add CUDA to <code>$LD_LIBRARY_PATH</code> on Linux and to <code>$DYLD_LIBRARY_PATH</code> on macOS (note that your actual CUDA path may vary from <code>/usr/local/cuda</code>):</p><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$LD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/lib64:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; </span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">export</span> DYLD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda/lib:<span class="variable">$DYLD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; $ <span class="built_in">echo</span> <span class="variable">$DYLD_LIBRARY_PATH</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt; &gt;&gt;&gt; /usr/<span class="built_in">local</span>/cuda/lib:...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">    &gt;</span></span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="4"><li><p>Verify that <code>nvcc</code> is accessible from terminal:</p><blockquote><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="quote">&gt;    &gt; $ nvcc --version</span></span><br><span class="line"><span class="quote">&gt;    &gt; &gt;&gt;&gt; 10.0</span></span><br><span class="line"><span class="quote">&gt;    &gt;</span></span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote><blockquote><ol start="5"><li><p>Ensure that PyTorch and system CUDA versions match:</p><blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;    &gt; $ python -c <span class="string">"import torch; print(torch.version.cuda)"</span></span><br><span class="line">&gt;    &gt; <span class="meta">&gt;&gt;&gt; </span><span class="number">10.0</span></span><br><span class="line">&gt;    &gt; </span><br><span class="line">&gt;    &gt; $ nvcc --version</span><br><span class="line">&gt;    &gt; <span class="meta">&gt;&gt;&gt; </span><span class="number">10.0</span></span><br><span class="line">&gt;    &gt;</span><br></pre></td></tr></table></figure></blockquote></li></ol></blockquote></li><li><p>Install all needed packages:</p><blockquote><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="symbol">$</span> you can see <span class="number">4.</span> first (optional)</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-scatter</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-sparse</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-cluster</span><br><span class="line">&gt; <span class="symbol">$</span> pip install --verbose --<span class="keyword">no</span>-cache-dir torch-spline-conv (optional)</span><br><span class="line">&gt; <span class="symbol">$</span> pip install torch-geometric</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote></li><li><p>added by yaya:<br>may be you can pip install scipy at first ,because above need it.</p></li></ol><h2 id="Docker-install"><a href="#Docker-install" class="headerlink" title="Docker install"></a>Docker install</h2><ul><li><a href="https://github.com/rusty1s/pytorch_geometric/tree/master/docker" target="_blank" rel="noopener">https://github.com/rusty1s/pytorch_geometric/tree/master/docker</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GCN_LSTM  vs  SGAE</title>
      <link href="/2019/07/30/gcn-on-captioning/"/>
      <url>/2019/07/30/gcn-on-captioning/</url>
      
        <content type="html"><![CDATA[<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Video Description: A Survey of Methods, Datasets and Evaluation Metrics</title>
      <link href="/2019/07/29/Video-Description-A-Survey-of-Methods-Datasets-and-Evaluation-Metrics/"/>
      <url>/2019/07/29/Video-Description-A-Survey-of-Methods-Datasets-and-Evaluation-Metrics/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>visual feature  language model </li><li></li><li></li></ul><h3 id="the-difficulty-of-video-caption"><a href="#the-difficulty-of-video-caption" class="headerlink" title="the difficulty of video caption"></a>the difficulty of video caption</h3><ul><li>videoobject description    </li><li>objects    </li><li>actionaction    </li></ul><h3 id="Sequence-Learning-based-Video-Captioning-Methods"><a href="#Sequence-Learning-based-Video-Captioning-Methods" class="headerlink" title="Sequence Learning based Video Captioning Methods"></a>Sequence Learning based Video Captioning Methods</h3><h4 id="CNN-RNN-based"><a href="#CNN-RNN-based" class="headerlink" title="CNN-RNN-based"></a>CNN-RNN-based</h4><ul><li><p> end-to-end</p><p>S. Venugopalan, H. Xu, J. Donahue, M. Rohrbach, R. Mooney, and K. Saenko. 2014. Translating videos to natural language using deep recurrent neural networks. arXiv preprint arXiv:1412.4729, (2014).    </p><img src="https://i.loli.net/2019/07/29/5d3ea016090c918345.png" alt="1.png" title="1.png"></li><li><p>S2VT </p><p>I. Sutskever, O. Vinyals, and Q. V. Le. 2014. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems. 3104-3112.    </p><img src="https://i.loli.net/2019/07/29/5d3ea01536b3144846.png" alt="2.png" title="2.png">   </li><li><p>TA ( C3D[1] )</p><p>L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, and A.Courville. 2015. Describing videos by exploiting temporal structure. In IEEE ICCV    </p><img src="https://i.loli.net/2019/07/29/5d3ea016a248c95582.png" alt="3.png" title="3.png">  </li><li><p>LSTM-E making a common visual-semantic-embedding </p><p>Y. Pan, T. Mei, T. Yao, H. Li, and Y. Rui. 2016. Jointly modeling embedding and translation to bridge video and language. In IEEE CVPR. </p><img src="https://i.loli.net/2019/07/29/5d3ea421aaf9013065.png" alt="4.png" title="4.png"></li></ul><ul><li><p>GRU-EVE  ( short fourier transform)</p><p>N. Aafaq, N. Akhtar, W. Liu, S. Z. Gilani and A. Mian. 2019. Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning. In IEEE CVPR.    </p><img src="https://i.loli.net/2019/07/29/5d3ea0163113561600.png" alt="20190729152752.png" title="20190729152752.png">   </li><li><p>h-RNN<br>H. Yu, J. Wang, Z. Huang, Y. Yang, and W. Xu. 2016. Video paragraph captioning using hierarchical recurrent neural networks. In IEEE CVPR.</p><img src="https://i.loli.net/2019/07/29/5d3ea63af2e0354548.png" alt="5.png" title="5.png"></li></ul><h4 id="RL-based"><a href="#RL-based" class="headerlink" title="RL-based"></a>RL-based</h4><ul><li><p>Z. Ren, X. Wang, N. Zhang, X. Lv, and L. Li. 2017. Deep reinforcement learning-based image captioning with embedding reward. arXiv preprint arXiv:1704.03899, (2017).</p></li><li><p>Y. Chen, S. Wang, W. Zhang, and Q. Huang. 2018.  ==Less Is More: Picking Informative Frames for Video Captioning.==  arXiv preprint arXiv:1803.01457, (2018).</p><p> key informative frames  complete video </p></li><li><p>L. Li and B. Gong. 2018. End-to-End Video Captioning with Multitask Reinforcement Learning. arXiv preprint arXiv:1803.07950,<br>(2018).</p></li><li><p>R. Pasunuru and M. Bansal. 2017. Reinforced video captioning with entailment rewards. arXiv preprint arXiv:1708.02300, (2017).</p></li><li><p>S. Phan, G. E. Henter, Y. Miyao, and S. Satoh. 2017. Consensusbased Sequence Training for Video Captioning. arXiv preprint arXiv:1712.09532, (2017).</p></li><li><p>X. Wang, W. Chen, J. Wu, Y. Wang, and W. Y. Wang. 2017.  ==Video Captioning via Hierarchical Reinforcement Learning.==  arXiv preprint arXiv:1711.11135, (2017).</p><p> decoder descriptionbaseline  DRLmotivation</p></li></ul><h3 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h3><ul><li><p><a href="https://blog.csdn.net/joshuaxx316/article/details/58696552" target="_blank" rel="noopener"></a></p></li><li><p>BLEUROUGEMETEOR   </p></li><li><p>CIDErSPICE    </p></li></ul><h4 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h4><ul><li><a href="https://blog.csdn.net/allocator/article/details/79657792" target="_blank" rel="noopener">BLEU</a></li><li>==BLEU== </li><li>BLEUBLEU</li><li></li></ul><ol><li> </li><li>  </li><li>  </li><li></li></ol><h4 id="ROUGE"><a href="#ROUGE" class="headerlink" title="ROUGE"></a>ROUGE</h4><img src="https://i.loli.net/2019/07/29/5d3ed71f2086769963.png" alt="20170228224903951.png" title="20170228224903951.png"><h4 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h4><img src="https://i.loli.net/2019/07/29/5d3edcce1761442736.png" alt="20170228225011405.png" title="20170228225011405.png">   <h4 id="CIDEr"><a href="#CIDEr" class="headerlink" title="CIDEr"></a>CIDEr</h4><img src="https://i.loli.net/2019/07/29/5d3edcce646d089162.png" alt="20170228225056046.png" title="20170228225056046.png"><h4 id="SPICE"><a href="#SPICE" class="headerlink" title="SPICE"></a>SPICE</h4><ul><li> gt  pred </li><li>sentence scene graph (eg:dog swimming through river, the failure case could be the word swimming being parsed as object and the word dog parsed as attribute )</li><li></li></ul><h4 id=""><a href="#" class="headerlink" title=""></a></h4><img src="https://i.loli.net/2019/07/29/5d3edd503479c20027.png" alt="20190729194921.png" title="20190729194921.png">    <h3 id=""><a href="#" class="headerlink" title=""></a></h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul><li><p>    </p></li><li><p>human evaluationvideo captioning       </p><h4 id=""><a href="#" class="headerlink" title=""></a></h4></li><li><p>videoactivitycaption model   </p></li><li><p>video action video representationeg:C3D   </p></li><li><p>   </p></li><li><p>encoder  decoder  ==== video representationdecoder    </p></li></ul><h3 id="captioning-model-"><a href="#captioning-model-" class="headerlink" title="captioning model "></a>captioning model </h3><ul><li>bias( )<img src="https://i.loli.net/2019/07/29/5d3ee4996cf7480633.png" alt="20190729202028.png" title="20190729202028.png"></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li>[1] D. Tran, L. D. Bourdev, R. Fergus, L. Torresani, and M. Paluri. 2014. C3D: Generic Features for Video Analysis. CoRR abs/1412.0767, (2014). </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning</title>
      <link href="/2019/07/28/Temporal-Deformable-Convolutional-Encoder-Decoder-Networks-for-Video-Captioning/"/>
      <url>/2019/07/28/Temporal-Deformable-Convolutional-Encoder-Decoder-Networks-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>RNN </li><li>RNN </li><li> ==Temporal Deformable Convolutional Encoder-Decoder Networks (dubbed as TDConvED) ==that fully employ convolutions in both encoder and decoder networks for video captioning. </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Motion Guided Spatial Attention for Video Captioning</title>
      <link href="/2019/07/28/Motion-Guided-Spatial-Attention-for-Video-Captioning/"/>
      <url>/2019/07/28/Motion-Guided-Spatial-Attention-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>spatial attention </li><li>motion information 3D-CNNs</li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li> MGSAGARU</li><li>The proposed MGSA utilize motion information between consecutive frames by applying CNN to stacked optical flows. </li><li>In addition, a gated recurrent unit named GARU is designed to adaptively relate spatial attention maps across time. <img src="https://i.loli.net/2019/07/28/5d3d877e9c0d546970.png" alt="20190728193057.png" title="20190728193057.png">    </li></ul><h3 id="Encoder-"><a href="#Encoder-" class="headerlink" title="Encoder "></a>Encoder </h3><ul><li>video NNappearences feature<code>N*H*W*D</code></li><li>MMoptical flow<code>N*M</code>optical flow imagesCNN<code>N*H*W*1</code></li><li>==NGRU==  appearence feature  optical flow cnn feature,<code>H*W</code></li><li>attention ==== frame feature <code>H*W</code>spatial attention</li></ul><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><img src="https://i.loli.net/2019/07/28/5d3d87b91afaa36288.png" alt="20190728193156.png" title="20190728193156.png" width="440px" height="400px">    <h3 id="Experimental-results"><a href="#Experimental-results" class="headerlink" title="Experimental results"></a>Experimental results</h3><ul><li>MSR-VTT====<img src="https://i.loli.net/2019/07/28/5d3d80835814750581.png" alt="20190728190107.png" title="20190728190107.png"></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li><p> spatial attention video captioning model</p></li><li><p>Li, X.; Zhao, B.; and Lu, X. 2017. MAM-RNN: multi-level attention model based RNN for video captioning. In IJCAI, 22082214. </p></li><li><p>Yang, Z.; Han, Y.; and Wang, Z. 2017. Catching the temporal regions-of-interest for video captioning. In ACM MM, 146153. attention, spatial. </p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning</title>
      <link href="/2019/07/27/Object-aware-Aggregation-with-Bidirectional-Temporal-Graph-for-Video-Captioning/"/>
      <url>/2019/07/27/Object-aware-Aggregation-with-Bidirectional-Temporal-Graph-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>object(capture object-based trajectory)object regions anchor regions anchor  iregionsregionanchorobjects   </li><li> Learning Video Representations from Correspondence Proposals   </li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li> global frame  salient regionsspecific objectsobject </li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h4 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h4><ul><li>constructs ==bidirectional temporal graph== to extract  the temporal trajectories for each object instance, which captures the detailed temporal dynamics in video content.    </li><li>==aggregation process on object regions==, which can capture the object-aware semantic information  VLAD[5, 6] representation   </li></ul><h4 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h4><ul><li><p>object VLAD representationtemporal attention  object attention</p></li><li><p> frames VLAD representation  temporal attention</p></li><li><p>nn.linear </p></li><li><p>word_embeddingGRU</p></li><li></li><li><p><font color="#0099ff" size="5" face=""></font>word score  sum</p><img src="https://i.loli.net/2019/07/28/5d3d37324d6d283934.png" alt="20190728134820.png" title="20190728134820.png">   </li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>videoobjects</li><li><strong> objects </strong></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li>NetVLADRelja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef Sivic. Netvlad: Cnn architecture for weakly supervised place recognition. In CVPR, pages 52975307, 2016.</li><li>SeqVLADYoujiang Xu, Yahong Han, Richang Hong, and Qi Tian. Sequential video vlad: Training the aggregation locally and temporally. IEEE Transactions on Image Processing (TIP), 27(10):49334944, 2018</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pointing Novel Objects in Image Captioning</title>
      <link href="/2019/07/26/Pointing-Novel-Objects-in-Image-Captioning/"/>
      <url>/2019/07/26/Pointing-Novel-Objects-in-Image-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><img src="https://i.loli.net/2019/07/27/5d3c1676f301a18995.png" alt="20190727171628.png" title="20190727171628.png"><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul><li>image-captionin-domain objects   </li></ul><h4 id="1"><a href="#1" class="headerlink" title="1"></a>1</h4><ul><li>words,(training dataset)   </li><li>object learner deep caption obectsdeep caption Model    </li><li>1LSTM decoder predicted word,  2objects learner copying layer  <strong>Pointing Mechanism</strong>   </li><li>loss:   <img src="https://i.loli.net/2019/07/27/5d3c1c012cccc48971.png" alt="20190727173939.png" title="20190727173939.png">   </li></ul><h4 id="2"><a href="#2" class="headerlink" title="2:"></a>2:</h4><ul><li>image</li><li>target caption nimage  objectsnimageobjects target caption</li><li> target caption .   </li><li>loss:</li></ul><img src="https://i.loli.net/2019/07/27/5d3c1c754b56a83488.png" alt="20190727174134.png" title="20190727174134.png">    <img src="https://i.loli.net/2019/07/27/5d3c1c7536e6674709.png" alt="20190727174147.png" title="20190727174147.png"> ]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vision to language </title>
      <link href="/2019/07/26/vision-to-language-%E5%A4%A7%E7%89%9B/"/>
      <url>/2019/07/26/vision-to-language-%E5%A4%A7%E7%89%9B/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>Papers can be found at <a href="https://sites.cs.ucsb.edu/~xwang" target="_blank" rel="noopener">https://sites.cs.ucsb.edu/~xwang</a><br>Email: <a href="mailto:xwang@cs.ucsb.edu" target="_blank" rel="noopener">xwang@cs.ucsb.edu</a></p><h4 id="video-captioning-via-hierarchical-reinforcement-learning"><a href="#video-captioning-via-hierarchical-reinforcement-learning" class="headerlink" title="video captioning via hierarchical  reinforcement learning"></a>video captioning via hierarchical  reinforcement learning</h4><ol><li></li><li></li></ol><h4 id="zero-shot-video-captioning"><a href="#zero-shot-video-captioning" class="headerlink" title="zero-shot video captioning"></a>zero-shot video captioning</h4><ul><li>Topic-Aware Mixture of Experts (TAMoE)  <h4 id="evaluation"><a href="#evaluation" class="headerlink" title="evaluation"></a>evaluation</h4></li></ul><ol><li><p></p></li><li><p>human evaluationstory</p></li></ol><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul><li></li></ul><ol><li>Adversarial REward Learning (AREL)</li></ol><h4 id="Connecting-Language-and-Vision-to-Actions"><a href="#Connecting-Language-and-Vision-to-Actions" class="headerlink" title="Connecting Language and Vision to Actions"></a>Connecting Language and Vision to Actions</h4><ul><li>Look Before You Leap: Model-based RL</li><li>Reinforced Cross-Modal Matching (RCM)</li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h4 id="-Vision--Language--Action"><a href="#-Vision--Language--Action" class="headerlink" title=" Vision  Language  Action"></a><a href="https://mp.weixin.qq.com/s/lnoL1TpKY8HQqCMaBqWA5Q" target="_blank" rel="noopener"> Vision  Language  Action</a></h4><h4 id="-Vision-and-Language-"><a href="#-Vision-and-Language-" class="headerlink" title=" Vision-and-Language "></a><a href="https://mp.weixin.qq.com/s/dyY64QrvPWbjGvJw5H51OA" target="_blank" rel="noopener"> Vision-and-Language </a></h4>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMUNeural Networks for NLP</title>
      <link href="/2019/07/26/CMU%E8%AF%BE%E7%A8%8B%E4%B8%8A%E6%96%B0%EF%BC%9ANeural-Networks-for-NLP/"/>
      <url>/2019/07/26/CMU%E8%AF%BE%E7%A8%8B%E4%B8%8A%E6%96%B0%EF%BC%9ANeural-Networks-for-NLP/</url>
      
        <content type="html"><![CDATA[<h1 id="CMUNeural-Networks-for-NLP18"><a href="#CMUNeural-Networks-for-NLP18" class="headerlink" title="CMUNeural Networks for NLP18"></a>CMUNeural Networks for NLP18</h1><p>Neural Networks for NLP</p><p></p><p></p><p>17-711NLP</p><p>2018B</p><p><a href="https://www.bilibili.com/video/av31156700/" target="_blank" rel="noopener">https://www.bilibili.com/video/av31156700/</a></p><p>19ELMo/BERTPyTorch/DyNet</p><p>19~~</p><p><a href="https://phontron.com/class/nn4nlp2019/schedule.html" target="_blank" rel="noopener">https://phontron.com/class/nn4nlp2019/schedule.html</a></p><p><strong></strong></p><p><img src="https://image.jiqizhixin.com/uploads/editor/6e56a929-53db-4396-bd4d-e42e2bd166cd/640.png" alt="img"></p><p>Graham NeubigAntonios AnastasopoulosGraham NeubigAntonios AnastasopoulosDavid Chiang</p><p><img src="https://image.jiqizhixin.com/uploads/editor/db527776-dbf8-4611-a415-1c94e99db32e/640.png" alt="img"></p><p></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p></p><p><img src="https://image.jiqizhixin.com/uploads/editor/0cf289f4-3ea8-43ad-b318-c97703e921ac/640.png" alt="img"></p><p>PPT~</p><p>PPT<a href="https://phontron.com/class/nn4nlp2019/schedule.html" target="_blank" rel="noopener">https://phontron.com/class/nn4nlp2019/schedule.html</a></p><p></p><p><a href="https://phontron.com/class/nn4nlp2019/schedule.html" target="_blank" rel="noopener">https://phontron.com/class/nn4nlp2019/schedule.html</a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning Video Representations from Correspondence Proposals</title>
      <link href="/2019/07/26/Learning-Video-Representations-from-Correspondence-Proposals/"/>
      <url>/2019/07/26/Learning-Video-Representations-from-Correspondence-Proposals/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>Non-local CNN2D 3D</li></ul><h3 id="CPNet-"><a href="#CPNet-" class="headerlink" title="CPNet "></a>CPNet </h3><p>1CNN<code>T*H*W*d</code><code>T*H*W</code>conv   </p><p>2graph <code>T*H*W</code>K   </p><p>3MLPKmax   </p><img src="https://i.loli.net/2019/07/26/5d3a7afee6b0178187.png" alt="20190726120054.png" title="20190726120054.png"><ul><li>Non-Local==CP Module==</li></ul><h3 id="Non-local-vs-CPNet"><a href="#Non-local-vs-CPNet" class="headerlink" title="Non-local  vs   CPNet"></a>Non-local  vs   CPNet</h3><ul><li><p>toy dataset figure4toy model CNN,SOTA modelCPNet</p></li><li><p> I3DARTNet TRN</p></li><li><p>ARTNet TRN </p></li><li><p>Non-local ==NL block ==CP moduleposition information</p></li></ul><img src="https://i.loli.net/2019/07/26/5d3a6c44659ae30922.png" alt="20190726102546.png" title="20190726102546.png"><h3 id="CPNet-model--"><a href="#CPNet-model--" class="headerlink" title="CPNet model: (  ,)"></a>CPNet model: (  ,)</h3><img src="https://i.loli.net/2019/07/26/5d3a889e2ce0b69830.png" alt="20190726125811.png" title="20190726125811.png">]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memory-Attended Recurrent Network for Video Captioning</title>
      <link href="/2019/07/25/Memory-Attended-Recurrent-Network-for-Video-Captioning/"/>
      <url>/2019/07/25/Memory-Attended-Recurrent-Network-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>&gt; =3</p><p>MSR-VTT :11K   MSVD:4K</p><h3 id="Attention-Decoder"><a href="#Attention-Decoder" class="headerlink" title="Attention Decoder"></a>Attention Decoder</h3><ul><li><p>SA-LSTM</p></li><li><p></p><ul><li><p>==attention==<br>frames_feature ==(L)==   C3D_feature ==L -&gt; L/16== attentionattention   <br>  </p><p>12D  3D   <br></p><p>2  <br>  </p></li><li><p><br>2D  3D 2048512</p></li></ul></li></ul><h3 id="Attended-Memory-Decoder"><a href="#Attended-Memory-Decoder" class="headerlink" title="Attended Memory Decoder"></a>Attended Memory Decoder</h3><ul><li><p></p><ul><li>wordvideovideo</li><li>video</li></ul></li><li><p>memeory</p></li></ul><h3 id="Attention-Coherent-Loss-AC-Loss"><a href="#Attention-Coherent-Loss-AC-Loss" class="headerlink" title="Attention-Coherent Loss (AC Loss)"></a>Attention-Coherent Loss (AC Loss)</h3><ul><li>C3D L1time interval,time interval frames feature attention</li><li>frames_features attention loss</li></ul><img src="https://i.loli.net/2019/07/25/5d397582d36f640160.png" alt="20190725172350.png" title="20190725172350.png">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/07/25/%E6%B7%B1%E5%BA%A6%E5%B1%82%E6%AC%A1%E5%8C%96%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2019/07/25/%E6%B7%B1%E5%BA%A6%E5%B1%82%E6%AC%A1%E5%8C%96%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h3 id="-"><a href="#-" class="headerlink" title=" "></a> </h3><h3 id="GCN-node-classification"><a href="#GCN-node-classification" class="headerlink" title="GCN( node classification )"></a>GCN( node classification )</h3><ul><li></li><li><code>H= AXW</code><h3 id="deeper-insight-into-graph-convolutional-networks-for-semi-supervised-learning"><a href="#deeper-insight-into-graph-convolutional-networks-for-semi-supervised-learning" class="headerlink" title="deeper insight into graph convolutional networks for semi-supervised learning"></a>deeper insight into graph convolutional networks for semi-supervised learning</h3></li><li>GCN<h3 id="GAT--GraphSAGE"><a href="#GAT--GraphSAGE" class="headerlink" title="GAT   GraphSAGE"></a>GAT   GraphSAGE</h3></li><li>2-hop</li></ul><h3 id="Hierarchical-Graph-Representation-Learning-with-Differentiable-Pooling-graph-classification"><a href="#Hierarchical-Graph-Representation-Learning-with-Differentiable-Pooling-graph-classification" class="headerlink" title="Hierarchical Graph Representation Learning with Differentiable Pooling graph classification"></a>Hierarchical Graph Representation Learning with Differentiable Pooling graph classification</h3><ol><li></li></ol><ul><li>GCN 2-hop</li><li>GCN- clusterpoolingGCN</li><li>graph Hierarchical  structure</li></ul><ol start="2"><li></li></ol><ul><li></li><li>pooling matrixobjects</li></ul><h3 id="Hierarchical-Graph-Convolutional-Networks-for-Semi-supervised-Node-Classification-9-IJCAI-2019"><a href="#Hierarchical-Graph-Convolutional-Networks-for-Semi-supervised-Node-Classification-9-IJCAI-2019" class="headerlink" title="Hierarchical Graph Convolutional Networks for Semi-supervised Node Classification ( 9 ) ( IJCAI 2019)"></a>Hierarchical Graph Convolutional Networks for Semi-supervised Node Classification ( 9 ) ( IJCAI 2019)</h3><ul><li> coarsening</li><li></li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hierarchical Global-Local Temporal Modeling for Video Captioning</title>
      <link href="/2019/07/23/Hierarchical-Global-Local-Temporal-Modeling-for-Video-Captioning/"/>
      <url>/2019/07/23/Hierarchical-Global-Local-Temporal-Modeling-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>object featuresaction  Object</li></ul><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul><li><p>LSTM</p></li><li><p>global : frame features and C3D features</p></li><li><p>local : objects </p></li></ul><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><ul><li><p>Top Down decoder</p><ul><li>Bottom LSTMmean of regions</li><li>Top LSTM : attention of  regions</li></ul></li><li><p>Grounded video descriptiondecoder</p><ul><li>Bottom LSTMmean of  fc+motion</li><li>Top LSTM: attention of  regions and attention of  fc+motion</li></ul></li><li><p>==Hierarchical Global-Local Temporal Modeling ==</p><ul><li>Bottom LSTMattention of fc+motion</li><li>Top LSTM: attention of regions</li><li>Bottom LSTMattention</li></ul></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li></li><li>C3D16C3D</li><li>object features: faster rcnn rcnn/head_to_healpooled_feats</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag> [object Object] </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VATEX: a video caption dataset</title>
      <link href="/2019/07/23/VATEX-a-video-caption-dataset/"/>
      <url>/2019/07/23/VATEX-a-video-caption-dataset/</url>
      
        <content type="html"><![CDATA[<h2 id="VATEX"><a href="#VATEX" class="headerlink" title="VATEX"></a>VATEX</h2><ul><li>41269video 10s, video1010105</li><li>1encoder-decoder2</li><li>kineticsvalidation dataset, caption41269video 4train, validation, public test, secret test()</li></ul><p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g8e7blhuobj30js0lfwkf.jpg" alt="20191028204431.png"></p><h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><ul><li>encoder-decoder  TopDown</li><li>I3Dkinetics trainfine-tunevideosegmentssegmentI3Dvi</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>faster_rcnn various box head</title>
      <link href="/2019/07/22/faster-rcnn-various-box-head/"/>
      <url>/2019/07/22/faster-rcnn-various-box-head/</url>
      
        <content type="html"><![CDATA[<h4 id="Ground-video-description"><a href="#Ground-video-description" class="headerlink" title="Ground video description"></a>Ground video description</h4><ul><li>objectsfc6issue<a href="https://github.com/facebookresearch/Detectron/blob/8170b25b425967f8f1c7d715bea3c5b8d9536cd8/detectron/modeling/fast_rcnn_heads.py" target="_blank" rel="noopener">box_head</a> </li><li>fc6  box_headbox_head faster_rcnn_head_to_tail</li></ul><h4 id="box-head-"><a href="#box-head-" class="headerlink" title="box_head "></a>box_head </h4><ul><li>roi_pooling  7*7pooled_feats ==== </li></ul><ul><li><p>faster_rcnn box_head resnet layer4</p></li><li><p>mmdetection  faster_rcnn 7*7  49 fc6, fc7.   !!</p></li><li><p> box_head</p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmdetectionconfigs</title>
      <link href="/2019/07/21/mmdetection%E7%9A%84configs%E4%B8%AD%E7%9A%84%E5%90%84%E9%A1%B9%E5%8F%82%E6%95%B0%E5%85%B7%E4%BD%93%E8%A7%A3%E9%87%8A/"/>
      <url>/2019/07/21/mmdetection%E7%9A%84configs%E4%B8%AD%E7%9A%84%E5%90%84%E9%A1%B9%E5%8F%82%E6%95%B0%E5%85%B7%E4%BD%93%E8%A7%A3%E9%87%8A/</url>
      
        <content type="html"><![CDATA[<p><br>mmdetectionfaster_rcnn_r50_fpn_1x.pycascade_rcnn_r50_fpn_1x.pymmdetection</p><p>faster_rcnn_r50_fpn_1x.py<br>resnet50backbone5fpnfaster-RCNN12epoch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model settings</span></span><br><span class="line">model = dict(</span><br><span class="line">type=<span class="string">'FasterRCNN'</span>,                         <span class="comment"># model</span></span><br><span class="line">    pretrained=<span class="string">'modelzoo://resnet50'</span>,          <span class="comment"># imagenet-resnet50</span></span><br><span class="line">    backbone=dict(</span><br><span class="line">        type=<span class="string">'ResNet'</span>,                         <span class="comment"># backbone</span></span><br><span class="line">        depth=<span class="number">50</span>,                              <span class="comment"># </span></span><br><span class="line">        num_stages=<span class="number">4</span>,                          <span class="comment"># resnetstage</span></span><br><span class="line">        out_indices=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),              <span class="comment"># stage</span></span><br><span class="line">        frozen_stages=<span class="number">1</span>,                       <span class="comment"># stagestage-1stage</span></span><br><span class="line">        style=<span class="string">'pytorch'</span>),                      <span class="comment"># pytorchstride2conv3x3caffestride2conv1x1</span></span><br><span class="line">    neck=dict(</span><br><span class="line">        type=<span class="string">'FPN'</span>,                            <span class="comment"># neck</span></span><br><span class="line">        in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],    <span class="comment"># stage</span></span><br><span class="line">        out_channels=<span class="number">256</span>,                      <span class="comment"># </span></span><br><span class="line">        num_outs=<span class="number">5</span>),                           <span class="comment"># </span></span><br><span class="line">    rpn_head=dict(</span><br><span class="line">        type=<span class="string">'RPNHead'</span>,                        <span class="comment"># RPN</span></span><br><span class="line">        in_channels=<span class="number">256</span>,                       <span class="comment"># RPN</span></span><br><span class="line">        feat_channels=<span class="number">256</span>,                     <span class="comment"># </span></span><br><span class="line">        anchor_scales=[<span class="number">8</span>],                     <span class="comment"># anchorbaselenbaselen = sqrt(w*h)whanchor</span></span><br><span class="line">        anchor_ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],         <span class="comment"># anchor</span></span><br><span class="line">        anchor_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>],     <span class="comment"># anchor</span></span><br><span class="line">        target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],         <span class="comment"># </span></span><br><span class="line">        target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>],      <span class="comment"># </span></span><br><span class="line">        use_sigmoid_cls=<span class="literal">True</span>),                 <span class="comment"># sigmoidFalsesoftmax</span></span><br><span class="line">    bbox_roi_extractor=dict(</span><br><span class="line">        type=<span class="string">'SingleRoIExtractor'</span>,                                   <span class="comment"># RoIExtractor</span></span><br><span class="line">        roi_layer=dict(type=<span class="string">'RoIAlign'</span>, out_size=<span class="number">7</span>, sample_num=<span class="number">2</span>),   <span class="comment"># ROIROIROIalign7sample2</span></span><br><span class="line">        out_channels=<span class="number">256</span>,                                            <span class="comment"># </span></span><br><span class="line">        featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),                             <span class="comment"># </span></span><br><span class="line">    bbox_head=dict(</span><br><span class="line">        type=<span class="string">'SharedFCBBoxHead'</span>,                     <span class="comment"># </span></span><br><span class="line">        num_fcs=<span class="number">2</span>,                                   <span class="comment"># </span></span><br><span class="line">        in_channels=<span class="number">256</span>,                             <span class="comment"># </span></span><br><span class="line">        fc_out_channels=<span class="number">1024</span>,                        <span class="comment"># </span></span><br><span class="line">        roi_feat_size=<span class="number">7</span>,                             <span class="comment"># ROI</span></span><br><span class="line">        num_classes=<span class="number">81</span>,                              <span class="comment"># +1+1</span></span><br><span class="line">        target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],               <span class="comment"># </span></span><br><span class="line">        target_stds=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],            <span class="comment"># </span></span><br><span class="line">        reg_class_agnostic=<span class="literal">False</span>))                   <span class="comment"># class_agnosticclass_agnosticbboxbbox</span></span><br><span class="line"><span class="comment"># model training and testing settings</span></span><br><span class="line">train_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        assigner=dict(</span><br><span class="line">            type=<span class="string">'MaxIoUAssigner'</span>,            <span class="comment"># RPN</span></span><br><span class="line">            pos_iou_thr=<span class="number">0.7</span>,                  <span class="comment"># iou</span></span><br><span class="line">            neg_iou_thr=<span class="number">0.3</span>,                  <span class="comment"># iou</span></span><br><span class="line">            min_pos_iou=<span class="number">0.3</span>,                  <span class="comment"># iouassignground truthanchorsIOU0.3anchorsIOUanchor</span></span><br><span class="line">            ignore_iof_thr=<span class="number">-1</span>),               <span class="comment"># bboxground truthbbox-1</span></span><br><span class="line">        sampler=dict(</span><br><span class="line">            type=<span class="string">'RandomSampler'</span>,             <span class="comment"># </span></span><br><span class="line">            num=<span class="number">256</span>,                          <span class="comment"># </span></span><br><span class="line">            pos_fraction=<span class="number">0.5</span>,                 <span class="comment"># </span></span><br><span class="line">            neg_pos_ub=<span class="number">-1</span>,                    <span class="comment"># -1</span></span><br><span class="line">            add_gt_as_proposals=<span class="literal">False</span>),       <span class="comment"># ground truthproposal</span></span><br><span class="line">        allowed_border=<span class="number">0</span>,                     <span class="comment"># bbox</span></span><br><span class="line">        pos_weight=<span class="number">-1</span>,                        <span class="comment"># -1</span></span><br><span class="line">        smoothl1_beta=<span class="number">1</span> / <span class="number">9.0</span>,                <span class="comment"># L1</span></span><br><span class="line">        debug=<span class="literal">False</span>),                         <span class="comment"># debug</span></span><br><span class="line">    rcnn=dict(</span><br><span class="line">        assigner=dict(</span><br><span class="line">            type=<span class="string">'MaxIoUAssigner'</span>,            <span class="comment"># RCNN</span></span><br><span class="line">            pos_iou_thr=<span class="number">0.5</span>,                  <span class="comment"># iou</span></span><br><span class="line">            neg_iou_thr=<span class="number">0.5</span>,                  <span class="comment"># iou</span></span><br><span class="line">            min_pos_iou=<span class="number">0.5</span>,                  <span class="comment"># iouassignground truthanchorsIOU0.3anchorsIOUanchor</span></span><br><span class="line">            ignore_iof_thr=<span class="number">-1</span>),               <span class="comment"># bboxground truthbbox-1</span></span><br><span class="line">        sampler=dict(</span><br><span class="line">            type=<span class="string">'RandomSampler'</span>,             <span class="comment"># </span></span><br><span class="line">            num=<span class="number">512</span>,                          <span class="comment"># </span></span><br><span class="line">            pos_fraction=<span class="number">0.25</span>,                <span class="comment"># </span></span><br><span class="line">            neg_pos_ub=<span class="number">-1</span>,                    <span class="comment"># -1</span></span><br><span class="line">            add_gt_as_proposals=<span class="literal">True</span>),        <span class="comment"># ground truthproposal</span></span><br><span class="line">        pos_weight=<span class="number">-1</span>,                        <span class="comment"># -1</span></span><br><span class="line">        debug=<span class="literal">False</span>))                         <span class="comment"># debug</span></span><br><span class="line">test_cfg = dict(</span><br><span class="line">    rpn=dict(                                 <span class="comment"># RPN</span></span><br><span class="line">        nms_across_levels=<span class="literal">False</span>,              <span class="comment"># fpnnms</span></span><br><span class="line">        nms_pre=<span class="number">2000</span>,                         <span class="comment"># nmsproposal</span></span><br><span class="line">        nms_post=<span class="number">2000</span>,                        <span class="comment"># nmsproposal</span></span><br><span class="line">        max_num=<span class="number">2000</span>,                         <span class="comment"># proposal</span></span><br><span class="line">        nms_thr=<span class="number">0.7</span>,                          <span class="comment"># nms</span></span><br><span class="line">        min_bbox_size=<span class="number">0</span>),                     <span class="comment"># bbox</span></span><br><span class="line">    rcnn=dict(</span><br><span class="line">        score_thr=<span class="number">0.05</span>, nms=dict(type=<span class="string">'nms'</span>, iou_thr=<span class="number">0.5</span>), max_per_img=<span class="number">100</span>)   <span class="comment"># max_per_imgdet bbox</span></span><br><span class="line">    <span class="comment"># soft-nms is also supported for rcnn testing</span></span><br><span class="line">    <span class="comment"># e.g., nms=dict(type='soft_nms', iou_thr=0.5, min_score=0.05)            # soft_nms</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># dataset settings</span></span><br><span class="line">dataset_type = <span class="string">'CocoDataset'</span>                <span class="comment"># </span></span><br><span class="line">data_root = <span class="string">'data/coco/'</span>                    <span class="comment"># </span></span><br><span class="line">img_norm_cfg = dict(</span><br><span class="line">    mean=[<span class="number">123.675</span>, <span class="number">116.28</span>, <span class="number">103.53</span>], std=[<span class="number">58.395</span>, <span class="number">57.12</span>, <span class="number">57.375</span>], to_rgb=<span class="literal">True</span>)   <span class="comment"># meanstdto_rgbbgrrgb</span></span><br><span class="line">data = dict(</span><br><span class="line">    imgs_per_gpu=<span class="number">2</span>,                <span class="comment"># gpu</span></span><br><span class="line">    workers_per_gpu=<span class="number">2</span>,             <span class="comment"># gpu</span></span><br><span class="line">    train=dict(</span><br><span class="line">        type=dataset_type,                                                 <span class="comment"># </span></span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_train2017.json'</span>,       <span class="comment"># annotation</span></span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>,                               <span class="comment"># </span></span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),                                             <span class="comment"># 1333800</span></span><br><span class="line">        img_norm_cfg=img_norm_cfg,                                         <span class="comment"># </span></span><br><span class="line">        size_divisor=<span class="number">32</span>,                                                   <span class="comment"># resize32resize32</span></span><br><span class="line">        flip_ratio=<span class="number">0.5</span>,                                                    <span class="comment"># </span></span><br><span class="line">        with_mask=<span class="literal">False</span>,                                                   <span class="comment"># mask</span></span><br><span class="line">        with_crowd=<span class="literal">True</span>,                                                   <span class="comment"># difficult</span></span><br><span class="line">        with_label=<span class="literal">True</span>),                                                  <span class="comment"># label</span></span><br><span class="line">    val=dict(</span><br><span class="line">        type=dataset_type,                                                 <span class="comment"># </span></span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,         <span class="comment"># </span></span><br><span class="line">        img_prefix=data_root + <span class="string">'val2017/'</span>,                                 <span class="comment"># </span></span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),                                             <span class="comment"># </span></span><br><span class="line">        img_norm_cfg=img_norm_cfg,                                         <span class="comment"># </span></span><br><span class="line">        size_divisor=<span class="number">32</span>,                                                   <span class="comment"># </span></span><br><span class="line">        flip_ratio=<span class="number">0</span>,                                                      <span class="comment"># </span></span><br><span class="line">        with_mask=<span class="literal">False</span>,                                                   <span class="comment"># </span></span><br><span class="line">        with_crowd=<span class="literal">True</span>,                                                   <span class="comment"># </span></span><br><span class="line">        with_label=<span class="literal">True</span>),                                                  <span class="comment"># </span></span><br><span class="line">    test=dict(</span><br><span class="line">        type=dataset_type,                                                 <span class="comment"># </span></span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,         <span class="comment"># </span></span><br><span class="line">        img_prefix=data_root + <span class="string">'val2017/'</span>,                                 <span class="comment"># </span></span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),                                             <span class="comment"># </span></span><br><span class="line">        img_norm_cfg=img_norm_cfg,                                         <span class="comment"># </span></span><br><span class="line">        size_divisor=<span class="number">32</span>,                                                   <span class="comment"># </span></span><br><span class="line">        flip_ratio=<span class="number">0</span>,                                                      <span class="comment"># </span></span><br><span class="line">        with_mask=<span class="literal">False</span>,                                                   <span class="comment"># </span></span><br><span class="line">        with_label=<span class="literal">False</span>,                                                  <span class="comment"># </span></span><br><span class="line">        test_mode=<span class="literal">True</span>))                                                   <span class="comment"># </span></span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = dict(type=<span class="string">'SGD'</span>, lr=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>)   <span class="comment"># lrmomentumweight_decay</span></span><br><span class="line">optimizer_config = dict(grad_clip=dict(max_norm=<span class="number">35</span>, norm_type=<span class="number">2</span>))          <span class="comment"># </span></span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = dict(</span><br><span class="line">    policy=<span class="string">'step'</span>,                        <span class="comment"># </span></span><br><span class="line">    warmup=<span class="string">'linear'</span>,                      <span class="comment"># linear</span></span><br><span class="line">    warmup_iters=<span class="number">500</span>,                     <span class="comment"># 500</span></span><br><span class="line">    warmup_ratio=<span class="number">1.0</span> / <span class="number">3</span>,                 <span class="comment"># </span></span><br><span class="line">    step=[<span class="number">8</span>, <span class="number">11</span>])                         <span class="comment"># 811epoch</span></span><br><span class="line">checkpoint_config = dict(interval=<span class="number">1</span>)      <span class="comment"># 1epoch</span></span><br><span class="line"><span class="comment"># yapf:disable</span></span><br><span class="line">log_config = dict(</span><br><span class="line">    interval=<span class="number">50</span>,                          <span class="comment"># 50batch</span></span><br><span class="line">    hooks=[</span><br><span class="line">        dict(type=<span class="string">'TextLoggerHook'</span>),      <span class="comment"># </span></span><br><span class="line">        <span class="comment"># dict(type='TensorboardLoggerHook')</span></span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># yapf:enable</span></span><br><span class="line"><span class="comment"># runtime settings</span></span><br><span class="line">total_epochs = <span class="number">12</span>                               <span class="comment"># epoch</span></span><br><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>)              <span class="comment"># </span></span><br><span class="line">log_level = <span class="string">'INFO'</span>                              <span class="comment"># </span></span><br><span class="line">work_dir = <span class="string">'./work_dirs/faster_rcnn_r50_fpn_1x'</span> <span class="comment"># log</span></span><br><span class="line">load_from = <span class="literal">None</span>                                <span class="comment"># None</span></span><br><span class="line">resume_from = <span class="literal">None</span>                              <span class="comment"># </span></span><br><span class="line">workflow = [(<span class="string">'train'</span>, <span class="number">1</span>)]                       <span class="comment"># </span></span><br></pre></td></tr></table></figure><p> cascade_rcnn_r50_fpn_1x.py<br>cascade-RCNNcvpr2018faster-RCNNRCNNstagestagerefineconfigfaster-RCNN </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model settings</span></span><br><span class="line">model = dict(</span><br><span class="line">    type=<span class="string">'CascadeRCNN'</span>,</span><br><span class="line">    num_stages=<span class="number">3</span>,                     <span class="comment"># RCNNstagefaster-RCNN1</span></span><br><span class="line">    pretrained=<span class="string">'modelzoo://resnet50'</span>,</span><br><span class="line">    backbone=dict(</span><br><span class="line">        type=<span class="string">'ResNet'</span>,</span><br><span class="line">        depth=<span class="number">50</span>,</span><br><span class="line">        num_stages=<span class="number">4</span>,</span><br><span class="line">        out_indices=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),</span><br><span class="line">        frozen_stages=<span class="number">1</span>,</span><br><span class="line">        style=<span class="string">'pytorch'</span>),</span><br><span class="line">    neck=dict(</span><br><span class="line">        type=<span class="string">'FPN'</span>,</span><br><span class="line">        in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        num_outs=<span class="number">5</span>),</span><br><span class="line">    rpn_head=dict(</span><br><span class="line">        type=<span class="string">'RPNHead'</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        feat_channels=<span class="number">256</span>,</span><br><span class="line">        anchor_scales=[<span class="number">8</span>],</span><br><span class="line">        anchor_ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],</span><br><span class="line">        anchor_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>],</span><br><span class="line">        target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],</span><br><span class="line">        target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>],</span><br><span class="line">        use_sigmoid_cls=<span class="literal">True</span>),</span><br><span class="line">    bbox_roi_extractor=dict(</span><br><span class="line">        type=<span class="string">'SingleRoIExtractor'</span>,</span><br><span class="line">        roi_layer=dict(type=<span class="string">'RoIAlign'</span>, out_size=<span class="number">7</span>, sample_num=<span class="number">2</span>),</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">    bbox_head=[</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">81</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>),</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">81</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.05</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.1</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>),</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">81</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.033</span>, <span class="number">0.033</span>, <span class="number">0.067</span>, <span class="number">0.067</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>)</span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># model training and testing settings</span></span><br><span class="line">train_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        assigner=dict(</span><br><span class="line">            type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">            pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">            neg_iou_thr=<span class="number">0.3</span>,</span><br><span class="line">            min_pos_iou=<span class="number">0.3</span>,</span><br><span class="line">            ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">        sampler=dict(</span><br><span class="line">            type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">            num=<span class="number">256</span>,</span><br><span class="line">            pos_fraction=<span class="number">0.5</span>,</span><br><span class="line">            neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">            add_gt_as_proposals=<span class="literal">False</span>),</span><br><span class="line">        allowed_border=<span class="number">0</span>,</span><br><span class="line">        pos_weight=<span class="number">-1</span>,</span><br><span class="line">        smoothl1_beta=<span class="number">1</span> / <span class="number">9.0</span>,</span><br><span class="line">        debug=<span class="literal">False</span>),</span><br><span class="line">    rcnn=[                    <span class="comment"># 3RCNNRCNNstage</span></span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.5</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.6</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.6</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.6</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.7</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>)</span><br><span class="line">    ],</span><br><span class="line">    stage_loss_weights=[<span class="number">1</span>, <span class="number">0.5</span>, <span class="number">0.25</span>])     <span class="comment"># 3RCNNstageloss</span></span><br><span class="line">test_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        nms_across_levels=<span class="literal">False</span>,</span><br><span class="line">        nms_pre=<span class="number">2000</span>,</span><br><span class="line">        nms_post=<span class="number">2000</span>,</span><br><span class="line">        max_num=<span class="number">2000</span>,</span><br><span class="line">        nms_thr=<span class="number">0.7</span>,</span><br><span class="line">        min_bbox_size=<span class="number">0</span>),</span><br><span class="line">    rcnn=dict(</span><br><span class="line">        score_thr=<span class="number">0.05</span>, nms=dict(type=<span class="string">'nms'</span>, iou_thr=<span class="number">0.5</span>), max_per_img=<span class="number">100</span>),</span><br><span class="line">    keep_all_stages=<span class="literal">False</span>)         <span class="comment"># stage</span></span><br><span class="line"><span class="comment"># dataset settings</span></span><br><span class="line">dataset_type = <span class="string">'CocoDataset'</span></span><br><span class="line">data_root = <span class="string">'data/coco/'</span></span><br><span class="line">img_norm_cfg = dict(</span><br><span class="line">    mean=[<span class="number">123.675</span>, <span class="number">116.28</span>, <span class="number">103.53</span>], std=[<span class="number">58.395</span>, <span class="number">57.12</span>, <span class="number">57.375</span>], to_rgb=<span class="literal">True</span>)</span><br><span class="line">data = dict(</span><br><span class="line">    imgs_per_gpu=<span class="number">2</span>,</span><br><span class="line">    workers_per_gpu=<span class="number">2</span>,</span><br><span class="line">    train=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_train2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0.5</span>,</span><br><span class="line">        with_mask=<span class="literal">False</span>,</span><br><span class="line">        with_crowd=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">True</span>),</span><br><span class="line">    val=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'val2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">False</span>,</span><br><span class="line">        with_crowd=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">True</span>),</span><br><span class="line">    test=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'val2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">False</span>,</span><br><span class="line">        with_label=<span class="literal">False</span>,</span><br><span class="line">        test_mode=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = dict(type=<span class="string">'SGD'</span>, lr=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>)</span><br><span class="line">optimizer_config = dict(grad_clip=dict(max_norm=<span class="number">35</span>, norm_type=<span class="number">2</span>))</span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = dict(</span><br><span class="line">    policy=<span class="string">'step'</span>,</span><br><span class="line">    warmup=<span class="string">'linear'</span>,</span><br><span class="line">    warmup_iters=<span class="number">500</span>,</span><br><span class="line">    warmup_ratio=<span class="number">1.0</span> / <span class="number">3</span>,</span><br><span class="line">    step=[<span class="number">8</span>, <span class="number">11</span>])</span><br><span class="line">checkpoint_config = dict(interval=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># yapf:disable</span></span><br><span class="line">log_config = dict(</span><br><span class="line">    interval=<span class="number">50</span>,</span><br><span class="line">    hooks=[</span><br><span class="line">        dict(type=<span class="string">'TextLoggerHook'</span>),</span><br><span class="line">        <span class="comment"># dict(type='TensorboardLoggerHook')</span></span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># yapf:enable</span></span><br><span class="line"><span class="comment"># runtime settings</span></span><br><span class="line">total_epochs = <span class="number">12</span></span><br><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>)</span><br><span class="line">log_level = <span class="string">'INFO'</span></span><br><span class="line">work_dir = <span class="string">'./work_dirs/cascade_rcnn_r50_fpn_1x'</span></span><br><span class="line">load_from = <span class="literal">None</span></span><br><span class="line">resume_from = <span class="literal">None</span></span><br><span class="line">workflow = [(<span class="string">'train'</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure><p></p><p><a href="https://www.jiqizhixin.com/articles/2018-10-17-10" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2018-10-17-10</a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Visual Genome </title>
      <link href="/2019/07/21/Visual-Genome-%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2019/07/21/Visual-Genome-%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<ul><li><br><a href="https://cloud.tencent.com/developer/article/1391855" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1391855</a></li></ul><p><a href="https://visualgenome.org/" target="_blank" rel="noopener">Visual Genome </a></p><p><a href="https://visualgenome.org/api/v0/api_home.html" target="_blank" rel="noopener">Visual Genome Data</a></p><p><a href="https://visualgenome.org/api/v0/api_readme" target="_blank" rel="noopener">Visual Genome Readme</a></p><p>Visual Genome </p><ul><li>108077 </li><li>5.4 Million Region Descriptions</li><li>1.7 Million Visual Question Answers</li><li>3.8 Million Object Instances</li><li>2.8 Million Attributes</li><li>2.3 Million Relationships</li><li>Everything Mapped to Wordnet Synsets  </li><li>  objectsattributes relationships</li><li> 108K  35  objects26  attributes21 objects  relationships.</li></ul><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/rex8eso6p5.png?imageView2/2/w/1620" alt="img"></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/vtmiv1yyr6.png?imageView2/2/w/1620" alt="img"></p><h2 id="1-Visual-Genome-"><a href="#1-Visual-Genome-" class="headerlink" title="1. Visual Genome "></a>1. Visual Genome </h2><p></p><ul><li>region descriptions</li><li>objects</li><li>attributes</li><li>relationships</li><li>region graphs</li><li>scene graphs</li><li>question answer pairs</li></ul><h3 id="1-1-Region-Descriptions"><a href="#1-1-Region-Descriptions" class="headerlink" title="1.1. Region Descriptions"></a>1.1. Region Descriptions</h3><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/8kgo0p0qim.png?imageView2/2/w/1620" alt="img"></p><p> regions descriptions region  bounding box. </p><p> regions descriptions man jumping over a fire hydrant,yellow fire hydrant,    woman in shorts is standing behind the man..</p><h3 id="1-2-Objects"><a href="#1-2-Objects" class="headerlink" title="1.2. Objects"></a>1.2. Objects</h3><p> 35  objects object  bounding box .</p><p>   </p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/ih1qpz1p3s.png?imageView2/2/w/1620" alt="img"></p><p><a href="http://blog.csdn.net/zziahgf/article/details/72819043" target="_blank" rel="noopener">MS-COCO </a>  80  object categories objects.  objects .</p><p>Visual Genome  objects objects categories  33877 .</p><h3 id="1-3-Attributes"><a href="#1-3-Attributes" class="headerlink" title="1.3. Attributes"></a>1.3. Attributes</h3><p> 26  attributes. Objects  attributes. </p><p>Attributes  color( yellow)states( standing)    </p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/k1n26a1mdt.png?imageView2/2/w/1620" alt="img"></p><p>Attributes  objects .  object attributes  object . yellow and brown spotted with long neck() object  giraffe().</p><p> attributes </p><ul><li>examplar SVMs objects</li><li>(textures)  objects.</li><li> attributes .  fine-grained .</li></ul><p>Attributes  parts( has legs)shapes(spherical)materials( furry) objects .</p><p>Visual Genome  attributes  attributes  image-specific  object-specific . attributes size( small), pose(bent), state ( transparent), emotion ( happy).</p><ul><li> VGG16  attributes    </li></ul><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/373ih7qquc.png?imageView2/2/w/1620" alt="img"></p><h3 id="1-4-Relationships"><a href="#1-4-Relationships" class="headerlink" title="1.4. Relationships"></a>1.4. Relationships</h3><p>Relationships  objects .</p><p>Relationships  actions( jumping over)spatial( is build)comparative( taller than)prepositional phrases ( drive on).    </p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/5ljbd3m2av.png?imageView2/2/w/1620" alt="img"></p><ul><li>Relationship    </li></ul><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/pgbhzj5ui4.png?imageView2/2/w/1620" alt="img"></p><h3 id="1-5-Region-Graphs"><a href="#1-5-Region-Graphs" class="headerlink" title="1.5. Region Graphs"></a>1.5. Region Graphs</h3><p> objectsattributes   region descriptions  relationships regions  graph representation. </p><h3 id="1-6-Scene-Graphs"><a href="#1-6-Scene-Graphs" class="headerlink" title="1.6. Scene Graphs"></a>1.6. Scene Graphs</h3><p>Region graphs  region graphs  scene graph.</p><p>Scene graph  region graphs  objectsattributes region description  relationships.</p><p>Scene Graph  scene .</p><h3 id="1-7-Question-Answer-QA-Pairs"><a href="#1-7-Question-Answer-QA-Pairs" class="headerlink" title="1.7. Question Answer(QA) Pairs"></a>1.7. Question Answer(QA) Pairs</h3><p> QA pairs</p><ul><li>freeform QAs - </li><li>region-based QAs - . </li></ul><p> 6 what, where, how, when, who, why.</p><p>   </p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/vbxbgpfi92.png?imageView2/2/w/1620" alt="img"></p><p>Figure . Visual Genome . region descriptions -  question answer pairs(QAs) - free form QAs  region-based QAs.  region  objectsattributes  pairwise relationships region  region graph .   region graphs  objects  scene graph.</p><h2 id="2-Visual-Genome-"><a href="#2-Visual-Genome-" class="headerlink" title="2. Visual Genome "></a>2. Visual Genome </h2><p></p><ul><li>attribute classification </li><li>relationship classification </li><li>description generation </li><li>question answering QA</li></ul><p></p><ul><li>Dense image captioning</li><li>Visual question answering</li><li>Image understanding</li><li>Relationship extraction</li><li>Semantic image retrieval</li><li>Completing the Set of Annotations</li></ul><p> -    </p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1682974/cjqe5v7i44.png?imageView2/2/w/1620" alt="img"></p><h2 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h2><p>[1] - <a href="https://visualgenome.org/" target="_blank" rel="noopener">Visual Genome Home</a></p><p>[1] - <a href="https://visualgenome.org/static/paper/Visual_Genome.pdf" target="_blank" rel="noopener">Visual Genome Doc</a></p><p>[2] - <a href="https://arxiv.org/pdf/1701.02426.pdf" target="_blank" rel="noopener">Scene Graph Generation by Iterative Message Passing</a></p><p><a href="https://cloud.tencent.com/developer/support-plan" target="_blank" rel="noopener"></a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/07/21/%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90/"/>
      <url>/2019/07/21/%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<p>def set_random_seed(seed):<br>    random.seed(seed)<br>    np.random.seed(seed)<br>    torch.manual_seed(seed)<br>    torch.cuda.manual_seed_all(seed)</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>mmdetection</title>
      <link href="/2019/07/20/mmdetection%E7%9A%84%E5%AE%89%E8%A3%85/"/>
      <url>/2019/07/20/mmdetection%E7%9A%84%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>py36-pytorch0.4.0-cu90-ctc cuda9.0</li><li>note: pytorch1.1.0pytorch1.21.1.0anacondapytorch</li><li>anaconda</li></ul><h3 id="Github-install"><a href="#Github-install" class="headerlink" title="Github install"></a><a href="https://github.com/open-mmlab/mmdetection/blob/master/INSTALL.md" target="_blank" rel="noopener">Github install</a></h3><ul><li>Create a conda virtual environment and activate it. Then install Cython.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n open-mmlab python=<span class="number">3.7</span> -y</span><br><span class="line">source activate open-mmlab</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>** open-mmlab**</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="keyword">install</span> cython</span><br></pre></td></tr></table></figure></li><li><p> numpy</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> numpy</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><a href="https://github.com/open-mmlab/mmcv" target="_blank" rel="noopener">mmcv</a> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmcv</span><br></pre></td></tr></table></figure></li><li><p>pytorch<br>conda install  pip install pip install torch  </p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">pip</span> <span class="selector-tag">install</span> <span class="selector-tag">torch-1</span><span class="selector-class">.1</span><span class="selector-class">.0-cp37-cp37m-manylinux1_x86_64</span><span class="selector-class">.whl</span></span><br></pre></td></tr></table></figure></li><li><p>opencv</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="keyword">install</span> -c menpo opencv</span><br></pre></td></tr></table></figure></li></ul><ul><li>matplotlib<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> matplotlib</span><br></pre></td></tr></table></figure></li></ul><ul><li> terminaltables<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> terminaltables</span><br></pre></td></tr></table></figure></li></ul><ul><li><p> pip install pycocotools</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> pycocotools</span><br></pre></td></tr></table></figure></li><li><p>Clone the mmdetection repository.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/open-mmlab/mmdetection.git</span><br><span class="line">cd mmdetection</span><br></pre></td></tr></table></figure></li><li><p>Install mmdetection</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py develop</span><br></pre></td></tr></table></figure></li><li><p></p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch.no_grad</title>
      <link href="/2019/07/17/torch-no-grad/"/>
      <url>/2019/07/17/torch-no-grad/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/21" target="_blank" rel="noopener">https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/21</a></li><li>with torch.no_grad()</li><li>batch_size </li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spacy</title>
      <link href="/2019/07/16/Spacy%E5%B7%A5%E5%85%B7%E5%8C%85/"/>
      <url>/2019/07/16/Spacy%E5%B7%A5%E5%85%B7%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<h2 id="spacy"><a href="#spacy" class="headerlink" title="spacy"></a>spacy</h2><h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import spacy</span><br><span class="line">nlp = spacy.<span class="built_in">load</span>(<span class="string">'en'</span>)</span><br><span class="line">doc = nlp(<span class="string">'Hello World! My name is HanXiaoyang'</span>)</span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">for</span> <span class="keyword">token</span> <span class="keyword">in</span> doc:</span><br><span class="line">    print(<span class="string">'"'</span> + <span class="keyword">token</span>.<span class="keyword">text</span> + <span class="string">'"'</span>)</span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> doc.sents:</span><br><span class="line">    print(sent)</span><br></pre></td></tr></table></figure><p>token</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">doc</span> <span class="string">=</span> <span class="string">nlp("Next</span> <span class="string">week</span> <span class="string">I'll</span>   <span class="string">be</span> <span class="string">in</span> <span class="string">Shanghai.")</span></span><br><span class="line"><span class="string">for</span> <span class="string">token</span> <span class="string">in</span> <span class="attr">doc:</span></span><br><span class="line">    <span class="string">print("&#123;0&#125;\t&#123;1&#125;\t&#123;2&#125;\t&#123;3&#125;\t&#123;4&#125;\t&#123;5&#125;\t&#123;6&#125;\t&#123;7&#125;".format(</span></span><br><span class="line">        <span class="string">token.text,</span></span><br><span class="line">        <span class="string">token.idx,</span></span><br><span class="line">        <span class="string">token.lemma_,</span></span><br><span class="line">        <span class="string">token.is_punct,</span></span><br><span class="line">        <span class="string">token.is_space,</span></span><br><span class="line">        <span class="string">token.shape_,</span></span><br><span class="line">        <span class="string">token.pos_,</span></span><br><span class="line">        <span class="string">token.tag_</span></span><br><span class="line">    <span class="string">))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Next</span>    <span class="number">0</span>   <span class="string">next</span>    <span class="literal">False</span>   <span class="literal">False</span>   <span class="string">Xxxx</span>    <span class="string">ADJ</span> <span class="string">JJ</span></span><br><span class="line"><span class="string">week</span>    <span class="number">5</span>   <span class="string">week</span>    <span class="literal">False</span>   <span class="literal">False</span>   <span class="string">xxxx</span>    <span class="string">NOUN</span>    <span class="string">NN</span></span><br><span class="line"><span class="string">I</span>   <span class="number">10</span>  <span class="bullet">-PRON-</span>  <span class="literal">False</span>   <span class="literal">False</span>   <span class="string">X</span>   <span class="string">PRON</span>    <span class="string">PRP</span></span><br><span class="line"><span class="string">'ll 11  will    False   False   '</span><span class="string">xx</span> <span class="string">VERB</span>    <span class="string">MD</span></span><br><span class="line">    <span class="number">15</span>      <span class="literal">False</span>   <span class="literal">True</span>        <span class="string">SPACE</span>   <span class="string">_SP</span></span><br><span class="line"><span class="string">be</span>  <span class="number">17</span>  <span class="string">be</span>  <span class="literal">False</span>   <span class="literal">False</span>   <span class="string">xx</span>  <span class="string">VERB</span>    <span class="string">VB</span></span><br><span class="line"><span class="string">in</span>  <span class="number">20</span>  <span class="string">in</span>  <span class="literal">False</span>   <span class="literal">False</span>   <span class="string">xx</span>  <span class="string">ADP</span> <span class="string">IN</span></span><br><span class="line"><span class="string">Shanghai</span>    <span class="number">23</span>  <span class="string">shanghai</span>    <span class="literal">False</span>   <span class="literal">False</span>   <span class="string">Xxxxx</span>   <span class="string">PROPN</span>   <span class="string">NNP</span></span><br><span class="line"><span class="string">.</span>   <span class="number">31</span>  <span class="string">.</span>   <span class="literal">True</span>    <span class="literal">False</span>   <span class="string">.</span>   <span class="string">PUNCT</span>   <span class="string">.</span></span><br></pre></td></tr></table></figure><h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># </span></span><br><span class="line">doc = nlp(<span class="string">"Next week I'll be in Shanghai."</span>)</span><br><span class="line">print([(<span class="keyword">token</span>.<span class="keyword">text</span>, <span class="keyword">token</span>.tag_) <span class="keyword">for</span> <span class="keyword">token</span> <span class="keyword">in</span> doc])</span><br></pre></td></tr></table></figure><p>[(Next, JJ), (week, NN), (I, PRP), (ll, MD), (be, VB), (in, IN), (Shanghai, NNP), (., .)]</p><h3 id="3"><a href="#3" class="headerlink" title="3"></a>3</h3><p>spaCy(root)Journal,piece,currencies</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">doc = nlp(<span class="string">"Wall Street Journal just published an interesting piece on crypto currencies"</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> doc<span class="selector-class">.noun_chunks</span>:</span><br><span class="line">    print(chunk<span class="selector-class">.text</span>, chunk<span class="selector-class">.label_</span>, chunk<span class="selector-class">.root</span><span class="selector-class">.text</span>)</span><br></pre></td></tr></table></figure><p><br>Wall Street Journal NP Journal<br>an interesting piece NP piece<br>crypto currencies NP currencies</p><h3 id="4"><a href="#4" class="headerlink" title="4"></a>4</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">doc = nlp(<span class="string">"Two years ago, I lived in my Beijing."</span>)</span><br><span class="line"><span class="keyword">for</span> ent <span class="keyword">in</span> doc<span class="selector-class">.ents</span>:</span><br><span class="line">    print(ent<span class="selector-class">.text</span>, ent.label_)</span><br></pre></td></tr></table></figure><p><br>Two years ago DATE<br>BeijingGPE</p><p></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy import displacy</span><br><span class="line">displacy.render(doc, <span class="attribute">style</span>=<span class="string">'ent'</span>, <span class="attribute">jupyter</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="//upload-images.jianshu.io/upload_images/11681023-77f9837fa7e661dd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/454/format/webp" alt></p><p>.png</p><h3 id="5"><a href="#5" class="headerlink" title="5"></a>5</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">doc = nlp(<span class="string">'Wall Street Journal just published an interesting piece on crypto currencies'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(<span class="string">"&#123;0&#125;/&#123;1&#125; &lt;--&#123;2&#125;-- &#123;3&#125;/&#123;4&#125;"</span>.format(</span><br><span class="line">        token<span class="selector-class">.text</span>, token<span class="selector-class">.tag_</span>, token<span class="selector-class">.dep_</span>, token<span class="selector-class">.head</span><span class="selector-class">.text</span>, token<span class="selector-class">.head</span><span class="selector-class">.tag_</span>))</span><br></pre></td></tr></table></figure><p><br>Wall/NNP &lt;compound Street/NNP<br>Street/NNP &lt;compound Journal/NNP<br>Journal/NNP &lt;nsubj published/VBD<br>just/RB &lt;advmod published/VBD<br>published/VBD &lt;ROOT published/VBD<br>an/DT &lt;det piece/NN<br>interesting/JJ &lt;amod piece/NN<br>piece/NN &lt;dobj published/VBD<br>on/IN &lt;prep piece/NN<br>crypto/JJ &lt;compound currencies/NNS<br>currencies/NNS &lt;pobj on/IN</p><h3 id="6-"><a href="#6-" class="headerlink" title="6===="></a>6====</h3><p>NLP==word2vec==v()-v()  v()-v()<br>spaCy</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">python3</span> -m spacy download en_core_web_lg</span><br></pre></td></tr></table></figure><p></p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">nlp = spacy.<span class="built_in">load</span>(<span class="string">'en_core_web_lg'</span>)</span><br><span class="line"><span class="built_in">from</span> scipy import spatial</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">cosine_similarity = lambda x, y: <span class="number">1</span> - spatial.distance.cosine(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line">man = nlp.vocab[<span class="string">'man'</span>].vector</span><br><span class="line">woman = nlp.vocab[<span class="string">'woman'</span>].vector</span><br><span class="line">queen = nlp.vocab[<span class="string">'queen'</span>].vector</span><br><span class="line">king = nlp.vocab[<span class="string">'king'</span>].vector</span><br><span class="line"> </span><br><span class="line"><span class="comment"># "man" - "woman" + "queen"</span></span><br><span class="line">maybe_king = man - woman + queen</span><br><span class="line">computed_similarities = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">word</span> <span class="keyword">in</span> nlp.vocab:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">word</span>.has_vector:</span><br><span class="line">        continue</span><br><span class="line"> </span><br><span class="line">    similarity = cosine_similarity(maybe_king, <span class="built_in">word</span>.vector)</span><br><span class="line">    computed_similarities.append((<span class="built_in">word</span>, similarity))</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">computed_similarities = sorted(computed_similarities, key=lambda <span class="keyword">item</span>: -<span class="keyword">item</span>[<span class="number">1</span>])</span><br><span class="line">print([w[<span class="number">0</span>].<span class="keyword">text</span> <span class="keyword">for</span> w <span class="keyword">in</span> computed_similarities[:<span class="number">10</span>]])</span><br></pre></td></tr></table></figure><p><br>[Queen, QUEEN, queen, King, KING, king, KIng, Kings, KINGS, kings]</p><h3 id="6"><a href="#6" class="headerlink" title="6"></a>6</h3><p>spaCy</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ()</span></span><br><span class="line">banana = nlp.vocab['banana']</span><br><span class="line">dog = nlp.vocab['dog']</span><br><span class="line">fruit = nlp.vocab['fruit']</span><br><span class="line">animal = nlp.vocab['animal']</span><br><span class="line"> </span><br><span class="line">print(dog.similarity(animal), dog.similarity(fruit)) <span class="comment"># 0.6618534 0.23552845</span></span><br><span class="line">print(banana.similarity(fruit), banana.similarity(animal)) <span class="comment"># 0.67148364 0.2427285</span></span><br></pre></td></tr></table></figure><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ()</span></span><br><span class="line">target = nlp(<span class="string">"Cats are beautiful animals."</span>)</span><br><span class="line"> </span><br><span class="line">doc1 = nlp(<span class="string">"Dogs are awesome."</span>)</span><br><span class="line">doc2 = nlp(<span class="string">"Some gorgeous creatures are felines."</span>)</span><br><span class="line">doc3 = nlp(<span class="string">"Dolphins are swimming mammals."</span>)</span><br><span class="line"> </span><br><span class="line">print(target.similarity(doc1))  <span class="comment"># 0.8901765218466683</span></span><br><span class="line">print(target.similarity(doc2))  <span class="comment"># 0.9115828449161616</span></span><br><span class="line">print(target.similarity(doc3))  <span class="comment"># 0.7822956752876101</span></span><br></pre></td></tr></table></figure><p><br><a href="https://www.jianshu.com/p/74e6c5376bc0" target="_blank" rel="noopener">https://www.jianshu.com/p/74e6c5376bc0</a><br><br></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch-gather</title>
      <link href="/2019/07/12/pytorch-gather/"/>
      <url>/2019/07/12/pytorch-gather/</url>
      
        <content type="html"><![CDATA[<p><code>torch.gather(input, dim, index, out=None)  Tensor</code><br>  dim , index .<br>  3 ,:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out[<span class="string">i</span>][<span class="symbol">j</span>][<span class="string">k</span>] = input[<span class="string">index[i</span>][<span class="symbol">j</span>][<span class="string">k</span>]][<span class="string">j</span>][<span class="symbol">k</span>]  # if dim == 0</span><br><span class="line">out[<span class="string">i</span>][<span class="symbol">j</span>][<span class="string">k</span>] = input[<span class="string">i</span>][<span class="symbol">index[i</span>][<span class="string">j</span>][<span class="symbol">k</span>]][<span class="symbol">k</span>]  # if dim == 1</span><br><span class="line">out[<span class="string">i</span>][<span class="symbol">j</span>][<span class="string">k</span>] = input[<span class="string">i</span>][<span class="symbol">j</span>][<span class="string">index[i</span>][<span class="symbol">j</span>][<span class="string">k</span>]]  # if dim == 2</span><br></pre></td></tr></table></figure><p>Parameters:</p><ul><li>input (Tensor)  </li><li>dim (int)  </li><li>index (LongTensor)  (indextorch.longTensor)</li><li>out (Tensor, optional)  </li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/07/11/hello-world/"/>
      <url>/2019/07/11/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>numpy </title>
      <link href="/2019/06/16/numpy-%E5%87%BD%E6%95%B0/"/>
      <url>/2019/06/16/numpy-%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="np-round"><a href="#np-round" class="headerlink" title="np.round "></a><font color="#0099ff" size="7" face="">np.round </font></h2><h3 id="round"><a href="#round" class="headerlink" title="round"></a>round</h3><p><br>python<br>round(number[, ndigits])<br>round ngigits0.ngigits&lt;0 .</p><h3 id="round-"><a href="#round-" class="headerlink" title="round "></a>round </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0  </span></span><br><span class="line">round(<span class="number">0.5</span>) <span class="comment"># 1.0  </span></span><br><span class="line">round(<span class="number">-0.5</span>) <span class="comment">#-1.0</span></span><br></pre></td></tr></table></figure><h3 id="round-"><a href="#round-" class="headerlink" title="round "></a>round </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">round(<span class="number">1.675</span>, <span class="number">2</span>) <span class="comment">#1.68  </span></span><br><span class="line">round(<span class="number">2.675</span>, <span class="number">2</span>) <span class="comment">#2.67</span></span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">round(<span class="number">3.4</span>) <span class="comment"># 3.0  </span></span><br><span class="line">round(<span class="number">3.5</span>) <span class="comment"># 4.0  </span></span><br><span class="line">round(<span class="number">3.6</span>) <span class="comment"># 4.0  </span></span><br><span class="line">round(<span class="number">3.6</span>, <span class="number">0</span>) <span class="comment"># 4.0  </span></span><br><span class="line">round(<span class="number">1.95583</span>, <span class="number">2</span>) <span class="comment"># 1.96  </span></span><br><span class="line">round(<span class="number">1241757</span>, <span class="number">-3</span>) <span class="comment"># 1242000.0  </span></span><br><span class="line">round(<span class="number">5.045</span>, <span class="number">2</span>) <span class="comment"># 5.05  </span></span><br><span class="line">round(<span class="number">5.055</span>, <span class="number">2</span>) <span class="comment"># 5.06</span></span><br></pre></td></tr></table></figure><h2 id="np-clip"><a href="#np-clip" class="headerlink" title="np.clip"></a><font color="#0099ff" size="7" face="">np.clip</font></h2><p>numpy.clip(a, a_min, a_max, out=None)[source]<br>a</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x=np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">np.clip(x,<span class="number">3</span>,<span class="number">8</span>)</span><br><span class="line">Out[<span class="number">88</span>]:</span><br><span class="line">array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>self-attention</title>
      <link href="/2019/06/16/self-attention/"/>
      <url>/2019/06/16/self-attention/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://kexue.fm/archives/4765" target="_blank" rel="noopener">https://kexue.fm/archives/4765</a></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>-----python</title>
      <link href="/2019/05/22/%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E5%BC%8F%E5%88%86%E6%94%AF%E9%99%90%E7%95%8C%E6%B3%95-%E6%9C%80%E5%B0%8F%E9%87%8D%E9%87%8F%E6%9C%BA%E5%99%A8%E8%AE%BE%E8%AE%A1%E9%97%AE%E9%A2%98-python%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/05/22/%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E5%BC%8F%E5%88%86%E6%94%AF%E9%99%90%E7%95%8C%E6%B3%95-%E6%9C%80%E5%B0%8F%E9%87%8D%E9%87%8F%E6%9C%BA%E5%99%A8%E8%AE%BE%E8%AE%A1%E9%97%AE%E9%A2%98-python%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p></p><p>1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## FIFO </span></span><br><span class="line"><span class="comment">##  d</span></span><br><span class="line"><span class="comment">## n</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding : utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n = <span class="number">3</span></span><br><span class="line">m = <span class="number">3</span></span><br><span class="line">d = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">price = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]</span><br><span class="line">weight = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Level</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getlevel</span><span class="params">(m, currrent)</span>:</span></span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    level = <span class="number">0</span></span><br><span class="line">    sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> currrent == <span class="number">0</span>:</span><br><span class="line">        level = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> level</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">        level = level+<span class="number">1</span></span><br><span class="line">        sum = m**level + sum  <span class="comment"># sum=m</span></span><br><span class="line">        <span class="keyword">if</span> sum-m**level &lt; currrent &lt;= sum:  <span class="comment"># m-m^0 = m-1</span></span><br><span class="line">            <span class="keyword">return</span> level</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_idx</span><span class="params">(m, current)</span>:</span></span><br><span class="line">    level = getlevel(m, current)</span><br><span class="line">    <span class="comment"># current level level</span></span><br><span class="line">    current_level_idx = current - sum([m**i <span class="keyword">for</span> i <span class="keyword">in</span> range(level)])</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    start_idx  = sum([m**i <span class="keyword">for</span> i <span class="keyword">in</span> range(level+<span class="number">1</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> start_idx + current_level_idx*m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_path</span><span class="params">(m, current)</span>:</span></span><br><span class="line">    path = []</span><br><span class="line">    path.append(current%m)  <span class="comment"># from 1, not from 0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        level = getlevel(m, current)</span><br><span class="line">        <span class="keyword">if</span> level == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> path[::<span class="number">-1</span>]</span><br><span class="line">        current_level_idx = current - sum([m ** i <span class="keyword">for</span> i <span class="keyword">in</span> range(level)])  <span class="comment"># # current level level</span></span><br><span class="line">        path.append(current_level_idx // m + <span class="number">1</span>)  <span class="comment"># </span></span><br><span class="line">        current = sum([m ** i <span class="keyword">for</span> i <span class="keyword">in</span> range(level<span class="number">-1</span>)]) + current_level_idx // m  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MinWighet</span><span class="params">(n,m,d,price,weight)</span>:</span></span><br><span class="line">    minweight = float(<span class="string">"inf"</span>)</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    vec_len = sum([m ** i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n+<span class="number">1</span>)]) + <span class="number">1</span></span><br><span class="line">    que = queue.Queue()</span><br><span class="line">    que.put(<span class="number">0</span>)</span><br><span class="line">    vec_price = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(vec_len)]</span><br><span class="line">    vec_weight = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(vec_len)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(<span class="keyword">not</span> que.empty()):</span><br><span class="line">        current = que.get()  <span class="comment"># </span></span><br><span class="line">        level = getlevel(m, current)  <span class="comment">#  level</span></span><br><span class="line"></span><br><span class="line">        idx = get_idx(m, current)   <span class="comment"># </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        <span class="keyword">if</span> getlevel(m, current) == getlevel(m, vec_len)<span class="number">-1</span>:</span><br><span class="line">            minweight = vec_price[current]</span><br><span class="line">            min_at_idx = current</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">not</span> que.empty()):</span><br><span class="line">                <span class="comment"># minweight = min(minweight, vec_price[que.get()])</span></span><br><span class="line">                tmp = que.get()</span><br><span class="line">                <span class="keyword">if</span> minweight &gt; vec_price[tmp]:</span><br><span class="line">                    minweight = vec_price[tmp]</span><br><span class="line">                    min_at_idx = tmp</span><br><span class="line">            path = get_path(m, min_at_idx)</span><br><span class="line">            <span class="keyword">return</span> minweight, path</span><br><span class="line"></span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            vec_price[idx] = int(vec_price[current] + price[level][i])</span><br><span class="line">            <span class="keyword">if</span> vec_price[idx] &lt;= d:</span><br><span class="line">                vec_weight[idx] = int(vec_weight[current] + weight[level][i])</span><br><span class="line">                que.put(idx)</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(MinWighet(n,m,d,price,weight))</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt=""></p><p>2 </p><p>m<br>x[1:n]  n x[i] i</p><p><br><br>wij</p><p></p><p>1<br>2<br>3<br>4</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## FIFO </span></span><br><span class="line"><span class="comment">##  d</span></span><br><span class="line"><span class="comment">## n</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --</span></span><br><span class="line"><span class="comment"># append</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding : utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Level</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getlevel</span><span class="params">(m, currrent)</span>:</span></span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    level = <span class="number">0</span></span><br><span class="line">    sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> currrent == <span class="number">0</span>:</span><br><span class="line">        level = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> level</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">        level = level+<span class="number">1</span></span><br><span class="line">        sum = m**level + sum  <span class="comment"># sum=m</span></span><br><span class="line">        <span class="keyword">if</span> sum-m**level &lt; currrent &lt;= sum:  <span class="comment"># m-m^0 = m-1</span></span><br><span class="line">            <span class="keyword">return</span> level</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_idx</span><span class="params">(m, current)</span>:</span></span><br><span class="line">    level = getlevel(m, current)</span><br><span class="line">    <span class="comment"># current level level</span></span><br><span class="line">    current_level_idx = current - sum([m**i <span class="keyword">for</span> i <span class="keyword">in</span> range(level)])</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    start_idx  = sum([m**i <span class="keyword">for</span> i <span class="keyword">in</span> range(level+<span class="number">1</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> start_idx + current_level_idx*m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_path</span><span class="params">(m, current)</span>:</span></span><br><span class="line">    path = []</span><br><span class="line">    path.append(current%m)  <span class="comment"># from 1, not from 0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        level = getlevel(m, current)</span><br><span class="line">        <span class="keyword">if</span> level == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> path[::<span class="number">-1</span>]</span><br><span class="line">        current_level_idx = current - sum([m ** i <span class="keyword">for</span> i <span class="keyword">in</span> range(level)])  <span class="comment"># # current level level</span></span><br><span class="line">        path.append(current_level_idx // m + <span class="number">1</span>)  <span class="comment"># </span></span><br><span class="line">        current = sum([m ** i <span class="keyword">for</span> i <span class="keyword">in</span> range(level<span class="number">-1</span>)]) + current_level_idx // m  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, idx, weight)</span>:</span></span><br><span class="line">        self.idx = idx</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MinWighet</span><span class="params">(n,m,d,price,weight)</span>:</span></span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    vec_len = sum([m ** i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n+<span class="number">1</span>)]) + <span class="number">1</span></span><br><span class="line">    que = []</span><br><span class="line">    que.append(Node(<span class="number">0</span>,<span class="number">0</span>))  <span class="comment"># </span></span><br><span class="line">    <span class="comment"># vec_price = [0 for _ in range(vec_len)]</span></span><br><span class="line">    <span class="comment"># vec_weight = [0 for _ in range(vec_len)]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(que):  <span class="comment"># </span></span><br><span class="line">        que = sorted(que, key=<span class="keyword">lambda</span> node: node.weight)  <span class="comment"># </span></span><br><span class="line">        current = que[<span class="number">0</span>]  <span class="comment"># </span></span><br><span class="line">        level = getlevel(m, current.idx)  <span class="comment">#  level</span></span><br><span class="line"></span><br><span class="line">        new_node_idx = get_idx(m, current.idx)   <span class="comment"># </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        <span class="keyword">if</span> getlevel(m, current.idx) == getlevel(m, vec_len)<span class="number">-1</span>:</span><br><span class="line">            minweight = current.weight</span><br><span class="line">            min_at_idx = current.idx</span><br><span class="line"></span><br><span class="line">            path = get_path(m, min_at_idx)</span><br><span class="line">            <span class="keyword">return</span> minweight, path</span><br><span class="line"></span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="keyword">if</span> int(current.weight + price[level][i]) &lt;= d:</span><br><span class="line">                new_node = Node(new_node_idx, int(current.weight + weight[level][i]))</span><br><span class="line">                que.append(new_node)</span><br><span class="line">            new_node_idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        <span class="keyword">del</span> que[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    n = <span class="number">3</span></span><br><span class="line">    m = <span class="number">3</span></span><br><span class="line">    d = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    price = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]</span><br><span class="line">    weight = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]</span><br><span class="line">    result = MinWighet(n,m,d,price,weight)</span><br><span class="line">    print(MinWighet(n,m,d,price,weight))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Grounded Video Description</title>
      <link href="/2019/05/10/Grounded-Video-Description/"/>
      <url>/2019/05/10/Grounded-Video-Description/</url>
      
        <content type="html"><![CDATA[<h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><ul><li>CVPR 2019 ActivityNet dense captionobject bbox</li><li><font color="#dd00dd">1. object . 2. video(object)</font><br></li><li>grounded-based video description model descriptionobjectregion feature penalize grounding</li></ul><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul><li>videoobjectvideo similar contextsvideoobejctvideoobject</li><li> object sentence  evidence of video <br><font color="#0099ff" size="5">object </font><font color="#0099ff" size="5"></font>teaching models to explicitly rely on the corresponding evidence in the video frame  when generating words and evaluating how well models   are doing in grounding individual words or phrases they  generated.<br>object sentencevideosentence</li></ul><h2 id="bbox"><a href="#bbox" class="headerlink" title="bbox"></a>bbox</h2><ul><li>we collect ActivityNet-Entities (short as ANet-Entities) which  grounds or links noun phrases in sentences with bounding  boxes in the video frames.<br>we only  annotate a single frame of the video for each noun phrase <br> sentence(bbox)videosentence </li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="1-object-feature-captioning"><a href="#1-object-feature-captioning" class="headerlink" title="1. object feature captioning"></a>1. object feature captioning</h3><ul><li><strong></strong>1off-the-shelf fine-tuned  object detector  object proposals 2object featuresattentionregion decoder</li><li><strong></strong>object detector object proposals  source dataset , target datasettarget dataset fine-tune object detectorvideo</li><li><font color="#0099ff" size="5" face="">(fine-tune obejct detector)</font>Instead of  fine-tuning a general detector, we transfer the object classification knowledge from off-the-shelf object detectors to  our model and then fine-tune this representation as part of  our generation model with sparse box annotations. </li><li>4.4bboxthe class probability distribution for each region. visual genomedetector<strong>object classifier</strong> classesKVisual Genomeclasses  softmax( Wx+b )W  b detectorWK<h3 id="2-object-attention"><a href="#2-object-attention" class="headerlink" title="2. object attention"></a>2. object attention</h3></li><li>attention modelregionattention supervisionfeature map attention </li><li>region attention with supervision object context <font color="#0099ff" size="5" face="">attention modelcontext encoding self-attention</font>regions (region feature fc grounding-aware region encoding 4.3  4.4<strong>R<sup>~</sup></strong> ) </li></ul><h2 id="Description-with-Grounding-Supervision"><a href="#Description-with-Grounding-Supervision" class="headerlink" title="Description with Grounding Supervision"></a>Description with Grounding Supervision</h2><ul><li>: <strong>grounding</strong>, <strong>region attention</strong> and <strong>language generation</strong>.<br>grounding word videovisual clue<br>region attention: visual clue high-leveldecoder   </li><li>object-level supervision: <strong>region classification</strong>,  <strong>object grounding (localization)</strong>, and <strong>supervised attention</strong>.  </li><li><strong>supervised attentionattentionlossobject grounding region attentionregion classificationloss M<sub>s</sub>( R ), region encoding, region attention  language generate</strong></li></ul><h3 id="Language-Generation-Module"><a href="#Language-Generation-Module" class="headerlink" title="Language Generation Module"></a>Language Generation Module</h3><ul><li>decoder  [1] decoderbottom up[3] <strong>[1]</strong> language lstmattention of region feature attention of k girdslanguage lstmattention of region features  attention of frames featuresregion attention  temporal attention</li><li><font color="#0099ff" size="5" face="">temporal attention</font>[2]self-attention context encoder with Bidirectional GRU (Bi-GRU)[1]attention</li><li><font color="#0099ff" size="5" face="">region attention</font>bottom up attention</li><li>[1]    <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2x5hlq801j30l20ezq4v.jpg">   </li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Region-proposal-and-features"><a href="#Region-proposal-and-features" class="headerlink" title="Region proposal and features"></a>Region proposal and features</h3><p>For each frame, we use a Faster  R-CNN detector [24] with ResNeXt-101 backbone [30] for  region proposal and feature extraction (fc6). The detector is  pretrained on Visual Genome</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Neural baby talk. In CVPR 2018.<br>[2] End-to-end dense video captioning with masked transformer. In CVPR 2018.<br>[3] Bottom-up and top-down attention for image captioning and  visual question answering. In CVPR 2018.</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video CaptioningCVPR2019</title>
      <link href="/2019/05/10/Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning-1/"/>
      <url>/2019/05/10/Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning-1/</url>
      
        <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/09/02/T5AzpW8DHkVL2Oy.png" alt="20190902152617.png"></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li><strong>temporal dynamics</strong>videoCNNfourier </li><li>object detector object <strong> spatial dynamics</strong></li><li></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>object detector YOLO[1]</li><li>C3D</li><li></li></ul><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>video captioning model attentionhigh levelCNN</p><h2 id="Visual-Representation"><a href="#Visual-Representation" class="headerlink" title="Visual Representation"></a>Visual Representation</h2><ul><li>the visual representation of a  video V as v = [; ; ; ]</li><li>; ; ;  <h3 id="Encoding-temporal-dynamics"><a href="#Encoding-temporal-dynamics" class="headerlink" title="Encoding temporal dynamics"></a>Encoding temporal dynamics</h3></li><li> f  CNN[2]cclipC3D[3]</li><li>videoa<strong></strong>pap p7m mp7<strong></strong></li><li><strong></strong>clipsC3D</li><li></li><li><font color="#0099ff" size="4" face="">rich temporal dynamics?</font></li></ul><h3 id="Encoding-Semantics-and-Spatial-Evolution"><a href="#Encoding-Semantics-and-Spatial-Evolution" class="headerlink" title="Encoding Semantics and Spatial Evolution"></a>Encoding Semantics and Spatial Evolution</h3><ul><li>object detector YOLO Object C3D</li></ul><h2 id="Experimental-Results-on-MSVD"><a href="#Experimental-Results-on-MSVD" class="headerlink" title="Experimental Results on MSVD"></a>Experimental Results on MSVD</h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2wd8q6kegj30dh0ig0wc.jpg">    <ul><li>GRU-MP - (C3D)  GRU-EVEhft - (C3D)  </li><li>GRU-EVEhft - (CI) GRU-EVEhft+sem - (CI)senmatic </li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Yolo9000: better, faster, stronger.  In IEEE CVPR, 2017<br>[2] Inception-v4, inception-resnet and the impact of residual  connections on learning. In AAAI, volume 4, page 12, 2017.<br>[3] Learning spatiotemporal features with 3d convolutional networks. In Proceedings of the IEEE international conference  on computer vision, pages 44894497, 2015.</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python-dict</title>
      <link href="/2019/05/08/python-dict/"/>
      <url>/2019/05/08/python-dict/</url>
      
        <content type="html"><![CDATA[<h1 id="dict-get-"><a href="#dict-get-" class="headerlink" title="dict get "></a>dict get </h1><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>Python (Dictionary) get() </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>get()</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dict.<span class="builtin-name">get</span>(key, <span class="attribute">default</span>=None)</span><br></pre></td></tr></table></figure><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li>key  </li><li>default  </li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>None</p><h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><p>getkeykeydefaultdefaultNone</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</title>
      <link href="/2019/05/06/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention/"/>
      <url>/2019/05/06/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention/</url>
      
        <content type="html"><![CDATA[<ul><li>encoder  attention<br>attention <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2re7nfbn3j30q70430sx.jpg"></li></ul><p><a href="https://blog.csdn.net/shenxiaolu1984/article/details/51493673" target="_blank" rel="noopener">https://blog.csdn.net/shenxiaolu1984/article/details/51493673</a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/21/%E6%B1%A0%E5%8C%96%E5%B1%82%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
      <url>/2019/04/21/%E6%B1%A0%E5%8C%96%E5%B1%82%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</url>
      
        <content type="html"><![CDATA[<ul><li> <a href="https://blog.csdn.net/qq_21190081/article/details/72871704" target="_blank" rel="noopener">https://blog.csdn.net/qq_21190081/article/details/72871704</a></li><li><br>122-&gt;1 1-&gt;22x, 4 1/4<br>122-&gt;1 1-&gt;22x, 0</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>An End-to-End Baseline for Video Captioning</title>
      <link href="/2019/04/20/An-End-to-End-Baseline-for-Video-Captioning/"/>
      <url>/2019/04/20/An-End-to-End-Baseline-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h3 id="--"><a href="#--" class="headerlink" title="  "></a>  </h3><p> loss, batch size<br></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>end-to-endGPUend-to-end fine-tune </p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>encoder CNN video captioningvideo/image featurefine tune<br>[1][2][3]</p><h4 id="fine-tune-encoder"><a href="#fine-tune-encoder" class="headerlink" title="fine-tune encoder"></a>fine-tune encoder</h4><p>1because of the amount of memory required to process  video data for each batch<br>2batch sizes for video captioning can become very high (e.g. 512), making training  prohibitive on a small number of GPUsGPU</p><h4 id="-"><a href="#-" class="headerlink" title="-"></a>-</h4><p>In this paper we address this issue by accumulating gradients over multiple steps, to update parameters only after  the required effective batch size is achieved.<br>(512examples)<br>encoderdecoderend-to-endfine-tune</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ol><li></li><li>GPURNNdecoders</li><li></li><li>baseline</li></ol><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ol><li>encoder</li><li>encoderdecoder</li><li>Inception-ResNet-v2BNaccumulating gradients over multiple steps, to update parameters only after  the required effective batch size is achieved. </li></ol><ul><li>2. 3. SA-LSTMtarget words(ground truth)</li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p> Inception-ResNet-v2[5] as an encoderand a modified version of  Soft-Attention LSTM as a decoder.<br> <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2ad637ykjj30hy0h677d.jpg">    </p><ul><li>decoder<ul><li>LSTMinput: <strong>x<sup>t</sup></strong> <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aeagi7o3j30a30280sl.jpg">    - step word<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aeiriwanj30jd014mx7.jpg"></li></ul></li></ul><p>soft-attentionattention soft-attention[2] </p><ul><li><p>soft-attention</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aeagheogj308o03ct8l.jpg">     </li><li><p><sub>t</sub></p></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aeagka0rj30h504dq37.jpg">   <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aeaggzpdj309302xdfq.jpg">   <ul><li><font color="#0099ff" size="5" face="">Figure2 concatenate !</font></li></ul><ul><li><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aes6w62rj30il09xwgp.jpg"></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>step1 : encoderencoderdecoder</li><li>step2step1encoder-decoder</li><li>MSR-VTT<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2ajqfodpkj30kl0b9acc.jpg">  </li><li>MSVD<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2ajqfqhbjj30ks0icn0q.jpg"></li></ul><h4 id="yaya-step1soft-attention-lstm-"><a href="#yaya-step1soft-attention-lstm-" class="headerlink" title=" yaya step1soft-attention lstm "></a><font color="#0099ff" size="5" face=""> yaya step1soft-attention lstm </font></h4><p>step1encoderdecoder </p><ol><li> Inception-ResNet-v2encoderencoder</li><li><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2ak8as8u4j309703pglo.jpg"></li><li>SA-LSTM[2]<br>1frame features soft-attention<sub>t</sub><br>2LSTM<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2ajg7vn8rj31fi0ci427.jpg">3wordE[y<sub>t-1</sub>] - soft-attention <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2aeiriwanj30jd014mx7.jpg"> - <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g2ajjxtsplj30d103v74i.jpg">- 3.3.2These changes are inspired by  the original code repository by Yao et al [2]</li></ol><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Video captioning with  transferred semantic attributes. CVPR, 2017<br>[2] Describing videos by exploiting temporal  structure. ICCV, 2015.<br>[3] Task-driven dynamic fusion: Reducing ambiguity in video description. CVPR, 2017.<br>[4] Show and  tell: Lessons learned from the 2015 mscoco image captioning challenge. TPAMI, 2016.<br>[5] Inception-v4, inception-resnet and the impact of residual  connections on learning. AAAI, 2017</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python list</title>
      <link href="/2019/04/18/python-%E5%85%B3%E4%BA%8Elist%E7%9A%84%E6%93%8D%E4%BD%9C/"/>
      <url>/2019/04/18/python-%E5%85%B3%E4%BA%8Elist%E7%9A%84%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h3 id="list-"><a href="#list-" class="headerlink" title="list "></a>list </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">nums[<span class="number">0</span>],nums[<span class="number">1</span>] = nums[<span class="number">1</span>],nums[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># nums = [2,1,3]</span></span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = []</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> a:</span><br><span class="line">    print(<span class="string">"a is a null list"</span>)</span><br><span class="line"><span class="comment"># a is a null list</span></span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]</span><br><span class="line">c = a + b</span><br><span class="line">print(c)  <span class="comment"># [1, 2, 3, 6, 7, 8]</span></span><br><span class="line">d = a.extend(b)  <span class="comment"># extend() </span></span><br><span class="line">print(d) </span><br><span class="line"><span class="comment"># d None ,extend  a[1, 2, 3, 6, 7, 8]</span></span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = [2,4,6,5]</span><br><span class="line">b = a.sort()  # a = [2,4,5,6] , b = None</span><br><span class="line">a= [2,4,6,5]  </span><br><span class="line">b = sorted(a)  # a = [2, 4, 6, 5] , b = [2, 4, 5, 6]</span><br><span class="line"></span><br><span class="line">## sorted() </span><br><span class="line">## sort() </span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">b = a.reverse() <span class="comment"># a=[4,3,2,1] b = None</span></span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p> nums<br> nums.function()<br> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">nums.extend([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])     <span class="comment"># [1, 2, 3, 4, 1, 2, 3]</span></span><br><span class="line">nums.append(<span class="number">2</span>)           <span class="comment"># [1, 2, 3, 4, 1, 2, 3, 2]</span></span><br><span class="line">nums.sort()              <span class="comment"># [1, 1, 2, 2, 2, 3, 3, 4]</span></span><br><span class="line">nums.reverse()           <span class="comment"># [4, 3, 3, 2, 2, 2, 1, 1]</span></span><br><span class="line">nums.insert(<span class="number">5</span>,<span class="number">100</span>)       <span class="comment"># [4, 3, 3, 2, 2, 100, 2, 1, 1]    5100</span></span><br></pre></td></tr></table></figure><ul><li><br>nums.index(100)          # <strong>5</strong>, <strong></strong></li></ul><h3 id="-123-gt-1-2-3"><a href="#-123-gt-1-2-3" class="headerlink" title="  123 -&gt; [1, 2, 3]"></a>  123 -&gt; [1, 2, 3]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num = <span class="number">123</span></span><br><span class="line">A = list(str(num))  <span class="comment"># A = ['1', '2', '3']</span></span><br><span class="line">B = int(<span class="string">""</span>.join(A))  <span class="comment"># B = 123</span></span><br></pre></td></tr></table></figure><h3 id="-for"><a href="#-for" class="headerlink" title=" for"></a> for</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">-7</span>,<span class="number">0</span>,]</span><br><span class="line">a = [<span class="number">1</span> <span class="keyword">if</span> num &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> num <span class="keyword">in</span> nums]</span><br><span class="line">print(a)   <span class="comment"># [1, 1, 0, 0]</span></span><br></pre></td></tr></table></figure><h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p><a href="https://wiki.python.org/moin/TimeComplexity" target="_blank" rel="noopener">https://wiki.python.org/moin/TimeComplexity</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(two pointers)</title>
      <link href="/2019/04/18/%E5%8F%8C%E6%8C%87%E9%92%88-two-pointers/"/>
      <url>/2019/04/18/%E5%8F%8C%E6%8C%87%E9%92%88-two-pointers/</url>
      
        <content type="html"><![CDATA[<ul><li><br> <a href="https://blog.csdn.net/sylar_d/article/details/52742598" target="_blank" rel="noopener">https://blog.csdn.net/sylar_d/article/details/52742598</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>pytorch0.4.0</title>
      <link href="/2019/04/18/pytorch0-4-0%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/04/18/pytorch0-4-0%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><ol><li>SGD  Adam weight_decay </li><li>SGD  momentum</li><li>pytorch  </li><li>y = y.permute(0, 2, 1).contiguous()<br></li></ol><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>loss<br>0.3.0loss(loss)total_loss+=loss.data[0] , , .data[0]? , lossVariable,<br>loss, loss.item()., , , lossgraph, .<br>total_loss, graph!</li></ul><h3 id="pytorch--tensor"><a href="#pytorch--tensor" class="headerlink" title="pytorch  tensor"></a>pytorch  tensor</h3><ul><li><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)  <span class="comment"># </span></span><br><span class="line">a.sum()                 <span class="comment"># a</span></span><br></pre></td></tr></table></figure></li><li><p>tensor </p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">a</span> = torch.randn(<span class="number">10</span>,<span class="number">8</span>)</span><br><span class="line">max_value, max_index = <span class="keyword">a</span>.<span class="built_in">max</span>(<span class="number">1</span>)   </span><br><span class="line"><span class="comment"># a 110,1</span></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure></li><li><p></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>])</span><br><span class="line">a.eq(b)   #  tensor([ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">0</span>], dtype=torch.uint8)</span><br></pre></td></tr></table></figure></li><li><p></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#  pytorch <span class="number">0.3</span><span class="number">.0</span></span><br><span class="line">output = torch.bmm(W, x)</span><br><span class="line"></span><br><span class="line">#  pytorch <span class="number">0.4</span><span class="number">.0</span></span><br><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = torch.rand(<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">c = torch.matmul(a, b)</span><br><span class="line">print(c.shape)  # torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"># pytorch <span class="number">0.4</span><span class="number">.0</span>torch.matmul <span class="number">3</span>dtensor ,tensorbatch_size</span><br></pre></td></tr></table></figure></li><li><p>tensor </p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># tensor </span><br><span class="line">x = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">x = x.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">print(x.shape)  # torch.Size([<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure></li><li><p>chunk  cat </p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(inputs, <span class="attribute">dimension</span>=0)  Tensor</span><br><span class="line"><span class="comment"># cat tensor</span></span><br><span class="line">torch.chunk(tensor, chunks, <span class="attribute">dim</span>=0)</span><br><span class="line"><span class="comment"># chunktensor</span></span><br></pre></td></tr></table></figure></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn as nn</span><br><span class="line">self.W = nn.Conv2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">1024</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), \</span><br><span class="line">                   padding=(<span class="number">1</span>,<span class="number">1</span>), stride=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">nn.init.kaiming.normal(self.W.weight)</span><br><span class="line">nn.init.kaiming.uniform(self.W.weight)</span><br><span class="line">nn.init.constant(self.W.bias, <span class="number">0</span>)</span><br><span class="line">#  tensor([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(dynamic programming)</title>
      <link href="/2019/04/18/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-dynamic-programming/"/>
      <url>/2019/04/18/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-dynamic-programming/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>1<br>2<br>grid    </p><ul><li>   </li><li>   </li><li>   </li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li>    </li><li>for   </li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li><a href="https://leetcode.com/problems/maximum-subarray/" target="_blank" rel="noopener">https://leetcode.com/problems/maximum-subarray/</a>  </li><li><a href="https://leetcode.com/problems/maximum-product-subarray/" target="_blank" rel="noopener">https://leetcode.com/problems/maximum-product-subarray/</a>  </li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(sort)</title>
      <link href="/2019/04/18/%E6%8E%92%E5%BA%8F-sort/"/>
      <url>/2019/04/18/%E6%8E%92%E5%BA%8F-sort/</url>
      
        <content type="html"><![CDATA[<ul><li>O(1)O(n)</li><li>O(nlogn)O(n^2)</li><li>O(n^2)</li><li>O(n^2)</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><blockquote><p></p></blockquote><h2 id=""><a href="#" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    tmp = left</span><br><span class="line">    reference = nums[left]  <span class="comment"># nums[left] </span></span><br><span class="line">    left = left</span><br><span class="line">    <span class="keyword">while</span> left &lt; right:</span><br><span class="line">        <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[left] &lt;= reference:</span><br><span class="line">            left = left + <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[right] &gt; reference:</span><br><span class="line">            right = right - <span class="number">1</span></span><br><span class="line">        nums[left], nums[right] = nums[right], nums[left]</span><br><span class="line">    <span class="keyword">if</span> nums[left] &lt; reference:</span><br><span class="line">        nums[left], nums[tmp] = nums[tmp], nums[left]</span><br><span class="line">        <span class="keyword">return</span> left</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        nums[left<span class="number">-1</span>], nums[tmp] = nums[tmp], nums[left<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">return</span> left<span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">QuickSort</span><span class="params">(nums , left, right)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left &lt; right:</span><br><span class="line">        index = partition(nums, left, right)</span><br><span class="line">        QuickSort(nums, left, index<span class="number">-1</span>)</span><br><span class="line">        QuickSort(nums, index+<span class="number">1</span>, right)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">6</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>]</span><br><span class="line"><span class="comment"># nums = [1,2,3,4]</span></span><br><span class="line"><span class="comment"># nums = [3,2,5,6,4,4,4,5,6]</span></span><br><span class="line">left = <span class="number">0</span></span><br><span class="line">right = len(nums)<span class="number">-1</span></span><br><span class="line">QuickSort(nums, left, right)</span><br><span class="line">print(nums)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/18/%E7%AE%97%E6%B3%95/"/>
      <url>/2019/04/18/%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/19131887" target="_blank" rel="noopener"></a></p></li><li><p><a href="https://shiyaya.github.io/2019/04/18/%E5%8F%8C%E6%8C%87%E9%92%88-two-pointers/" target="_blank" rel="noopener"></a></p></li><li><p><a href="https://shiyaya.github.io/2019/04/18/%E6%8E%92%E5%BA%8F-sort/" target="_blank" rel="noopener"></a></p></li><li><p><a href="https://shiyaya.github.io/2019/04/18/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-dynamic-programming/" target="_blank" rel="noopener"></a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python </title>
      <link href="/2019/04/10/python-%E5%87%BD%E6%95%B0/"/>
      <url>/2019/04/10/python-%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>numpy</title>
      <link href="/2019/04/09/numpy%E5%B9%BF%E6%92%AD/"/>
      <url>/2019/04/09/numpy%E5%B9%BF%E6%92%AD/</url>
      
        <content type="html"><![CDATA[<ul><li></li></ul><h1 id="NumPy--Broadcast"><a href="#NumPy--Broadcast" class="headerlink" title="NumPy (Broadcast)"></a>NumPy (Broadcast)</h1><p>(Broadcast) numpy (shape) </p><p> a  b  <strong>a.shape == b.shape</strong> a*b  a  b </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>import numpy as np    a = np.array([1,2,3,4])  b = np.array([10,20,30,40])  c = a * b  print (c)</p><p></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="number">10</span>  <span class="number">40</span>  <span class="number">90</span> <span class="number">160</span>]</span><br></pre></td></tr></table></figure><p> 2 numpy </p><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np    </span><br><span class="line">a = np.array([[ <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],            [<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>],            [<span class="number">20</span>,<span class="number">20</span>,<span class="number">20</span>],            [<span class="number">30</span>,<span class="number">30</span>,<span class="number">30</span>]]) </span><br><span class="line">b = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) print(a + b)</span><br></pre></td></tr></table></figure><p></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line"> [<span class="number">11</span> <span class="number">12</span> <span class="number">13</span>]</span><br><span class="line"> [<span class="number">21</span> <span class="number">22</span> <span class="number">23</span>]</span><br><span class="line"> [<span class="number">31</span> <span class="number">32</span> <span class="number">33</span>]]</span><br></pre></td></tr></table></figure><p> b  a </p><p><img src="http://www.runoob.com/wp-content/uploads/2018/10/image0020619.gif" alt="img"></p><p>4x3  3  b  4 </p><h2 id="yayay"><a href="#yayay" class="headerlink" title="yayay"></a>yayay</h2><p>few-shot gnnA<strong>a<sub>ij</sub> = fc(v<sub>i</sub>-v<sub>j</sub>)</strong><br>NNNN</p><pre><code class="python"><span class="keyword">import</span> numpy <span class="keyword">as</span> npN = <span class="number">10</span>D = <span class="number">7</span>X = np.ones((N,D))X1 = np.expand_dims(X, axis=<span class="number">0</span>)X2 = np.expand_dims(X, axis=<span class="number">1</span>)X_abs = np.abs(X1-X2)X_abs = np.reshape(X_abs, (N,N,D))X_T = X_abs ?????????????????</code></pre>]]></content>
      
      
      <categories>
          
          <category> numpy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(few-shot learning)</title>
      <link href="/2019/04/09/%E5%B0%91%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0-few-shot-learning/"/>
      <url>/2019/04/09/%E5%B0%91%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0-few-shot-learning/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li>(few-shot learning)<strong>(Seen Class)(Unseen Class)</strong></li><li><br>1(finetune)<br>2(15)</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/09/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87/"/>
      <url>/2019/04/09/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/29895933" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29895933</a><br><a href="https://www.jianshu.com/p/41218cb5e099" target="_blank" rel="noopener">https://www.jianshu.com/p/41218cb5e099</a></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><strong>v<sub>t</sub></strong>   _t  t<br><strong><sub>t</sub></strong> t<br><strong></strong>   </p><p>t<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1wnugwmkrj30ne0ggjsp.jpg" width="50%" height="50%">    </p><p><strong>v<sub>100</sub></strong> :<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1wonisescj30j201o0sr.jpg"><br>v<sub>t</sub> <strong></strong></p><p><img src="https://upload-images.jianshu.io/upload_images/1667471-485da343fbd96353.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/665/format/webp" alt><br></p><p>  = 0.9 <strong></strong> 10 <br>  = 0.98 <strong></strong> 50 <br>  = 0.5 <strong></strong> 2 </p><p><img src="//upload-images.jianshu.io/upload_images/1667471-7d82e7b89e860299.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/473/format/webp" alt></p><p><img src="//upload-images.jianshu.io/upload_images/1667471-6fd989467bcb6121.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/475/format/webp" alt></p><p><strong> </strong></p><p><strong> </strong><br> 0.02  0.98 <br></p><p> <strong> 0.9 </strong></p><p><br><a href="https://www.jianshu.com/p/41218cb5e099" target="_blank" rel="noopener">https://www.jianshu.com/p/41218cb5e099</a><br>  </p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>0nn</p><p>0-(n-1)n</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>  </p><p> Momentum </p><p><strong>Momentum </strong><strong></strong></p><p><strong></strong></p><p></p><p><img src="//upload-images.jianshu.io/upload_images/1667471-07d825d3e2624537.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/745/format/webp" alt></p><p><br><strong></strong></p><p><strong></strong></p><p></p><p> Momentum <strong> dw  db </strong></p><p><img src="//upload-images.jianshu.io/upload_images/1667471-eedf9342a4bce813.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/272/format/webp" alt></p><p></p><p><img src="//upload-images.jianshu.io/upload_images/1667471-f9e70b57daae0359.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/718/format/webp" alt></p><p><br><strong></strong><br><strong></strong><br></p><p><br><a href="https://www.jianshu.com/p/41218cb5e099" target="_blank" rel="noopener">https://www.jianshu.com/p/41218cb5e099</a><br>  </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title> Model Pruning</title>
      <link href="/2019/04/09/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D-Model-Pruning/"/>
      <url>/2019/04/09/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D-Model-Pruning/</url>
      
        <content type="html"><![CDATA[<p><a href="https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/" target="_blank" rel="noopener">https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/</a><br>L1<br>L1filter</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/09/%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB%E6%80%BB%E7%BB%93/"/>
      <url>/2019/04/09/%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="Two-Stream"><a href="#Two-Stream" class="headerlink" title="Two-Stream"></a>Two-Stream</h3><ul><li><br>1spatial netvideo1224<em>224</em>3<br>2temporal netvideoL=10224<em>224</em>2L<br>x,y 1055</li><li>video25crop and flip10video250</li></ul><h3 id="TSN"><a href="#TSN" class="headerlink" title="TSN"></a>TSN</h3><ul><li>video3<br>1spatial netvideoN1NNNscorevideo<br>2temporal net ,videoNL=10NNscorevideo</li><li>video25</li><li></li></ul><h3 id="C3D"><a href="#C3D" class="headerlink" title="C3D"></a>C3D</h3><ul><li>Sports-1Mvideo feature extractor </li><li>video52sclipclip </li><li>videoNN16clipsclips8clipsfc6 activations <strong>video feature</strong>video class label</li></ul><h3 id="I3D"><a href="#I3D" class="headerlink" title="I3D"></a>I3D</h3><ul><li>video 25/</li><li>64snippets</li><li>64snippetsvideosnippet<strong></strong>video</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>I3D</title>
      <link href="/2019/04/09/I3D/"/>
      <url>/2019/04/09/I3D/</url>
      
        <content type="html"><![CDATA[<ul><li>:<a href="https://zhuanlan.zhihu.com/p/34919655" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34919655</a></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1wgkib11aj310b0ew77m.jpg">  <h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li></li><li>video 25/</li><li>64snippets</li><li>64snippetsvideosnippetvideo</li></ul><h3 id="1ConvNet-LSTM"><a href="#1ConvNet-LSTM" class="headerlink" title="1ConvNet+LSTM"></a><strong>1ConvNet+LSTM</strong></h3><ul><li>cnnLSTMcnnLSTMcnnLSTM<br>  LSTMcnn<code>low-level motion</code><h3 id="23D-ConvNets"><a href="#23D-ConvNets" class="headerlink" title="23D ConvNets"></a><strong>23D ConvNets</strong></h3></li><li><code>3D ConvNets</code>cnn<code>2d conv</code><code>3d conv</code><code>spatio-temporal feature</code><code>3D ConvNets</code><code>3d conv</code>Imagenetcnn<br>  C3D8 conv layer5 pooling layer  2 fc layerfcbn16112112croppooling layerstride12memorybatch<h3 id="3Two-Stream-Networks"><a href="#3Two-Stream-Networks" class="headerlink" title="3Two-Stream Networks"></a><strong>3Two-Stream Networks</strong></h3></li><li>clipC3DRGB10<code>optical flow</code>(5x/y)<code>two-branch</code>imagenetsoftmax  </li><li>cnn<code>end-to-end</code>two-stream<code>3d conv</code>spatialflow<h3 id="4Two-Stream-Inflated-3D-ConvNets"><a href="#4Two-Stream-Inflated-3D-ConvNets" class="headerlink" title="4Two-Stream Inflated 3D ConvNets"></a><strong>4Two-Stream Inflated 3D ConvNets</strong></h3></li><li>imagenet<code>3d conv</code><code>RGB stream</code><code>temporal feature</code><code>optical-flow stream</code>  </li><li><code>2D conv</code>temporalNNfilterNNNNNfilterN<code>3D filter</code>  </li><li>stridestrideobject  </li><li>3D convmotion<code>two-stream</code></li></ul><p><img src="https://pic2.zhimg.com/80/v2-34f1d3ac14884d5c9114d4e9383c2e89_hd.jpg" alt></p><hr><ul><li><p>flowUCF-101HMDB-51kineticscamera<br><img src="https://pic2.zhimg.com/80/v2-e719a0a3a022e348838d4b6a5c0b8a55_hd.jpg" alt></p></li><li><p>imagenetkineticskineticsRGBI3DC3D<br><img src="https://pic3.zhimg.com/80/v2-b358535638c000de801577fc84296252_hd.jpg" alt></p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C3D</title>
      <link href="/2019/04/09/C3D/"/>
      <url>/2019/04/09/C3D/</url>
      
        <content type="html"><![CDATA[<h2 id="pytorch-"><a href="#pytorch-" class="headerlink" title="pytorch "></a>pytorch </h2><h3 id="Conv2d"><a href="#Conv2d" class="headerlink" title="Conv2d"></a>Conv2d</h3><p><a href="https://pytorch.org/docs/stable/nn.html#conv2d" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html#conv2d</a><br>the shape of input:  <font size="5," color="#0099ff">batchchannelheightwidth</font></p><h2 id="Conv3d"><a href="#Conv3d" class="headerlink" title="Conv3d"></a>Conv3d</h2><p><a href="https://pytorch.org/docs/stable/nn.html#conv3d" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html#conv3d</a><br>the shape of input: <font size="5," color="#0099ff">batchchanneldepthheightwidth</font></p><h2 id="C3D--1-2"><a href="#C3D--1-2" class="headerlink" title="C3D [1][2]"></a>C3D [1][2]</h2><p>[1] C3D </p><ul><li> bs3<font size="5," color="#0099ff">16</font>HW16clip  bs3161212</li><li> bsfeature_size</li></ul><p>videoNN16clipsclips8clipsfc6 activations video featurevideo class label</p><h2 id="Learning-Spatio-Temporal-Features-with-3D-Residual-Networks-for-Action-Recognition"><a href="#Learning-Spatio-Temporal-Features-with-3D-Residual-Networks-for-Action-Recognition" class="headerlink" title="Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition"></a><code>Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition</code></h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li></li><li>kinetics model</li></ul><h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h3><ul><li> spatio-temporal recognition</li></ul><h3 id="image-size-"><a href="#image-size-" class="headerlink" title="image size "></a>image size </h3><ul><li>360resneXt240</li></ul><h4 id="train"><a href="#train" class="headerlink" title="train"></a>train</h4><ul><li> 16 clip video</li><li>resize 112</li><li>trick  (1) =min(height, weight) * sacle (2)   (3)50%</li></ul><h4 id="test"><a href="#test" class="headerlink" title="test"></a>test</h4><ul><li>video   16 clipvideo</li><li></li><li></li><li>  <code>112*112</code></li></ul><h3 id="-resnet34-c3d--rgb-i3d-"><a href="#-resnet34-c3d--rgb-i3d-" class="headerlink" title=" resnet34-c3d  rgb-i3d "></a> resnet34-c3d  rgb-i3d </h3><ol><li><p>rgb-i3d 64GPUbatch size  resnet34-c3d 4GPU256 batch size</p></li><li><p>rgb-i3d  clip 3  64  224  224.   resnet34-c3d  clip  3  16  112  112     </p><p>i3d  <strong>64</strong> clip image  <strong>224</strong></p><p> resnet c3d  <strong>16</strong> clip image  <strong>112</strong></p></li></ol><h2 id="Can-Spatiotemporal-3D-CNNs-Retrace-the-History-of-2D-CNNs-and-ImageNet"><a href="#Can-Spatiotemporal-3D-CNNs-Retrace-the-History-of-2D-CNNs-and-ImageNet" class="headerlink" title="Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?"></a><code>Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?</code></h2><h3 id="Goal-1"><a href="#Goal-1" class="headerlink" title="Goal"></a>Goal</h3><ul><li>3d</li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition .  ICCV 2017<br>[2] Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?  CVPR 2018</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/09/%E8%A7%86%E9%A2%91%E6%A0%BC%E5%BC%8F/"/>
      <url>/2019/04/09/%E8%A7%86%E9%A2%91%E6%A0%BC%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[ <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1w907erjdj30800ffq31.jpg">  <h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><ul><li></li><li>video<strong></strong>MPEGH.26x</li><li>AVIMPEG</li><li>videovideovideo</li><li>H.26mp4MPEG</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><br><a href="https://www.zhihu.com/question/20997688/answer/30720197" target="_blank" rel="noopener">https://www.zhihu.com/question/20997688/answer/30720197</a><br><br>Container format ()Codec ()</p><h3 id="1-Container-format-"><a href="#1-Container-format-" class="headerlink" title="1. Container format ()"></a><strong>1. Container format ()</strong></h3><p>Container format ()Container format<br>Container format(windows)</p><h3 id="2-Codec-"><a href="#2-Codec-" class="headerlink" title="2. Codec ()"></a><strong>2. Codec ()</strong></h3><p>Codec//Codec/Codec/()<br>ITU-T VCEG(Visual Coding Experts Group)MPEG(Moving Picture Experts Group, ISO)MPEGMPEGH.26xITU-T</p><h3 id="3-Container-format--Codec--"><a href="#3-Container-format--Codec--" class="headerlink" title="3. Container format ()**Codec** ()****"></a><strong>3. Container format</strong> <strong>()**</strong>Codec** <strong>()**</strong>**</h3><p>(Container)Codec(Content)CodecQuickTime File Format (.MOV)CodecMPEG(.MP4)CodecCodecH.264 Quicktime(.mov)</p><h3 id="4-"><a href="#4-" class="headerlink" title="4. "></a><strong>4. </strong></h3><p>Container format Codecmov</p><p>Container formatCodecMPEG-4Container format Codec</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/09/%E8%A7%86%E9%A2%91%E8%A7%A3%E7%A0%81/"/>
      <url>/2019/04/09/%E8%A7%86%E9%A2%91%E8%A7%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<ul><li><p>opencvbanet</p></li><li><p>ffmpeg video to text</p></li><li><p>iPB</p></li><li><p><a href="https://blog.csdn.net/huangblog/article/details/8739876" target="_blank" rel="noopener">https://blog.csdn.net/huangblog/article/details/8739876</a><br>IIntra-coded frame<br>Ppredictive frame: P<br>BBi-Predictive frame: <br>PBI</p></li></ul><p><strong>IPBIIPB</strong>  </p><h3 id="GOP"><a href="#GOP" class="headerlink" title="GOP"></a>GOP</h3><p>GOPGOPIIGOP</p><ul><li><p><strong>I</strong><br>IGOPIJPEG</p></li><li><p><strong>P:</strong><br>PI,IP,IPP,P</p></li><li><p><strong>B</strong><br>BIPP,B,(),B,B</p></li><li><p><strong>1234567</strong><br>1I<br>144<br>14221433</p></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1w7ki6x02j30ra0ge0st.jpg">  <ul><li>  </li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1w7ki8pfvj30nm0fk77r.jpg"><hr><h3 id="IPB"><a href="#IPB" class="headerlink" title="IPB"></a>IPB</h3><ul><li> <a href="https://blog.csdn.net/huangblog/article/details/8739876" target="_blank" rel="noopener">https://blog.csdn.net/huangblog/article/details/8739876</a></li></ul><p>IPB</p><pre><code>IAVIPBI</code></pre><p>   I</p><p>   PPP</p><p>   BB4BBCPU~</p><pre><code>: :(GOP),,    1.:,IBP;    2.:I,IP,IPB;    3.:I</code></pre><p>I  </p><pre><code>II (intra picture)I  GOPMPEG MPEGIPBIPBIDCTDiscrete Cosine TransformJPEGI1/6I    1.JPEG;    2.I;    3.I;    4.I;    5.IPB();    6.IGOP(),I;    7.I;    8.II    (1)    (2)    (3)    (4)    (5)</code></pre><p>P</p><pre><code> PP,B,IPPIPIPIPPIP:    PI,IP,IPP,PP    PI1-2      PIP      IP      PIP      PPB    P     P</code></pre><p>B</p><pre><code>B   BBB2001IPBB    BIPP,B,(),B,BB    1.BIPP;    2.BIPP;    3.B;    4.B,2,;    5.B, P  B     (1)()P  B     (2)    (3)    (4)    (5):IBP,,,I,,I, </code></pre><p></p><pre><code>IPIPPIPBBPIPBBBBBI7JPGP20B50BI</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python</title>
      <link href="/2019/04/08/python%E7%B1%BB%E7%9A%84%E7%BB%A7%E6%89%BF/"/>
      <url>/2019/04/08/python%E7%B1%BB%E7%9A%84%E7%BB%A7%E6%89%BF/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://www.cnblogs.com/bigberg/p/7182741.html" target="_blank" rel="noopener">https://www.cnblogs.com/bigberg/p/7182741.html</a>  </li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="1-"><a href="#1-" class="headerlink" title="1. "></a>1. </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span>   <span class="comment"># </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">talk</span><span class="params">(self)</span>:</span>    <span class="comment"># </span></span><br><span class="line">        print(<span class="string">"person is talking...."</span>)  </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Chinese</span><span class="params">(Person)</span>:</span>    <span class="comment">#  Person</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">walk</span><span class="params">(self)</span>:</span>      <span class="comment"># </span></span><br><span class="line">        print(<span class="string">'is walking...'</span>)</span><br><span class="line"> </span><br><span class="line">c = Chinese()</span><br><span class="line">c.talk()      <span class="comment"># Person</span></span><br><span class="line">c.walk()     <span class="comment"># </span></span><br></pre></td></tr></table></figure><p></p><blockquote><p>person is talking.<br>is walking</p></blockquote><h2 id="2-"><a href="#2-" class="headerlink" title="2. "></a>2. </h2><p> c </p><p><br>1. .<strong>init</strong>(self,12)  </p><ol start="2"><li><font color="#0059ff" size="5" face=""> super(self).<strong>init</strong>(12.)</font></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span>  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age)</span>:</span>  </span><br><span class="line">        self.name = name  </span><br><span class="line">        self.age = age  </span><br><span class="line">        self.weight = <span class="string">'weight'</span>  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">talk</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        print(<span class="string">"person is talking...."</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Chinese</span><span class="params">(Person)</span>:</span>  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age, language)</span>:</span>  <span class="comment">#   </span></span><br><span class="line">Person.__init__(self, name, age)  </span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># super(Chinese,self).__init__(name,age)  </span></span><br><span class="line">        self.language = language  <span class="comment">#   </span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">walk</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        print(<span class="string">'is walking...'</span>)  </span><br><span class="line">        </span><br><span class="line">c = Chinese(<span class="string">'bigberg'</span>, <span class="number">22</span>, <span class="string">'Chinese'</span>)  </span><br><span class="line">print(c.name)  </span><br><span class="line">print(c.language)</span><br><span class="line">c.talk()</span><br></pre></td></tr></table></figure><p></p><blockquote><p>bigberg<br>Chinese<br>person is talking.</p></blockquote><h3 id="3-"><a href="#3-" class="headerlink" title="3."></a>3.</h3><p>/talk()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age)</span>:</span>  </span><br><span class="line">        self.name = name  </span><br><span class="line">        self.age = age  </span><br><span class="line">        self.weight = <span class="string">'weight'</span>  </span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">talk</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        print(<span class="string">"person is talking...."</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Chinese</span><span class="params">(Person)</span>:</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age, language)</span>:</span>  </span><br><span class="line">        Person.__init__(self, name, age)  </span><br><span class="line">        self.language = language  </span><br><span class="line">        print(self.name, self.age, self.weight, self.language)  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">talk</span><span class="params">(self)</span>:</span>  <span class="comment">#    </span></span><br><span class="line">  print(<span class="string">'%s is speaking chinese'</span> % self.name)  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">walk</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        print(<span class="string">'is walking...'</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">c = Chinese(<span class="string">'bigberg'</span>, <span class="number">22</span>, <span class="string">'Chinese'</span>)  </span><br><span class="line">c.talk()</span><br></pre></td></tr></table></figure><p></p><blockquote><p>bigberg 22 weight Chinese<br>bigberg is speaking chinese</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/08/%E8%B0%B1%E8%81%9A%E7%B1%BB/"/>
      <url>/2019/04/08/%E8%B0%B1%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<ul><li><p></p></li><li><p><a href="https://www.cnblogs.com/pinard/p/6221564.html" target="_blank" rel="noopener"></a>  </p></li><li><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" target="_blank" rel="noopener">sklearn.cluster.SpectralClustering</a></p><ul><li>References<br>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324" target="_blank" rel="noopener">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324</a><br>A Tutorial on Spectral Clustering, 2007 Ulrike von Luxburg <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323" target="_blank" rel="noopener">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323</a><br>Multiclass spectral clustering, 2003 Stella X. Yu, Jianbo Shi <a href="http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf" target="_blank" rel="noopener">http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spectral Networks and Deep Locally Connected Networks on Graphs</title>
      <link href="/2019/04/08/Spectral-Networks-and-Deep-Locally-Connected-Networks-on-Graphs/"/>
      <url>/2019/04/08/Spectral-Networks-and-Deep-Locally-Connected-Networks-on-Graphs/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(SCST)Self-critical Sequence Training for Image Captioning</title>
      <link href="/2019/04/08/SCST-Self-critical-Sequence-Training-for-Image-Captioning/"/>
      <url>/2019/04/08/SCST-Self-critical-Sequence-Training-for-Image-Captioning/</url>
      
        <content type="html"><![CDATA[<p><br>self-critical sequence training (SCST)</p><p><strong>sequence models for image captioning  exposure bias </strong></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id=""><a href="#" class="headerlink" title=""></a><strong></strong></h3><p>[1] <strong>show attend and tell</strong> captionattention<br>[2] <strong>Teacher-Forcing</strong> deep generative models wordground truth wordTeacher-Forcing    </p><ul><li><p>exposure  bias [2]<br>This exposure  bias [2], results in error accumulation during generation at  test time,<br>since the model has never been exposed to its own  predictions</p><p>exposure bias[3] [4]<br>[3] <strong>Scheduled sampling</strong> p<br>[4] <strong>Professor forcing</strong> a  technique that uses adversarial training to encourage the dynamics of the recurrent network to be the same when training conditioned on ground truth previous words and when  sampling freely from the network</p></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>we find that directly optimizing the CIDEr metric with  SCST and greedy decoding at test-time is highly effective.</p><h2 id="Image-Features"><a href="#Image-Features" class="headerlink" title="Image Features"></a>Image Features</h2><ul><li>FC Models<br>CNN+FCimage  LSTMcaption<br>first step word (embedding)   </li><li>Spatial CNN features for Attention models<br>resnet-101apply spatially adaptive max-pooling14  14  2048time stepattention model14  14=196<font color="#0099ff" size="6" face=""> attention mask</font>/mask image feature  </li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Show, attend and tell: Neural image caption generation with visual attention. In ICML,  2015.<br>[2] Sequence level training with recurrent neural networks. ICLR, 2015.<br>[3] Scheduled sampling for sequence prediction with recurrent neural networks. In NIPS, 2015.<br>[4] Professor forcing: A  new algorithm for training recurrent networks. Neural Information Processing Systems. (NIPS) 2016.  </p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</title>
      <link href="/2019/04/07/Bottom-Up-and-Top-Down-Attention-for-Image-Captioning-and-Visual-Question-Answering/"/>
      <url>/2019/04/07/Bottom-Up-and-Top-Down-Attention-for-Image-Captioning-and-Visual-Question-Answering/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>object attention<br><strong>bottom-up</strong>: Faster R-CNN  object<br><strong>top-down</strong>: attention bottom-upobject feature </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><strong>1Bottom-Up</strong><br>Faster R-CNN R-CNNobject feature<br><strong>2Top-Down Attention</strong><br>object features  <strong>v<sub>i</sub></strong>attention <br><strong>3object features attention </strong><br>image feature<br><strong>4Decoderlanguage LSTM</strong><br></p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g19d1x7kiij30im0bvaat.jpg" style="zoom:60%">  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14xg3jwvdj30mo0h2wfi.jpg" style="zoom:60%"><h2 id="Bottom-Up"><a href="#Bottom-Up" class="headerlink" title="Bottom-Up"></a>Bottom-Up</h2><ul><li><strong>Faster R-CNN </strong><br>1Resnet-101 ImageNet<br>2Faster R-CNNMS COCO<br>rpn score classification lossbbox regression loss<br>r-cnn score classification lossbbox regression loss<br>3Faster R-CNNVisual Genome<br> </li><li><strong></strong><br>To predict attributes for region i, we concatenate the mean  pooled convolutional feature vi with a learned embedding  of the ground-truth object class, and feed this into an additional output layer defining a softmax distribution over each  attribute class plus a no attributes class.</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>self.training in pytorch</title>
      <link href="/2019/04/07/self-training-in-pytorch/"/>
      <url>/2019/04/07/self-training-in-pytorch/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://zhuanlan.zhihu.com/p/26893755" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26893755</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable, Function</span><br><span class="line"></span><br><span class="line">x_train = np.array([[<span class="number">3.3</span>], [<span class="number">4.4</span>], [<span class="number">5.5</span>], [<span class="number">6.71</span>], [<span class="number">6.93</span>], [<span class="number">4.168</span>],</span><br><span class="line">                    [<span class="number">9.779</span>], [<span class="number">6.182</span>], [<span class="number">7.59</span>], [<span class="number">2.167</span>], [<span class="number">7.042</span>],</span><br><span class="line">                    [<span class="number">10.791</span>], [<span class="number">5.313</span>], [<span class="number">7.997</span>], [<span class="number">3.1</span>]], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">y_train = np.array([[<span class="number">1.7</span>], [<span class="number">2.76</span>], [<span class="number">2.09</span>], [<span class="number">3.19</span>], [<span class="number">1.694</span>], [<span class="number">1.573</span>],</span><br><span class="line">                    [<span class="number">3.366</span>], [<span class="number">2.596</span>], [<span class="number">2.53</span>], [<span class="number">1.221</span>], [<span class="number">2.827</span>],</span><br><span class="line">                    [<span class="number">3.465</span>], [<span class="number">1.65</span>], [<span class="number">2.904</span>], [<span class="number">1.3</span>]], dtype=np.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train)</span><br><span class="line">y_train = torch.from_numpy(y_train)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"---------------------------------------"</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LinearRegression, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># input and output is 1 dimension</span></span><br><span class="line">        print(<span class="string">"self.training: "</span> + str(self.training))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.linear(x)</span><br><span class="line">        print(<span class="string">"self.training"</span> + str(self.training))</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">print(<span class="string">"initialize"</span>)</span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"---------------------------------------"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"model.eval()"</span>)</span><br><span class="line">model.eval()</span><br><span class="line">inputs = Variable(x_train)</span><br><span class="line">target = Variable(y_train)</span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line">out = model(inputs) <span class="comment"># </span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"---------------------------------------"</span>)</span><br><span class="line">print(<span class="string">"model.train()"</span>)</span><br><span class="line">model.train()</span><br><span class="line">inputs = Variable(x_train)</span><br><span class="line">target = Variable(y_train)</span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line">out = model(inputs) <span class="comment"># </span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorboard_logger</title>
      <link href="/2019/04/06/tensorboard-logger/"/>
      <url>/2019/04/06/tensorboard-logger/</url>
      
        <content type="html"><![CDATA[<p>tensorboard_logger<br>1tensorflow</p><ul><li><a href="https://blog.csdn.net/love666666shen/article/details/77099843" target="_blank" rel="noopener">https://blog.csdn.net/love666666shen/article/details/77099843</a></li><li>tensorflowpip install CPU </li><li>pip install ignore-installed upgrade <a href="https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-win_amd64.whl" target="_blank" rel="noopener">https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-win_amd64.whl</a></li></ul><p>2tensorboard</p><ul><li>pip install tensorboard</li></ul><p>3No scalar data was found<br>cmdcd</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">e:</span><br><span class="line">cd logdir</span><br><span class="line">tensorboard <span class="attribute">--logdir</span>=E:\logdir <span class="attribute">--host</span>=127.0.0.1</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/09/05/7YODLiJAZ6aUTG4.png" alt="20190905112015.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> tensorboard </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>range xrange np.arange np.linspace</title>
      <link href="/2019/04/05/range-xrange-np-arange-np-linspace/"/>
      <url>/2019/04/05/range-xrange-np-arange-np-linspace/</url>
      
        <content type="html"><![CDATA[<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1rmpadk75j309a07saa2.jpg"><p>python</p><ul><li>xrange python2</li><li>range python2/python3</li></ul><p>numpy</p><ul><li>numpy.arange </li><li>numpy.linspace <strong></strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> numpy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>glob.glob vs os.listdir</title>
      <link href="/2019/04/05/glob-glob-vs-os-listdir/"/>
      <url>/2019/04/05/glob-glob-vs-os-listdir/</url>
      
        <content type="html"><![CDATA[<ul><li>  </li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1rl9d9xq9j30ia0cbjri.jpg">  <ul><li>frames_list<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frames_list = sorted(os.listdir(video_path))</span><br></pre></td></tr></table></figure></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1rlb8uq8aj309h0a8q2z.jpg"><ul><li>frames_list<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frames_list = sorted(glob.glob(os.path.join(video_path, <span class="string">'*.jpg'</span>)))</span><br></pre></td></tr></table></figure></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1rlbroiqmj30nt0b40u9.jpg"><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>os.listdir <br>glob.glob </p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python list sort</title>
      <link href="/2019/04/04/python-list-sort%E6%96%B9%E6%B3%95/"/>
      <url>/2019/04/04/python-list-sort%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><strong>sort()</strong> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>sort()</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list.sort(<span class="attribute">cmp</span>=None, <span class="attribute">key</span>=None, <span class="attribute">reverse</span>=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li>cmp  , </li><li>key  </li><li>reverse  <strong>reverse = True</strong>  <strong>reverse = False</strong> </li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">video_sort_lambda = <span class="keyword">lambda</span> x: int(x[<span class="number">3</span>:<span class="number">-4</span>]) <span class="comment"># xInt</span></span><br><span class="line">video_root = <span class="string">"/userhome/dataset/MSVD/Video-Description-with-Spatial-Temporal-Attention/youtube"</span></span><br><span class="line">videos = sorted(os.listdir(video_root), key=video_sort_lambda) <span class="comment"># list</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytohn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/04/%E5%8F%B2%E9%9B%85%E9%9B%85%E7%9A%84%E6%94%B6%E8%97%8F%E5%A4%B9/"/>
      <url>/2019/04/04/%E5%8F%B2%E9%9B%85%E9%9B%85%E7%9A%84%E6%94%B6%E8%97%8F%E5%A4%B9/</url>
      
        <content type="html"><![CDATA[<p><a href="http://pygments.org/" target="_blank" rel="noopener">http://pygments.org/</a></p><p><a href="https://202.38.95.226:7443/view.html" target="_blank" rel="noopener">https://202.38.95.226:7443/view.html</a></p><p><a href="https://aideadlin.es/?sub=ML,RO,CV,SP,NLP,DM" target="_blank" rel="noopener">https://aideadlin.es/?sub=ML,RO,CV,SP,NLP,DM</a></p><p><a href="https://yjs.ustc.edu.cn/" target="_blank" rel="noopener">https://yjs.ustc.edu.cn/</a></p><p><a href="https://www.json.cn/" target="_blank" rel="noopener">https://www.json.cn/</a></p><p><a href="https://kevinj-huang.github.io/" target="_blank" rel="noopener">https://kevinj-huang.github.io/</a></p><p><a href="https://shiyaya.github.io/" target="_blank" rel="noopener">https://shiyaya.github.io/</a></p><p><a href="https://stackedit.io/app#" target="_blank" rel="noopener">https://stackedit.io/app#</a></p><p><a href="http://jsonviewer.stack.hu/" target="_blank" rel="noopener">http://jsonviewer.stack.hu/</a></p><p><a href="http://www.nlpjob.com/" target="_blank" rel="noopener">http://www.nlpjob.com/</a></p><p><a href="https://nlp.stanford.edu/software/scenegraph-parser.shtml#Usage" target="_blank" rel="noopener">https://nlp.stanford.edu/software/scenegraph-parser.shtml#Usage</a></p><p><a href="https://paperswithcode.com/sota" target="_blank" rel="noopener">https://paperswithcode.com/sota</a></p><p><a href="https://sm.ms/" target="_blank" rel="noopener">https://sm.ms/</a></p><p><a href="http://www.arxiv-sanity.com/" target="_blank" rel="noopener">http://www.arxiv-sanity.com/</a></p><p><a href="http://www.cvpapers.com/" target="_blank" rel="noopener">http://www.cvpapers.com/</a></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li><p><a href="https://dblp.uni-trier.de/db/" target="_blank" rel="noopener">https://dblp.uni-trier.de/db/</a></p><ul><li>eg:nips, iccv, cvpr; ()</li></ul></li><li><p><a href="http://openaccess.thecvf.com/menu.py" target="_blank" rel="noopener">http://openaccess.thecvf.com/menu.py</a></p></li><li><p><a href="http://actionrecognition.net/files/paper.php" target="_blank" rel="noopener">http://actionrecognition.net/files/paper.php</a></p></li><li><p><a href="http://www.aaai.org/Library/AAAI/aaai19contents.php" target="_blank" rel="noopener">http://www.aaai.org/Library/AAAI/aaai19contents.php</a></p></li><li><p><a href="https://dl.acm.org/results.cfm?within=owners.owner%3DHOSTED&amp;srt=_score&amp;query=&amp;Go.x=26&amp;Go.y=1" target="_blank" rel="noopener">https://dl.acm.org/results.cfm?within=owners.owner%3DHOSTED&amp;srt=_score&amp;query=&amp;Go.x=26&amp;Go.y=1</a></p></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li><p><a href="https://github.com/vpncn/vpncn.github.io" target="_blank" rel="noopener">https://github.com/vpncn/vpncn.github.io</a></p></li><li><p><a href="https://flyzyblog.com/install-ss-ssr-bbr-in-one-command/#ss" target="_blank" rel="noopener">https://flyzyblog.com/install-ss-ssr-bbr-in-one-command/#ss</a></p></li><li><p><a href="https://www.banpie.info/shadowsocks-pac-gfw/" target="_blank" rel="noopener">https://www.banpie.info/shadowsocks-pac-gfw/</a></p></li><li><p>VultrSS</p></li><li><p><a href="https://github.com/sirzdy/shadowsocks/wiki/VultrSSVPSSS" target="_blank" rel="noopener">http://wuzhangyang.com/2019/03/06/vultr-ss/</a></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https:<span class="comment">//raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh</span></span><br><span class="line"></span><br><span class="line">chmod +x shadowsocks.sh</span><br><span class="line"></span><br><span class="line">./shadowsocks<span class="selector-class">.sh</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p></p></li><li><p><a href="https://www.bandwagonhost.net/1967.html" target="_blank" rel="noopener">https://www.bandwagonhost.net/1967.html</a></p></li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li><a href="http://www.searchconf.net/conf/searchresule/" target="_blank" rel="noopener">http://www.searchconf.net/conf/searchresule/</a></li></ul><h3 id="iccv-2019-challenge"><a href="#iccv-2019-challenge" class="headerlink" title="iccv 2019 challenge"></a>iccv 2019 challenge</h3><ul><li><a href="https://sites.google.com/site/iccv19clvllsmdc/home" target="_blank" rel="noopener">https://sites.google.com/site/iccv19clvllsmdc/home</a></li></ul><h3 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h3><ul><li><a href="https://github.com/rusty1s/pytorch_geometric" target="_blank" rel="noopener">https://github.com/rusty1s/pytorch_geometric</a></li></ul><p></p><ul><li><a href="https://discuss.gluon.ai/c/5-category" target="_blank" rel="noopener">https://discuss.gluon.ai/c/5-category</a></li><li><a href="http://zh.d2l.ai/chapter_preface/preface.html" target="_blank" rel="noopener">http://zh.d2l.ai/chapter_preface/preface.html</a></li></ul><h3 id="tensorboard-"><a href="#tensorboard-" class="headerlink" title="tensorboard "></a>tensorboard </h3><ul><li><a href="https://www.aiuai.cn/aifarm646.html" target="_blank" rel="noopener">https://www.aiuai.cn/aifarm646.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch out of memory</title>
      <link href="/2019/04/03/pytorch-%E5%87%8F%E5%B0%8F%E6%98%BE%E5%AD%98%E6%B6%88%E8%80%97%EF%BC%8C%E4%BC%98%E5%8C%96%E6%98%BE%E5%AD%98%E4%BD%BF%E7%94%A8%EF%BC%8C%E9%81%BF%E5%85%8Dout-of-memory/"/>
      <url>/2019/04/03/pytorch-%E5%87%8F%E5%B0%8F%E6%98%BE%E5%AD%98%E6%B6%88%E8%80%97%EF%BC%8C%E4%BC%98%E5%8C%96%E6%98%BE%E5%AD%98%E4%BD%BF%E7%94%A8%EF%BC%8C%E9%81%BF%E5%85%8Dout-of-memory/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li><p><br><a href="https://oldpan.me/archives/how-to-calculate-gpu-memory" target="_blank" rel="noopener">https://oldpan.me/archives/how-to-calculate-gpu-memory</a></p></li><li><p>Pytorch<br><a href="https://oldpan.me/archives/how-to-use-memory-pytorch" target="_blank" rel="noopener">https://oldpan.me/archives/how-to-use-memory-pytorch</a></p></li><li><p><br><a href="https://zhuanlan.zhihu.com/p/31558973" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31558973</a></p></li><li><p>ppt<br><a href="https://www.zhihu.com/question/67209417" target="_blank" rel="noopener">https://www.zhihu.com/question/67209417</a></p></li><li><p></p></li></ul><blockquote><p>sudo apt-get install htop</p></blockquote><ul><li>-d0.1s</li></ul><blockquote><p>htop -d=0.1</p></blockquote><ul><li>-n0.1s</li></ul><blockquote><p>watch -n 0.1 nvidia-smi</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>torch.backends.cudnn.benchmark = true </title>
      <link href="/2019/04/03/torch-backends-cudnn-benchmark-true-%E4%BD%BF%E7%94%A8%E6%83%85%E5%BD%A2/"/>
      <url>/2019/04/03/torch-backends-cudnn-benchmark-true-%E4%BD%BF%E7%94%A8%E6%83%85%E5%BD%A2/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.pytorchtutorial.com/when-should-we-set-cudnn-benchmark-to-true/" target="_blank" rel="noopener">pytorch-torch.backends.cudnn.benchmark</a></p><ul><li>torch.backends.cudnn.benchmark<br> flag  cuDNN  auto-tuner </li></ul><p></p><ul><li>  torch.backends.cudnn.benchmark = true  </li><li> iteration  cnDNN </li><li></li><li><br>torch.cuda.empty_cache()</li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/02/%E5%88%B7%E9%A2%98%E7%BB%8F%E9%AA%8C/"/>
      <url>/2019/04/02/%E5%88%B7%E9%A2%98%E7%BB%8F%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li><strong></strong></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Stanford Scene Graph Parser</title>
      <link href="/2019/03/26/Stanford-Scene-Graph-Parser/"/>
      <url>/2019/03/26/Stanford-Scene-Graph-Parser/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://nlp.stanford.edu/software/scenegraph-parser.shtml#Usage" target="_blank" rel="noopener">https://nlp.stanford.edu/software/scenegraph-parser.shtml#Usage</a></li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li>stanford-corenlp-full-2015-12-09.zip</li><li>scenegraph-1.0.jar<h2 id=""><a href="#" class="headerlink" title=""></a></h2></li></ul><ol><li>stanford-corenlp-full-2015-12-09.zip<a href="https://shiyaya.github.io/2019/03/26/ubuntu-%E5%AE%89%E8%A3%85-Stanford-CoreNLP/" target="_blank" rel="noopener">ubuntu  Stanford CoreNLP</a>corenlp</li><li> scenegraph-1.0.jar stanford-corenlp-full-2015-12-09</li></ol><ul><li><p></p></li><li><p>java  idk 1.8+ </p></li><li><p>corenlp 2015</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>1</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -mx2g -cp <span class="string">"*"</span> edu.stanford.nlp.scenegraph.RuleBasedParser</span><br></pre></td></tr></table></figure></li><li><p>stanford-corenlp-full-2015-12-09<br>scene graph</p></li></ul><p>2</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu  Stanford CoreNLP</title>
      <link href="/2019/03/26/ubuntu-%E5%AE%89%E8%A3%85-Stanford-CoreNLP/"/>
      <url>/2019/03/26/ubuntu-%E5%AE%89%E8%A3%85-Stanford-CoreNLP/</url>
      
        <content type="html"><![CDATA[<h3 id="java-jdk"><a href="#java-jdk" class="headerlink" title="java jdk"></a>java jdk</h3><ul><li><p></p><figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-<span class="built_in">get</span> <span class="keyword">update</span></span><br></pre></td></tr></table></figure></li><li><p>openjdk-8-jdk</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-<span class="builtin-name">get</span> install openjdk-8-jdk</span><br></pre></td></tr></table></figure></li><li><p>java</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="Stanford-coreNLP-"><a href="#Stanford-coreNLP-" class="headerlink" title="Stanford coreNLP "></a>Stanford coreNLP </h3><ul><li><br><a href="https://stanfordnlp.github.io/CoreNLP/download.html" target="_blank" rel="noopener">https://stanfordnlp.github.io/CoreNLP/download.html</a><br><blockquote><p>wget <a href="http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip" target="_blank" rel="noopener">http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip</a>  </p></blockquote></li></ul><ul><li><p></p><blockquote><p>unzip stanford-corenlp-full-2018-02-27.zip</p></blockquote></li><li><p></p></li></ul><blockquote><p>cd stanford-corenlp-full-2018-02-27/</p></blockquote><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>.bashrc(vim .bashrc)</p><blockquote><p> cd ~<br>vim .bashrc<br>export CLASSPATH=/path/to/stanford-corenlp-full-2018-02-27/stanford-corenlp-3.9.1.jar<br>source ~/.bashrc  ## <br>/path/to/stanford-corenlp-full-2016-10-31</p></blockquote><h3 id=""><a href="#" class="headerlink" title=""></a></h3><blockquote><p>pip install stanfordcorenlp</p></blockquote><p>jarstanford-corenlp-full-2018-02-27</p><p>wget <a href="http://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-02-27-models.jar" target="_blank" rel="noopener">http://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-02-27-models.jar</a></p><h3 id="stanfordcorenlp"><a href="#stanfordcorenlp" class="headerlink" title="stanfordcorenlp"></a>stanfordcorenlp</h3><p>python2python3</p><p></p><blockquote><p>python</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br></pre></td></tr></table></figure><p></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>java</title>
      <link href="/2019/03/26/java%20%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E6%89%A7%E8%A1%8C/"/>
      <url>/2019/03/26/java%20%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E6%89%A7%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="java-"><a href="#java-" class="headerlink" title="java "></a>java </h2><ol><li><p>yumhtest.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">yumhtest</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"hello world !"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>shell <strong>javac yumhtest.java</strong></p></li><li><p>shell <strong>java yumhtest</strong><br>shellhello world !</p></li></ol><p></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java </title>
      <link href="/2019/03/26/java/"/>
      <url>/2019/03/26/java/</url>
      
        <content type="html"><![CDATA[<h2 id="java-"><a href="#java-" class="headerlink" title="java "></a>java </h2><ol><li><p>yumhtest.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">yumhtest</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"hello world !"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>shell <strong>javac yumhtest.java</strong></p></li><li><p>shell <strong>java yumhtest</strong><br>shellhello world !</p></li></ol><p></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SPICE</title>
      <link href="/2019/03/25/SPICE/"/>
      <url>/2019/03/25/SPICE/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="UbuntuStanford-CoreNLP"><a href="#UbuntuStanford-CoreNLP" class="headerlink" title="UbuntuStanford CoreNLP"></a><a href="https://blog.csdn.net/Hay54/article/details/82313535" target="_blank" rel="noopener">UbuntuStanford CoreNLP</a></h3>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>faster r-cnn </title>
      <link href="/2019/03/24/faster-r-cnn-%E8%A7%A3%E8%AF%BB/"/>
      <url>/2019/03/24/faster-r-cnn-%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><a href="https://mp.weixin.qq.com/s/M_i38L2brq69BYzmaPeJ9w" target="_blank" rel="noopener"></a><br><a href="http://tech.ifeng.com/a/20180223/44884976_0.shtml" target="_blank" rel="noopener"></a><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e0ltm2y7j30u0083wev.jpg"><br>by yaya:<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e10a6tguj31fj0mw0vw.jpg"></p><h2 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e0p68j95j30t80gaaar.jpg" style="zoom:60%"><p>anchor: anchor: scale=[4,8,16], : ratio=[0.5, 1, 1.5, 2]each position of conv feature k=len(scale)len(ratio)=12anchor</p><p>(1).<br><br>11shape=N2kHW  <br></p><p>(2)()<font color="#0099ff" size="5" face="">xcenterycenterwidthheight</font>(x1, y1, x2, y2)area=(x2-x1)*(y2-y1).<br><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e0p66yxyj312w066t91.jpg"></p><p>(3) <font color="#0099ff" size="5" face="">RoI Pooling</font>   pooled featsbase feats, pred proposals  <font color="#0099ff" size="5" face="">1/scale</font><br>pred proposals<del>image</del> imagebase feats .</p><h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e0p6ekybj30u00c175l.jpg"><p><br><br>(1) <br><br>(2) <br><br> Faster R-CNN R-CNN  4096  ReLU <br><br> N+1  N <br><br> 4N  N  <font color="#0099ff" size="5" face="">xcenterycenterwidthheight</font><br><br><br><br>R-CNN  RPN  IoU<br></p><p> IoU  0.5 IoU  0.1  0.5  RPN <br></p><p> IoU <br></p><p> 64  balanced mini batch 25%  75% <br></p><p> RPN  25%  Smooth L1 loss R-CNN <br><br><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e0p66uafj30nq03vt8o.jpg"></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Image Caption </title>
      <link href="/2019/03/24/Image-Caption-%E5%B8%B8%E7%94%A8%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
      <url>/2019/03/24/Image-Caption-%E5%B8%B8%E7%94%A8%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Graph R-CNN for Scene Graph Generation</title>
      <link href="/2019/03/24/Graph-R-CNN-for-Scene-Graph-Generation/"/>
      <url>/2019/03/24/Graph-R-CNN-for-Scene-Graph-Generation/</url>
      
        <content type="html"><![CDATA[<p>ECCV 2018  <br>GCNGraph Attention NetworksattentionAXW</p><ul><li><strong>relation featureunion box feature relation feature</strong></li><li><strong>relation nodegraph object feature  realtion featuregraphAuto-Encoding Scene Graphs for Image Captioning</strong>  </li><li><strong>W<sup>sr</sup>Z<sup>r</sup><sup>sr</sup> node<sub>i</sub>relation nodesobject relationrelation</strong>0attention</li></ul><p>X=AXW X XZ<sub>i</sub><sup>r</sup>Z<sup>o</sup></p><p><strong></strong></p><ol><li><strong>GCN</strong> with attention scene graph generate Updating each object and relationship representation based on its neighbors</li><li>Nobject ,NNrelationN<strong>RePN relation</strong></li><li>scene graph generate SGGen+SGGen+</li></ol><h2 id=""><a href="#" class="headerlink" title=""></a></h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1dxanmhpfj312o08p75l.jpg">    <ol><li>P( V|I )  image <strong>object proposals</strong><br>pytorch [1]faster R-CNN bbox[2]faster R-CNNfaster r-cnn  </li><li>P( E|V, I ) image  bbox <strong>relation proposals</strong><br>object proposals relationNNrelationNNobject pairsrelationobject pairs ReRN  relatedness relations</li><li>P( R,O|V,E,I )  imageobject proposalsrelation proposalobject label  relation label<br>iterative refinement process[2]GCN</li></ol><ul><li>overview<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1dy02tb1zj31du0crajb.jpg"></li></ul><h2 id="Object-Proposal"><a href="#Object-Proposal" class="headerlink" title="Object Proposal"></a>Object Proposal</h2><p>faster r-cnn<strong>object proposals</strong><strong>pooled feat</strong>faster r-cnn object <strong>label</strong><br></p><h2 id="Relation-Proposal-Network"><a href="#Relation-Proposal-Network" class="headerlink" title="Relation Proposal Network"></a>Relation Proposal Network</h2><p> <strong>labels</strong> of object pairs<br>relatedness relations/ m object pairs<br><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e8ud0p66j32v311qjyg.jpg"></p><h2 id="Attention-GCN"><a href="#Attention-GCN" class="headerlink" title="Attention GCN"></a>Attention GCN</h2><h3 id="Formulation"><a href="#Formulation" class="headerlink" title="Formulation"></a>Formulation</h3><ul><li>GATGAT[ 3]<strong><sub>i</sub></strong> <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e8wl8yubj30f60360sr.jpg" style="zoom:60%"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e8wl8m92j30gn04sjrp.jpg" style="zoom:60%"></li></ul><h3 id="aGCN-for-Scene-Graph-Generation"><a href="#aGCN-for-Scene-Graph-Generation" class="headerlink" title="aGCN for Scene Graph Generation"></a>aGCN for Scene Graph Generation</h3><ul><li>graphgraphobjectnoderelationnode<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e98pvy7aj30dh0cq0t3.jpg" style="zoom:60%">  </li><li>skipobject node</li></ul><p><strong>object &lt;&gt; relationship</strong> <strong>relationship &lt;&gt; subject</strong> and <strong>object &lt;&gt; object</strong><br><strong>s</strong>=subjects, <strong>o</strong>=objects, and <strong>r</strong>=relationships<br>object and relationship features as  <strong>Z<sup>o</sup></strong> and <strong>Z<sup>r</sup></strong><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1e9gaiumnj30vp0dg0v2.jpg" style="zoom:60%"><br><br>1aGCNobject and relationship node representationvisual aGCN visual feature semantic aGCN pre-softmax outputs<br>2WZGCN</p><ul><li><p> <strong>W<sup>skip</sup> Z<sup>o</sup> <sup>skip</sup></strong> <strong>W<sup>skip</sup></strong> <strong>Z<sup>o</sup></strong> object nodes feature d,N<strong><sup>skip</sup></strong>  node<sub>i</sub>object nodes(1,NNobjects</p></li><li><p> <strong>W<sup>sr</sup> Z<sup>r</sup> <sup>sr</sup></strong> <strong>W<sup>sr</sup></strong> <strong>Z<sup>r</sup></strong> realtion nodes feature d,m<strong><sup>sr</sup></strong> node<sub>i</sub>relation nodes(1,mmrealtion</p></li><li><p> <strong>W<sup>rs</sup> Z<sup>o</sup> <sup>rs</sup></strong> <strong>W<sup>rs</sup></strong> <strong>Z<sup>o</sup></strong> object nodes feature d,N<strong><sup>rs</sup></strong> relation<sub>i</sub>object nodes(1,NNobjects  </p><p>3<strong><sub>ii</sub></strong>=11</p></li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1ea7p889dj313l0dzwj3.jpg"><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] A faster pytorch implementation of faster  r-cnn. <a href="https://github.com/jwyang/faster-rcnn.pytorch" target="_blank" rel="noopener">https://github.com/jwyang/faster-rcnn.pytorch</a><br>[2] Scene graph generation by iterative message passing<br>[3] Graph Attention Networks<br>[3] Graph Attention Networks</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Batch Normalization(BN)</title>
      <link href="/2019/03/23/Batch-Normalization-BN%E5%B1%82/"/>
      <url>/2019/03/23/Batch-Normalization-BN%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/donkey_1993/article/details/81871132" target="_blank" rel="noopener">https://blog.csdn.net/donkey_1993/article/details/81871132</a><br><a href="https://zhuanlan.zhihu.com/p/34879333" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34879333</a></p><h2 id="BN"><a href="#BN" class="headerlink" title="BN"></a>BN</h2><ul><li><p>mini batch</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1chneox3hj30dv0bddgx.jpg"></li><li><p>NormalizationICSrepresentation ability of the network01sigmoidtanh  </p></li><li><p>BNlearnable    <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7BZ_j%7D%3D%5Cgamma_j+%5Chat%7BZ%7D_j%2B%5Cbeta_j" alt="\tilde{Z_j}=\gamma_j \hat{Z}_j+\beta_j">  <sup>2</sup>=<sup>2</sup>  = identity transform</p></li></ul><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>BN  <sup>2</sup>batch <sup>2</sup></p><p>BNmini-batch<br> <sub>batch</sub><sup>2</sup><sub>batch</sub> Test</p><p><img src="https://www.zhihu.com/equation?tex=%5Cmu_%7Btest%7D%3D%5Cmathbb%7BE%7D+%28%5Cmu_%7Bbatch%7D%29" alt="\mu_{test}=\mathbb{E} (\mu_{batch})"></p><p><img src="https://www.zhihu.com/equation?tex=%5Csigma%5E2_%7Btest%7D%3D%5Cfrac%7Bm%7D%7Bm-1%7D%5Cmathbb%7BE%7D%28%5Csigma%5E2_%7Bbatch%7D%29" alt="\sigma^2_{test}=\frac{m}{m-1}\mathbb{E}(\sigma^2_{batch})"></p><p>testnormalization</p><p><img src="https://www.zhihu.com/equation?tex=BN%28X_%7Btest%7D%29%3D%5Cgamma%5Ccdot+%5Cfrac%7BX_%7Btest%7D-%5Cmu_%7Btest%7D%7D%7B%5Csqrt%7B%5Csigma%5E2_%7Btest%7D%2B%5Cepsilon%7D%7D%2B%5Cbeta" alt="BN(X_{test})=\gamma\cdot \frac{X_{test}-\mu_{test}}{\sqrt{\sigma^2_{test}+\epsilon}}+\beta"></p><p>CourseraDeep Learningtrainbatchmean/variance<a href="[https://zhuanlan.zhihu.com/p/29895933](https://zhuanlan.zhihu.com/p/29895933)"><font color="#0099ff" size="5" face=""> </font></a>testmean/variance</p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>Batch NormalizationBN</p><p><strong>1BN</strong></p><p>BN</p><p><strong>2BN</strong></p><p>Xavier<br>BN<br>Batch Normalizationdivergence</p><p><strong>3BNsigmoidtanh</strong></p><p>BNnormalize </p><p><strong>4BN</strong></p><p>Batch Normalizationmini-batchbatchmini-batchDropout</p><p>BNDropout</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>optical flow()</title>
      <link href="/2019/03/23/optical-flow-%E5%85%89%E6%B5%81/"/>
      <url>/2019/03/23/optical-flow-%E5%85%89%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/zouxy09/article/details/8683859" target="_blank" rel="noopener">https://blog.csdn.net/zouxy09/article/details/8683859</a></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><br><br><strong></strong><strong></strong><strong></strong></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li><p>tA(x1, y1)t+1A(x2,y2)A(ux, vy) = (x2, y2) - (x1,y1)</p></li><li><p>t+1A </p></li><li><p>1981HornSchunckBarron<strong></strong></p></li><li><p>yaya: <strong></strong><br></p><p>  [] <br>  [] <br>  []   </p></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1cgxrjz19j30hi0h90uo.jpg">  <p>I<sub>x</sub>,  I<sub>y</sub>xyI<sub>t</sub>I(x,y,t)I(x,y,t1)(u,v) </p><p>NN2N2NNN</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1cgxrjo7dj30g00e6ta4.jpg"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1cgxrhmkgj30gh05swej.jpg">  <p>H(x,y)I(x+u,y+v)(u,v)=  </p><p><a href="https://xmfbit.github.io/2017/05/03/cs131-opticalflow/" target="_blank" rel="noopener">https://xmfbit.github.io/2017/05/03/cs131-opticalflow/</a><br><a href="https://blog.csdn.net/carson2005/article/details/7581642" target="_blank" rel="noopener">https://blog.csdn.net/carson2005/article/details/7581642</a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>baggingdropout</title>
      <link href="/2019/03/22/%E4%BB%8Ebagging%E5%88%B0dropout/"/>
      <url>/2019/03/22/%E4%BB%8Ebagging%E5%88%B0dropout/</url>
      
        <content type="html"><![CDATA[<ul><li> from: <a href="https://blog.csdn.net/m0_37477175/article/details/77145459" target="_blank" rel="noopener">https://blog.csdn.net/m0_37477175/article/details/77145459</a></li></ul><p>dropoutbaggingdropoutbagging</p><h2 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h2><ul><li>baggingensemble methods,generalization error </li><li>bagging<strong></strong>model averaging </li><li>model averaging  </li><li>bagging<strong></strong><a href="https://www.baidu.com/s?wd=%E6%96%B0%E6%95%B0%E6%8D%AE&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener"></a><strong></strong> </li><li><strong></strong> </li><li>bagging888 </li><li>Each of these individual classification ruls is brittle, but if we average there output then the detector is robust.<br><img src="https://img-blog.csdn.net/20170813153102572?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzc0NzcxNzU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></li></ul><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><ul><li><p>dropoutbagging </p></li><li><p> </p></li><li><p>dropout<a href="https://www.baidu.com/s?wd=%E7%A5%9E%E7%BB%8F%E5%85%83&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener"></a> </p></li><li><p><br><img src="https://img-blog.csdn.net/20170813154717429?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzc0NzcxNzU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p></li><li><p>wider layers</p></li><li><p>0</p></li><li><p>minibatch1</p></li></ul><h2 id="baggingdropout"><a href="#baggingdropout" class="headerlink" title="baggingdropout"></a>baggingdropout</h2><ul><li>baggingdropout</li><li>baggingdropout</li><li><strong></strong></li></ul><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><ul><li>very computationally cheapdropoutO(n)<br>nO(n)</li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/03/22/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2019/03/22/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<p>from: <a href="https://blog.csdn.net/raojunyang/article/details/79962665" target="_blank" rel="noopener">https://blog.csdn.net/raojunyang/article/details/79962665</a></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><br></p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">- </span></span><br><span class="line"><span class="bullet">- </span></span><br><span class="line"><span class="bullet">- </span></span><br><span class="line"><span class="bullet">- </span>batchnorm</span><br><span class="line"><span class="bullet">- </span></span><br><span class="line"><span class="bullet">- </span>LSTM</span><br></pre></td></tr></table></figure><h1 id=""><a href="#" class="headerlink" title=""></a></h1><hr><ul><li><p>LSTM ( </p></li><li><p> </p></li><li><p> </p></li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1baz0q65tj30e809edj1.jpg"><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><strong></strong><strong></strong>sigmoid<strong></strong></p><h3 id="1-"><a href="#1-" class="headerlink" title="1."></a>1.</h3><p><br><img src="https://img-blog.csdn.net/20171219215626301?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>,, <br>BP<br><br>1<strong></strong>1<strong></strong>1</p><p><br>21</p><p><img src="https://img-blog.csdn.net/20171220110058983?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20171220110732927?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><p><strong></strong><strong></strong><a href="https://www.baidu.com/s?wd=%E5%85%88%E5%A4%A9%E4%B8%8D%E8%B6%B3&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener"></a>Hintoncapsule</p><h3 id="2-"><a href="#2-" class="headerlink" title="2."></a>2.</h3><p>sigmoidsigmoidsigmoid0.25sigmoid<br><img src="https://img-blog.csdn.net/20171220113129230?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="sigmoid"><img src="https://img-blog.csdn.net/20171220113422675?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="sigmoid"></p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built-in">tanh</span><span class="built-in">tanh</span><span class="built-in">sigmoid</span><span class="number">1</span><span class="built-in">tanh</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20171220114016270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><hr><h3 id="2-1-1-"><a href="#2-1-1-" class="headerlink" title="2.1 1-"></a>2.1 1-</h3><p>Hinton2006Hintonpre-trainingfine-tunningHintonDeep Belief NetworksBP</p><h3 id="2-2-2-"><a href="#2-2-2-" class="headerlink" title="2.2 2-"></a>2.2 2-</h3><p><strong></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WGANWGANlipchitz</span><br></pre></td></tr></table></figure><p><strong></strong>weithts regularizationAPI</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regularization_loss = tf.add_n(tf<span class="selector-class">.losses</span><span class="selector-class">.get_regularization_losses</span>(scope=<span class="string">'my_resnet_50'</span>))</span><br></pre></td></tr></table></figure><p></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l2_loss = tf.add_n([tf<span class="selector-class">.nn</span><span class="selector-class">.l2_loss</span>(var) <span class="keyword">for</span> <span class="selector-tag">var</span> <span class="keyword">in</span> tf.trainable_variables() <span class="keyword">if</span> <span class="string">'weights'</span> <span class="keyword">in</span> <span class="selector-tag">var</span>.name])</span><br></pre></td></tr></table></figure><p> </p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-3-3-reluleakreluelu"><a href="#2-3-3-reluleakreluelu" class="headerlink" title="2.3 3-reluleakreluelu"></a>2.3 3-reluleakreluelu</h3><p><strong>Relu:</strong>1relurelu</p><p><img src="https://img-blog.csdn.net/20171220115642365?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><p></p><p><img src="https://img-blog.csdn.net/20171220115719332?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>relu1relu</p><p><strong>relu</strong></p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- </span></span><br><span class="line"><span class="comment">-- </span></span><br><span class="line"><span class="comment">-- </span></span><br></pre></td></tr></table></figure><p><strong></strong></p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 0</span></span><br><span class="line"> <span class="comment">-- 0</span></span><br></pre></td></tr></table></figure><p>relu</p><p><strong>leakrelu</strong><br>leakrelurelu0kleak0.010.02</p><p><img src="https://img-blog.csdn.net/20170702211001517?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2FpY2FpYXRuYnU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><p>leakrelu0relu<br><strong>elu</strong><br>elurelu0<img src="https://img-blog.csdn.net/20171220134603079?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></p><p><img src="https://img-blog.csdn.net/20171220134614121?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><p>eluleakrelu</p><h3 id="2-4-4-batchnorm"><a href="#2-4-4-batchnorm" class="headerlink" title="2.4 4-batchnorm"></a>2.4 4-batchnorm</h3><p><strong>Batchnorm</strong>Batchnormbatchnormbatch normalizationBNx01<br>batchnormbatchnorm<br>batchnorm<br>batch norm<br><a href="http://blog.csdn.net/qq_25737169/article/details/79048516" target="_blank" rel="noopener">http://blog.csdn.net/qq_25737169/article/details/79048516</a></p><h3 id="2-5-5-"><a href="#2-5-5-" class="headerlink" title="2.5 5-"></a>2.5 5-</h3><p><strong></strong>Deep Residual Learning for Image Recognition<a href="https://zhuanlan.zhihu.com/p/31852747" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31852747</a><br>image netshortcut<br><img src="https://img-blog.csdn.net/20171220144105760?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjU3MzcxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br><br><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%20loss%7D%7B%5Cpartial%20%7B%7Bx%7D_%7Bl%7D%7D%7D=%5Cfrac%7B%5Cpartial%20loss%7D%7B%5Cpartial%20%7B%7Bx%7D_%7BL%7D%7D%7D%5Ccdot%20%5Cfrac%7B%5Cpartial%20%7B%7Bx%7D_%7BL%7D%7D%7D%7B%5Cpartial%20%7B%7Bx%7D_%7Bl%7D%7D%7D=%5Cfrac%7B%5Cpartial%20loss%7D%7B%5Cpartial%20%7B%7Bx%7D_%7BL%7D%7D%7D%5Ccdot%20%5Cleft%28%201%2B%5Cfrac%7B%5Cpartial%20%7D%7B%5Cpartial%20%7B%7Bx%7D_%7BL%7D%7D%7D%5Csum%5Climits_%7Bi=l%7D%5E%7BL-1%7D%7BF%28%7B%7Bx%7D_%7Bi%7D%7D,%7B%7BW%7D_%7Bi%7D%7D%29%7D%20%5Cright%29" alt=""><br>   L 1weights-11</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-6-6-LSTM"><a href="#2-6-6-LSTM" class="headerlink" title="2.6 6-LSTM"></a>2.6 6-LSTM</h3><p><strong>LSTM</strong>long-short term memory networksLSTM(gates)LSTMCNNLSTM</p><p><img src="http://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></p><h2 id=""><a href="#" class="headerlink" title=":"></a>:</h2><p>1.Neural networks and deep learning<br>2.<a href="https://www.baidu.com/s?wd=%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener"></a> </p><ol start="3"><li><p><a href="https://www.cnblogs.com/willnote/p/6912798.html&gt;" target="_blank" rel="noopener">https://www.cnblogs.com/willnote/p/6912798.html&gt;</a> </p></li><li><p><a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">https://www.zhihu.com/question/38102762</a> </p><ol start="5"><li><a href="http://www.jianshu.com/p/9dc9f41f0b29" target="_blank" rel="noopener">http://www.jianshu.com/p/9dc9f41f0b29</a></li></ol></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python: list vs tuple</title>
      <link href="/2019/03/20/python-list-vs-tuple/"/>
      <url>/2019/03/20/python-list-vs-tuple/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://shiyaya.github.io/2019/03/12/python%E5%9F%BA%E7%A1%80%EF%BC%9A-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-python-%E4%B8%AD%E7%9A%84%E8%B5%8B%E5%80%BC%E3%80%81%E5%BC%95%E7%94%A8%E3%80%81%E6%8B%B7%E8%B4%9D%E3%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F/" target="_blank" rel="noopener">shiyaya.github.io-python  python </a></p></li><li><p><a href="https://data-flair.training/blogs/python-tuples-vs-lists/" target="_blank" rel="noopener">https://data-flair.training/blogs/python-tuples-vs-lists/</a>  </p></li></ul><table><thead><tr><th>list</th><th>tuple</th></tr></thead><tbody><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td>a= [1,2,3]<br>b=a<br>b[0]=8<br>print(a) #a=[8,2,3]</td><td></td></tr><tr><td>slice<br>del a[0:2]</td><td>slice<br>del a[0:2]#</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/03/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2019/03/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<ul><li><p>L1L2<br>L1L2L10L20</p></li><li><p><br>1<br>2L1L2</p></li><li><p><br>Precision  (TP+FP)(TP)</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1asfgshjuj307c01d3yb.jpg">Recall  (TP+FN)(TP)<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1asfv7ikpj306d019t8i.jpg">  Accuracy  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1asg2ggqgj30ab01eglg.jpg">F1-measure  F1PrecisionRecallPR<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1asgb0qo9j304701dwe9.jpg"></li><li><p><br>kernel lr  lr <br>lr </p></li><li><p>pooling max poolingaverage poolingmax pooling<br>1NLP<br>maxpoolingpositioninvariancemaxpoolingoutput<br>22D1DconvolutionFilter<br>3xCNNcnnxpoolingfilterFilterPooling<br>4yaya: pooling image size<br>max-pooling, max-pooling.</p></li></ul><p><strong>average poolingmax pooling</strong>Flatten</p><ul><li><p>1x1<br>1*1NINGooglenet<br>1<br>2<br>3feature map feature map</p></li><li><p> <br><a href="https://blog.csdn.net/raojunyang/article/details/79962665" target="_blank" rel="noopener">https://blog.csdn.net/raojunyang/article/details/79962665</a><br><br>yaya: <br>sigmoid/tanhsigmoid1/2<br>123batch normalization4</p></li><li><p>CNNRNN  </p></li><li><p><br>L1L2dropout</p></li><li><p>sigmoidtanhrelu. Leaky ReLU<br>sigmoidtanh <br>relu x&gt;0<br>leaky relu </p></li><li><p>relu0  </p></li><li><p>batch size  </p></li><li><p>batch normalization<br>mini batch </p></li><li><p>dropoutbagging<br><a href="https://blog.csdn.net/m0_37477175/article/details/77145459" target="_blank" rel="noopener">https://blog.csdn.net/m0_37477175/article/details/77145459</a><br>bagging </p></li><li><p>data augmentation  </p></li><li><p>sgd, momentum, rmsprop, adam  </p></li><li><p><br><br>1<strong></strong>0<br>2<strong></strong><br>3<strong></strong>Relu<br>4<strong></strong></p></li></ul><p>1leetcode<br>face++60%70%face++residual netshuffle net<br>leetcode mediumBug-free. <br><br>&lt;1&gt; C++lower_boundupper_bound.<br>&lt;2&gt;  <br>&lt;3&gt; <br>O(n)<br>&lt;4&gt; <br>O(n)<br>&lt;5&gt; kk + n-k<br>O(n)<br>&lt;6&gt; 0101<br>O(n)<br>&lt;7&gt; K K <br>O(n^2)<br>&lt;8&gt; 011<br>O(n^2)<br>&lt;9&gt; <br>O(n) (Manacher)<br>&lt;10&gt; 0x 1120x<br>&lt;11&gt; <br>&lt;12&gt; nkk &lt; n) kmax pooling<br>O(n)<br>&lt;13&gt; <br>&lt;14&gt; nsm10 A,T,C,G<br>&lt;15&gt; </p><p>2<br><br><br>&lt;1&gt; <br>ps<br>&lt;2&gt; na1, a2, a3. an <br>&lt;3&gt; 0.5. <br>&lt;4&gt; 10.5<br>&lt;5&gt;  <br>&lt;6&gt; <br>&lt;7&gt; </p><p>3<br><br><br>&lt;1&gt; <br>&lt;2&gt; <br>&lt;3&gt; <br>&lt;4&gt; L1L2<br>&lt;5&gt; <br>&lt;6&gt; <br>&lt;7&gt; GBDTGBDT GBDTAdaboost<br>&lt;8&gt; softmax loss<br>&lt;9&gt; SVM, SVMLR<br>&lt;10&gt;PCAPCASVD<br>&lt;11&gt; ensemble<br>&lt;12&gt; ensemble<br> </p><p>4<br>BengioDeep learning @ -<br><br>&lt;1&gt; BP<br>&lt;2&gt; RNNLSTM<br>&lt;3&gt; LSTMgateRNNLSTM<br>&lt;4&gt; pooling max poolingaverage poolingmax pooling<br>&lt;5&gt;  <br>&lt;6&gt; CNNRNN<br>&lt;6&gt; <br>&lt;7&gt; sigmoidtanhrelu. <br>&lt;8&gt; relu0<br>&lt;9&gt; batch size<br>&lt;10&gt; batch normalization<br>&lt;11&gt; CNNCNNchannel<br>&lt;12&gt; AlexNet<br>&lt;13&gt; dropoutbagging<br>&lt;14&gt; data augmentation<br>&lt;15&gt; sgd, momentum, rmsprop, adam<br>&lt;16&gt; <br>&lt;17&gt;  1x1<br>..<br></p><p>5<br>paperinsightintuition<br><br>&lt;1&gt; motivation<br>&lt;2&gt; paper<br>&lt;3&gt;  AlexNet VGGGoogleNet Residual Netcontribution<br>&lt;4&gt; XXX paper? <br><br>6 <br>C++ Python Linux<br>7/ / <br></p><p>wendy_<br><a href="https://www.jianshu.com/p/d40fc51874c8" target="_blank" rel="noopener">https://www.jianshu.com/p/d40fc51874c8</a><br><br></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Unexpected key(s) in state_dict: **module**.features.conv1.0.weight</title>
      <link href="/2019/03/20/Unexpected-key-s-in-state-dict-%E2%80%9C-module-features-conv1-0-weight%E2%80%9D/"/>
      <url>/2019/03/20/Unexpected-key-s-in-state-dict-%E2%80%9C-module-features-conv1-0-weight%E2%80%9D/</url>
      
        <content type="html"><![CDATA[<ul><li><p><a href="https://discuss.pytorch.org/t/when-loading-a-model-unexpected-key-s-in-state-dict-module-features-conv1-0-weight/20505" target="_blank" rel="noopener">[link]</a></p></li><li><p>pytorch :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">decoder.load_state_dict(checkpoint[<span class="string">'dec'</span>])</span><br></pre></td></tr></table></figure></li></ul><p></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">Missing</span> <span class="selector-tag">key</span>(<span class="selector-tag">s</span>) <span class="selector-tag">in</span> <span class="selector-tag">state_dict</span>: <span class="selector-tag">features</span><span class="selector-class">.conv1</span><span class="selector-class">.0</span><span class="selector-class">.weight</span>,</span><br><span class="line"><span class="selector-tag">Unexpected</span> <span class="selector-tag">key</span>(<span class="selector-tag">s</span>) <span class="selector-tag">in</span> <span class="selector-tag">state_dict</span>: **<span class="selector-tag">module</span>**<span class="selector-class">.features</span><span class="selector-class">.conv1</span><span class="selector-class">.0</span><span class="selector-class">.weight</span>,</span><br></pre></td></tr></table></figure><ul><li><br>GPUnn.DataParallelGPU</li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/"/>
      <url>/2019/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="A"><a href="#A" class="headerlink" title="A"></a>A</h3><ul><li>(AAAI)   Conference on Artificial Intelligence  </li></ul><p>2019-8-30</p><ul><li>CVPR 2019: IEEE Conference on Computer Vision and Pattern Recognition    </li></ul><p><a href="http://cvpr2019.thecvf.com/" target="_blank" rel="noopener">http://cvpr2019.thecvf.com/</a> </p><p>2018-11-16<br>2019-03-02<br>2019-06-15</p><ul><li>IJCAI 2019: International Joint Conference on Artificial Intelligence</li></ul><p><a href="http://www.ijcai19.org" target="_blank" rel="noopener">http://www.ijcai19.org</a></p><p>2019-02-05<br>Aug 10 - Aug 16, 2019</p><ul><li>ICCV2019: International Conference on Computer Vision</li></ul><p><a href="http://iccv2019.thecvf.com" target="_blank" rel="noopener">http://iccv2019.thecvf.com</a></p><p>2019-05-01<br>Oct 27 - Nov 3, 2019</p><ul><li>ECCV</li></ul><p>3  14 <br>9  8-14 </p><ul><li>ACM International Conference on Multimedia (ACM MM) </li></ul><p><a href="https://www.acmmm.org/2019/" target="_blank" rel="noopener">https://www.acmmm.org/2019/</a></p><p>2019.4.1</p><h3 id="B"><a href="#B" class="headerlink" title="B"></a>B</h3><ul><li>ICME 2019: International Conference on Multimedia and Expo</li></ul><p><a href="http://www.icme2019.org" target="_blank" rel="noopener">http://www.icme2019.org</a> </p><p>2018-12-03<br>2019-03-11<br>2019-07-08</p><h3 id="C"><a href="#C" class="headerlink" title="C"></a>C</h3><ul><li>BMVC</li></ul><p><a href="http://bmvc2018.org" target="_blank" rel="noopener">http://bmvc2018.org</a></p><p>4  30 </p><ul><li>ICIP</li></ul><p>3  2 </p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(NMS)</title>
      <link href="/2019/03/20/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6-NMS/"/>
      <url>/2019/03/20/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6-NMS/</url>
      
        <content type="html"><![CDATA[<p>Non-maximum suppressionNMS</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>NSi, 1&lt;=i&lt;=N</p><p>0HN</p><p>M</p><p>1 H  m H  M</p><p>2 H  m Interection-over-unionIoU0~0.5 m  H </p><p>31 H  M </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>IoU 0~0.5<br></p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g19dbcocjfj30gw07kdmg.jpg"><p> 5 </p><p>0.98 IoU 0.98 </p><p>0.810.670.67 0.81  IoU </p><p></p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g19dbr3kk4j30gw07kdmi.jpg"><p><a href="https://blog.csdn.net/shuzfan/article/details/52711706" target="_blank" rel="noopener">https://blog.csdn.net/shuzfan/article/details/52711706</a></p><h2 id="-by-yaya"><a href="#-by-yaya" class="headerlink" title=" by yaya:"></a> by yaya:</h2><ul><li>faster r-cnnpred_boxescls_boxes objectsNMSclass_agnostic=falsebboxN</li><li>object bboxIOUIoU</li><li>bboxIoUobjectobjectIoU</li><li>bbox</li><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">1</span>, imdb.num_classes):</span><br><span class="line">    inds = torch.nonzero(scores[:,j]&gt;thresh).view(<span class="number">-1</span>) </span><br><span class="line">    <span class="comment"># thresh = 0   inds.shape = torch.Size([300])</span></span><br><span class="line">    <span class="comment"># if there is det</span></span><br><span class="line">    <span class="keyword">if</span> inds.numel() &gt; <span class="number">0</span>:</span><br><span class="line">      cls_scores = scores[:,j][inds] <span class="comment"># 300object</span></span><br><span class="line">      _, order = torch.sort(cls_scores, <span class="number">0</span>, <span class="literal">True</span>) <span class="comment"># 300object</span></span><br><span class="line">      <span class="keyword">if</span> args.class_agnostic:</span><br><span class="line">        cls_boxes = pred_boxes[inds, :]</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        cls_boxes = pred_boxes[inds][:, j * <span class="number">4</span>:(j + <span class="number">1</span>) * <span class="number">4</span>]  <span class="comment"># predict bbox</span></span><br><span class="line">      </span><br><span class="line">      cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(<span class="number">1</span>)), <span class="number">1</span>)  <span class="comment"># torch.Size([300, 5])</span></span><br><span class="line">      <span class="comment"># cls_dets = torch.cat((cls_boxes, cls_scores), 1)</span></span><br><span class="line">      cls_dets = cls_dets[order]  <span class="comment"># torch.Size([300, 5]) cat</span></span><br><span class="line">      keep = nms(cls_dets, cfg.TEST.NMS)  <span class="comment"># torch.Size([91, 1])</span></span><br><span class="line">      cls_dets = cls_dets[keep.view(<span class="number">-1</span>).long()]  <span class="comment"># torch.Size([91, 5])</span></span><br><span class="line">      <span class="keyword">if</span> vis:</span><br><span class="line">        im2show = vis_detections(im2show, imdb.classes[j], cls_dets.cpu().numpy(), <span class="number">0.3</span>)</span><br><span class="line">      all_boxes[j][i] = cls_dets.cpu().numpy()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      all_boxes[j][i] = empty_array</span><br></pre></td></tr></table></figure></li></ul><p>HappyRocking<br>CSDN<br><a href="https://blog.csdn.net/HappyRocking/article/details/79970627" target="_blank" rel="noopener">https://blog.csdn.net/HappyRocking/article/details/79970627</a><br></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CV vs PIL</title>
      <link href="/2019/03/20/CV-vs-PIL/"/>
      <url>/2019/03/20/CV-vs-PIL/</url>
      
        <content type="html"><![CDATA[<h2 id="PIL"><a href="#PIL" class="headerlink" title="PIL"></a>PIL</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line">pil_image = Image.open(<span class="string">'test.jpg'</span>) <span class="comment"># 360x480 x  </span></span><br><span class="line">print(type(pil_image)) <span class="comment"># out: PIL.JpegImagePlugin.JpegImageFile  </span></span><br><span class="line">print(pil_image.size)  <span class="comment"># out: (360,480) # w,h  </span></span><br><span class="line">print(pil_image.mode) <span class="comment"># out: 'RGB'  </span></span><br><span class="line">  </span><br><span class="line">pil_image = np.array(pil_image,dtype=np.float32) <span class="comment"># image = np.array(image)uint8  </span></span><br><span class="line">print(pil_image.shape) <span class="comment"># out: (480, 360, 3)  </span></span><br><span class="line"><span class="comment"># wh(h,w,c)  </span></span><br><span class="line"><span class="comment"># ndarray row x col x dim </span></span><br></pre></td></tr></table></figure><blockquote><pre><code>&lt;class &apos;PIL.JpegImagePlugin.JpegImageFile&apos;&gt;(360, 480)RGB(480, 360, 3)</code></pre></blockquote><p>pycharmnumpy array</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g193y86ko4j30lt0ixmy8.jpg">  <blockquote><p>PIL.Imageimagew,h,cimage.mode = RGB<br>PIL.Imagenumpy.arrayimage.sizeh,w,c,c RGB</p></blockquote><h2 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line">cv_image = cv2.imread(<span class="string">'test.jpg'</span>)  </span><br><span class="line">print(type(cv_image)) <span class="comment"># out: numpy.ndarray  </span></span><br><span class="line">print(cv_image.dtype) <span class="comment"># out: dtype('uint8')  </span></span><br><span class="line">print(cv_image.shape) <span class="comment"># out: (360,480, 3) (h,w,c) skimage  </span></span><br><span class="line"><span class="comment"># print(image) # BGR</span></span><br></pre></td></tr></table></figure><h2 id="PIL--CV"><a href="#PIL--CV" class="headerlink" title="PIL  CV"></a>PIL  CV</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(cv_image == pil_image)</span><br></pre></td></tr></table></figure><p>  False True False<br><strong>PILRGBCVBGR</strong><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g194ap1lw4j306d07zmx0.jpg"></p><p></p><ol><li>PILPIL.imagew,h,cRGB</li><li>numpy.arrayh,w,cRGB</li><li>CVnumpy.arrayh,w,cBGR</li></ol><ul><li></li><li>pytorchimageRGB</li><li>caffeBGR</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pytorch_normalze</span><span class="params">(img)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    https://github.com/pytorch/vision/issues/223</span></span><br><span class="line"><span class="string">    return appr -1~1 RGB</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    normalize = tvtsf.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                                std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    img = normalize(t.from_numpy(img))</span><br><span class="line">    <span class="keyword">return</span> img.numpy()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">caffe_normalize</span><span class="params">(img)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    return appr -125-125 BGR</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    img = img[[<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>], :, :]  <span class="comment"># RGB-BGR</span></span><br><span class="line">    img = img * <span class="number">255</span></span><br><span class="line">    mean = np.array([<span class="number">122.7717</span>, <span class="number">115.9465</span>, <span class="number">102.9801</span>]).reshape(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    img = (img - mean).astype(np.float32, copy=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python-tryexcept</title>
      <link href="/2019/03/19/python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-try%E4%B8%8Eexcept%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E8%AF%AD%E5%8F%A5/"/>
      <url>/2019/03/19/python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-try%E4%B8%8Eexcept%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E8%AF%AD%E5%8F%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="try-except"><a href="#try-except" class="headerlink" title="try/except"></a>try/except</h2><blockquote><p>pythontry/exceptpythontry/finally<strong>try/except**</strong>try/finally**try/except/else/finally</p><p>try/exceptpython shellpython shellpython shell</p></blockquote><h2 id="try-except"><a href="#try-except" class="headerlink" title="try/except"></a>try/except</h2><blockquote><p>pythontry/except/else/finally</p><p>try:</p><p>     Normal execution block</p><p>except A:</p><p>     Exception A handle</p><p>except B:</p><p>     Exception B handle</p><p>except:</p><p>     Other exception handle</p><p>else:</p><p>     if no exception,get here</p><p>finally:</p><p>     print(finally)   </p></blockquote><blockquote><p></p><p>tryNormal execution block<strong>Normal execution block</strong></p><p>python<strong>except X</strong>exceptionexception handleexceptexceptexceptionpython<strong></strong></p><p>Normal execution blockNormal execution blockelse</p></blockquote><blockquote><p>finallytry/except/else/finallyfinally</p><p></p><p>1.try/except/else/finallytry&gt;except X&gt;except&gt;else&gt;finally<strong>exceptelsefinally</strong><strong>elsefinally</strong><strong>except Xexcept</strong></p><p>2.try/exceptelsefinallye<strong>lsefinally</strong><strong>finally</strong><strong></strong></p><p>3.elseexcept Xexcept<strong>excepttry blockelse</strong><strong>elsetry/finally</strong></p></blockquote><p>4.except</p><p>class AError(Exception):<br>     AErrorexception<br>     print(AError)</p><blockquote><p>try:</p><p>     #raise AError</p><p>     asdas(123)</p><p>except AError:</p><p>     print(Get AError)</p><p>except:</p><p>     print(exception)     </p><p>else:</p><p>     print(else)</p><p>finally:</p><p>     print(finally)     </p><p>print(hello wolrd)</p><p>Normal execution blockexcepttry/exceptNormal execution block</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(SGAE)Auto-Encoding Scene Graphs for Image Captioning</title>
      <link href="/2019/03/16/SAGE-Auto-Encoding-Scene-Graphs-for-Image-Captioning/"/>
      <url>/2019/03/16/SAGE-Auto-Encoding-Scene-Graphs-for-Image-Captioning/</url>
      
        <content type="html"><![CDATA[<p>CVPR2019 scene graph  GCNsaptial GCNgraph :-) </p><ul><li><br>spatial  gcn  spectral gcn <br>Learning task-dependent distributed representations by backpropagation through structure.<br>A new model for  learning in graph domains<br>The graph neural network model<br>Spectral networks and locally connected networks on graphs.<br>Deep convolutional networks on graph-structured data.<br>Semi-supervised classification with graph convolutional networks</li></ul><p>graph  convolutional network</p><ul><li><br>graphsentence scene graphimage scene graphrelationshipattributeobject graphgraph relationship graphobejct<sub>a</sub> obejct<sub>b</sub>relationship<sub>ab</sub>graphrelationship embeddinggraph  </li><li>graph embedding gcn layer gcn layer  graphv<sub>i</sub>concatenate<br>gcn(.) = fc( concatenate(v1, v2,  , vn) )**</li></ul><p></p><h1 id="General-encoder-decoder-network-for-image-captioning"><a href="#General-encoder-decoder-network-for-image-captioning" class="headerlink" title="General encoder-decoder network for image captioning"></a>General encoder-decoder network for image captioning</h1><ul><li><p>encoder-decoder network for image captioning <strong>CNNimageRNN</strong></p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14r211sidj30kb0fy0v3.jpg" style="zoom:80%"></li><li><p><strong>attention</strong> [1]1414512 feature map of the fourth  convolutional layer flatten to 196  512 before feed into decoderdecoder196feature vectorattention</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14rdh7wg7j33ak1ep7wj.jpg" style="zoom:50%"></li><li><p><strong>images objectobject feature attentiondecoder</strong>RPN ROI poolingobjects featureLSTMstep ,object featuresattentionLSTM[2]</p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14u74yahwj30q30modsg.jpg" style="zoom:70%"></li></ul><h1 id="encoder-decoder-baseline"><a href="#encoder-decoder-baseline" class="headerlink" title="encoder-decoder baseline"></a>encoder-decoder baseline</h1><h2 id="1-Encoder"><a href="#1-Encoder" class="headerlink" title="1. Encoder"></a><strong>1.</strong> <strong>Encoder</strong></h2><p>encoder  image-encodersentence-encoder<br>sentence-encoder  Dictionary image-encoderbaselineGCN/MGCN  Dictionaryimage-encodersentence-encoder  baselinesentence-encoder</p><p><strong>1image encoder object embeddingrelationship embedding , attribute embedding</strong></p><p>object embeddingrelationship embedding , attribute embedding</p><ul><li>object detector : [1]faster r-cnn 0.7 for proposal NMS 0.3for object NMSFaster R-CNNvisual genomeproposals0.7IoUNMSobjects 0.3IoUNMSimage10-100objectRoI pooling object featuresobject features relationship classifier attribute classifier</li><li>relationship classifier[5] LSTMobject relationship label</li><li>attribute classifier : object object featurefc-relu-fc-softmax</li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14vip74y0j311l09eq4y.jpg" style="zoom:60%">      <ul><li><p>image scene graph  </p></li><li><p><strong>Visual Genome</strong>scene graph obejcts categoriesobejcts attributes and pairwise relationships2000objectsattributesrelationships305objects10364  </p></li><li><p> label embedding: <strong>u<sub>o</sub> , u<sub>r</sub> , u<sub>a</sub></strong> <br> label 472 = 305 + 103 + 64object/realation/attribute labelone hot vector </p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14w80gi8tj30w70ik0xu.jpg" style="zoom:70%">  </li></ul><p><strong>2sentence encoder [6]  parse scene graphobject embeddingrelationship embedding , attribute embedding</strong><br>sentences<strong>MS COCO</strong>captionVisual Genomecaptionall parsed scene graphobjectsattributesrelationships105364objects1308realtionships3430attributes<br>sentence encoder [6]  parse scene graph[6][7][7]<br> [6] SPICE image caption<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1dwj56im1j30iq0nmk00.jpg"></p><p>parse scene graph sentence-&gt; syntax dependency tree-&gt; scene graph<br>scene graphscene graph sentenceobject relationattributeword one hot vector <br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1gbldqsamj30q50kntkm.jpg"></p><p>parse scene graphobject <strong>label</strong>relationship <strong>label</strong>attributes <strong>label</strong>one hot vectorone hot  5346+1308+3430 = 10102 nodelabelword embeddingword embedding: <strong>e<sub>o</sub> , e<sub>r</sub> , e<sub>a</sub></strong><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14w6j9aouj31670aqdiw.jpg" style="zoom:50%"></p><h2 id="2-Decoder"><a href="#2-Decoder" class="headerlink" title="2.  Decoder"></a><strong>2.</strong>  <strong>Decoder</strong></h2><p>LSTM[1][4] decoderencoder outputdecoder [1][4]decoder</p><ul><li>[4]encoder outputGCNobject featuresgraphencoder outputdecoder</li><li>encoder output <strong>u<sub>o</sub> , u<sub>r</sub> , u<sub>a</sub></strong> dM  <strong>e<sub>o</sub> , e<sub>r</sub> , e<sub>a</sub></strong> dM  M = num_objects + num_relationships + num_attributes  sentence-encoderMparse scene graphobjectrelationattributebaseline  sentence-encoderimage-encoderobject detectorrelationship classifierattribute classifier </li></ul><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14xg3jwvdj30mo0h2wfi.jpg" style="zoom:60%"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g19d1x7kiij30im0bvaat.jpg" style="zoom:60%"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14v8kb8kmj30sr0gzwgz.jpg" style="zoom:60%">:10369MS COCOcaptions  len of vocabulary<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14wrwfzplj30ze0hcjwe.jpg" style="zoom:60%"><h1 id="baseline-"><a href="#baseline-" class="headerlink" title="baseline "></a>baseline </h1><ul><li>encoder-decodertopMGCN for imageGCN for sentenceDictionary betwen sentence and image<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14yn2vbtej30k40jzac6.jpg" style="zoom:50%">image scene graph  sentence scene graphGCNDictionary  </li></ul><h2 id="sentence-graph-gt-GCN-embedding"><a href="#sentence-graph-gt-GCN-embedding" class="headerlink" title="sentence graph -&gt; GCN (embedding )"></a>sentence graph -&gt; GCN (embedding )</h2><p>sentence scene graph objectrelationattribute label word embeddingGCNembedding</p><ul><li>789relationshipattributeobject graph<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14y1f5p02j31370e1jw1.jpg" style="zoom:60%"></li><li><strong>g<sub>r</sub> g<sub>a</sub> g<sub>o</sub> g<sub>s</sub></strong><br><strong>g<sub>r</sub></strong> g<sub>r</sub> (D<sub>in</sub>D<sub>out</sub>3000e<sub>oi</sub> , e<sub>rij</sub> , e<sub>oj</sub>1000concatenateconcatenate3000g<sub>r</sub>1000</li><li><strong> graphv<sub>i</sub>concatenate<br>g(.) = fc( concatenate(v1, v2,  , vn) )</strong><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14y594pa8j30og0ksdi2.jpg" style="zoom:50%">  </li></ul><h2 id="image-graph-gt-Multi-modal-GCN-embedding"><a href="#image-graph-gt-Multi-modal-GCN-embedding" class="headerlink" title="image graph -&gt; Multi-modal GCN (embedding )"></a>image graph -&gt; Multi-modal GCN (embedding )</h2><p>sentence graph GCN multimodal 91011label word embeddingfeature<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14yf14p1mj30sp0k0ten.jpg">  </p><ul><li><strong>f<sub>r</sub> f<sub>a</sub> f<sub>o</sub> f<sub>s</sub></strong><br>sentence scene graph gconcatenate<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14yhc6gpzj314l0gktax.jpg"></li></ul><h2 id="Dictionary"><a href="#Dictionary" class="headerlink" title="Dictionary"></a>Dictionary</h2><ul><li><strong></strong>memory networkDictionary<strong>S-&gt;G-&gt;D-&gt;S</strong><strong>I-&gt;G-&gt;D-&gt;S</strong>  <strong>S-&gt;G-&gt;D-&gt;S</strong>sentencehuman generatedDictionarypreserve humans inductive bias<strong>I-&gt;G-&gt;D-&gt;S</strong>  image predict caption humans inductive bias</li><li>GCN/MGCNembedding1000Dictionary1000D1000*10000xDictionary x^<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14yrlt89sj310c07e40b.jpg">  </li></ul><h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>encoder GCN/MGCNdecoder</p><ul><li><strong>S-&gt;G-&gt;D-&gt;S</strong> D-&gt;S decoder LSTMD</li><li><strong>I-&gt;G-&gt;D-&gt;S</strong> decoder LSTMDvGv^concate[v, v^]<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g1507wpmlij30zf0h8dku.jpg"></li></ul><h1 id=""><a href="#" class="headerlink" title=""></a></h1><ul><li> <strong>S-&gt;G-&gt;S</strong>  20 epochD</li><li> <strong>S-&gt;G-&gt;D-&gt;S</strong>  20 epochD</li><li> <strong>I-&gt;G-&gt;D-&gt;S</strong>  20 epochDfine-tune</li><li>RL-based reward  <strong>I-&gt;G-&gt;D-&gt;S</strong>  40 epoch D  </li></ul><h1 id=""><a href="#" class="headerlink" title=""></a></h1><ul><li><strong>I-&gt;G-&gt;D-&gt;S</strong>  </li></ul><h1 id=""><a href="#" class="headerlink" title=""></a></h1><ul><li>GCN-LSTM[7]GCN-LSTM</li><li>GCN-LSTM GCN-LSTMbatch_size bsGCN-LSTMsem graphGCN-LSTMsemantic graph saptial graph</li><li>SGAEdecoder<strong>I-&gt;G-&gt;D-&gt;S</strong> DvG v^concate[v,  v^]<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g14zjng66yj30oc0f0djs.jpg">   </li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Bottom-up and top-down attention for image captioning and visual question answering<br>[2] Show, Attend and Tell: Neural Image Caption  Generation with Visual Attention<br>[3] Image Captioning with Object Detection and Localization<br>[4] Exploring Visual Relationship  for Image Captioning<br><strong>[5] Neural motifs: Scene graph parsing with global context</strong><br><strong>[6] Spice:  Semantic propositional image caption evaluation</strong><br><strong>[7] Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval</strong></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Video as Space-Time Region Graphs</title>
      <link href="/2019/03/15/Video-as-Space-Time-Region-Graphs/"/>
      <url>/2019/03/15/Video-as-Space-Time-Region-Graphs/</url>
      
        <content type="html"><![CDATA[<p><br>charadessomething-something</p><ul><li>videocharadesvideoobjectsomething-something video1~2object</li><li>videocharadesvideo30sannotationclips of videoclipssomething-somethingvideo 3s-6s  </li></ul><p>something-somethingvideoobjects of video gcn+i3d i3dcharades</p><ul><li>charadescharadespre-trainsomething-something</li></ul><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>video6 fpsvideo30video5s5sclipssamplelabel</p><h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>charadesvideo 10clips clipssomething-somethingvideo2clips</p><h2 id="Construct-Graph"><a href="#Construct-Graph" class="headerlink" title="Construct Graph"></a>Construct Graph</h2><p>charades dataset50objectsomething-something dataset 10object</p><ul><li>Similarity Graph<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g13qsziabzj30fk0ahjrw.jpg" style="zoom:65%">Similarity graph </li><li>Spatial Graph</li><li></li><li>We denote the IoU between object i in frame t and object  j in frame t + 1 as <sub>ij</sub><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g13qv0z3bxj30fq0b30t3.jpg" style="zoom:65%"></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux-CPUCPU</title>
      <link href="/2019/03/13/linux-%E7%89%A9%E7%90%86CPU%E5%92%8C%E9%80%BB%E8%BE%91CPU/"/>
      <url>/2019/03/13/linux-%E7%89%A9%E7%90%86CPU%E5%92%8C%E9%80%BB%E8%BE%91CPU/</url>
      
        <content type="html"><![CDATA[<p>cat /proc/cpuinfo CPU</p><p><img src="https:////upload-images.jianshu.io/upload_images/5262207-4e29a8e7da45169c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/837/format/webp" alt="img"></p><p>cpu.png</p><p>physical id CPU<br> CPU cores CPU<br> core id <br> processor CPU</p><p>CPU=CPU * CPU * <br>  CPU=CPU * CPU </p><p></p><p><a href="https://www.jianshu.com/p/ff8e8be262ac" target="_blank" rel="noopener">https://www.jianshu.com/p/ff8e8be262ac</a></p><p></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux-cpu</title>
      <link href="/2019/03/13/linux-%E6%9F%A5%E7%9C%8Bcpu%E7%8A%B6%E6%80%81/"/>
      <url>/2019/03/13/linux-%E6%9F%A5%E7%9C%8Bcpu%E7%8A%B6%E6%80%81/</url>
      
        <content type="html"><![CDATA[<ul><li> <a href="https://www.tianmaying.com/tutorial/cpu-top&quot;" target="_blank" rel="noopener">https://www.tianmaying.com/tutorial/cpu-top&quot;</a><br><code>top</code><code>Linux</code></li></ul><p><code>top</code></p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">top - 23:16:12 up  7:40, <span class="number"> 1 </span>user,  load average: 0.97, 0.98, 1.01</span><br><span class="line">Tasks:<span class="number"> 440 </span>total,  <span class="number"> 2 </span>running,<span class="number"> 438 </span>sleeping,  <span class="number"> 0 </span>stopped,  <span class="number"> 0 </span>zombie</span><br><span class="line">%Cpu(s):  1.3 us,  1.4 sy,  0.0 ni, 96.9 id,  0.0 wa,  0.0 hi,  0.4 si,  0.0 st</span><br><span class="line">KiB Mem : 13183891+total, 12378241+free, <span class="number"> 3884532 </span>used, <span class="number"> 4171956 </span>buff/cache</span><br><span class="line">KiB Swap:       <span class="number"> 0 </span>total,       <span class="number"> 0 </span>free,       <span class="number"> 0 </span>used. 12719112+avail Mem </span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                               </span><br><span class="line">11746 jenkins  <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 159972 </span> <span class="number"> 4760 </span> <span class="number"> 1600 </span>R  99.7  0.0 362:41.65 root/2                                                                                                                </span><br><span class="line">  <span class="number"> 42 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   4.3  0.0  14:46.50 rcu_sched                                                                                                             </span><br><span class="line">  <span class="number"> 68 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   2.6  0.0   0:55.10 rcuos/25                                                                                                              </span><br><span class="line">11414 jenkins  <span class="number"> 20 </span> <span class="number"> 0 </span>42.134g 1.652g <span class="number"> 24516 </span>S   0.7  1.3   2:37.54 java                                                                                                                  </span><br><span class="line">  <span class="number"> 49 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:32.35 rcuos/6                                                                                                               </span><br><span class="line"><span class="number"> 6818 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:34.33 kworker/0:1                                                                                                           </span><br><span class="line">14702 root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:00.26 kworker/2:0                                                                                                           </span><br><span class="line">15491 txq      <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 158044 </span> <span class="number"> 2616 </span> <span class="number"> 1552 </span>R   0.3  0.0   0:00.13 top                                                                                                                   </span><br><span class="line">   <span class="number"> 1 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span> <span class="number"> 45892 </span> <span class="number"> 8580 </span> <span class="number"> 3908 </span>S   0.0  0.0   0:13.06 systemd                                                                                                               </span><br><span class="line">   <span class="number"> 2 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.06 kthreadd</span><br></pre></td></tr></table></figure><p></p><p>1515</p><p><code>Tasks</code>44043800</p><p><code>CPU</code></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%<span class="selector-tag">Cpu</span>(<span class="selector-tag">s</span>):  1<span class="selector-class">.3</span> <span class="selector-tag">us</span>,  1<span class="selector-class">.4</span> <span class="selector-tag">sy</span>,  0<span class="selector-class">.0</span> <span class="selector-tag">ni</span>, 96<span class="selector-class">.9</span> <span class="selector-tag">id</span>,  0<span class="selector-class">.0</span> <span class="selector-tag">wa</span>,  0<span class="selector-class">.0</span> <span class="selector-tag">hi</span>,  0<span class="selector-class">.4</span> <span class="selector-tag">si</span>,  0<span class="selector-class">.0</span> <span class="selector-tag">st</span></span><br></pre></td></tr></table></figure><p><code>us</code> user CPU time -<code>CPU</code></p><p><code>sy</code> system CPU time-<code>CPU</code></p><p><code>ni</code> nice CPU time-<code>CPU</code></p><p><code>id</code> idle-<code>CPU</code></p><p><code>wa</code> iowait- <code>CPU</code></p><p><code>hi</code> hardware irq-</p><p><code>si</code> software irq-</p><p><code>st</code> steal time-</p><p></p><p><code>Memory</code>13183891+12378241+38845324171956</p><p><code>Swap</code>00012719112+</p><p></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PID   <span class="built_in"> USER </span>     PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+   COMMAND</span><br><span class="line">PID`  `id</span><br></pre></td></tr></table></figure><p><code>USER</code>  </p><p><code>PR</code>  </p><p><code>NI</code>  nice</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">VIRT`  `VIRT=SWAP+RES</span><br><span class="line">RES`  `RES=CODE+DATA</span><br></pre></td></tr></table></figure><p><code>SHR</code>  </p><p><code>S</code> <code>D</code>= <code>R</code>= <code>S</code>= <code>T</code>=/ <code>Z</code>=</p><p><code>%CPU</code>  <code>CPU</code></p><p><code>%MEM</code>  </p><p><code>TIME+</code>  <code>CPU</code></p><p><code>COMMAND</code>  /</p><p></p><p><code>1</code></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">top - <span class="number">23</span>:<span class="number">16</span>:<span class="number">12</span> <span class="keyword">up</span>  <span class="number">7</span>:<span class="number">40</span>,  <span class="number">1</span> user,  load average: <span class="number">0.97</span>, <span class="number">0.98</span>, <span class="number">1.01</span></span><br><span class="line">Task<span class="variable">s:</span> <span class="number">440</span> total,   <span class="number">2</span> running, <span class="number">438</span> sleeping,   <span class="number">0</span> stopped,   <span class="number">0</span> zombie</span><br><span class="line">%Cpu0  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu1  :  <span class="number">0.0</span> us,  <span class="number">0.3</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni, <span class="number">99.7</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu2  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu3  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu4  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu5  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu6  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu7  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu8  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu9  :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu10 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu11 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu12 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu13 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu14 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu15 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu16 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu17 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu18 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu19 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu20 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu21 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu22 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu23 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu24 : <span class="number">44.2</span> us, <span class="number">43.9</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,  <span class="number">0.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>, <span class="number">12.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu25 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu26 :  <span class="number">0.3</span> us,  <span class="number">0.3</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni, <span class="number">99.3</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu27 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu28 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu29 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu30 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">%Cpu31 :  <span class="number">0.0</span> us,  <span class="number">0.0</span> <span class="keyword">sy</span>,  <span class="number">0.0</span> ni,<span class="number">100.0</span> id,  <span class="number">0.0</span> <span class="keyword">wa</span>,  <span class="number">0.0</span> <span class="keyword">hi</span>,  <span class="number">0.0</span> si,  <span class="number">0.0</span> <span class="keyword">st</span></span><br><span class="line">KiB Mem : <span class="number">13183891</span>+total, <span class="number">12377862</span>+free,  <span class="number">3887628</span> used,  <span class="number">4172660</span> buff/cache</span><br><span class="line">KiB Swap:        <span class="number">0</span> total,        <span class="number">0</span> free,        <span class="number">0</span> used. <span class="number">12718814</span>+avail Mem </span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                               </span><br><span class="line"><span class="number">11746</span> jenkins   <span class="number">20</span>   <span class="number">0</span>  <span class="number">159972</span>   <span class="number">4760</span>   <span class="number">1600</span> R <span class="number">100.0</span>  <span class="number">0.0</span> <span class="number">393</span>:<span class="number">16.94</span> root/<span class="number">2</span>                                                                                                                </span><br><span class="line">   <span class="number">42</span> root      <span class="number">20</span>   <span class="number">0</span>       <span class="number">0</span>      <span class="number">0</span>      <span class="number">0</span> S   <span class="number">2.7</span>  <span class="number">0.0</span>  <span class="number">15</span>:<span class="number">59.27</span> rcu_sched                                                                                                             </span><br><span class="line">   <span class="number">67</span> root      <span class="number">20</span>   <span class="number">0</span>       <span class="number">0</span>      <span class="number">0</span>      <span class="number">0</span> S   <span class="number">1.3</span>  <span class="number">0.0</span>   <span class="number">1</span>:<span class="number">03.60</span> rcuos/<span class="number">24</span></span><br></pre></td></tr></table></figure><p><code>1</code><code>CPU</code>32<code>CPU</code></p><p></p><p><code>b</code><code>shift+&gt;</code><code>shift+&lt;</code></p><p><code>x</code><code>b</code><code>shift+&gt;</code><code>shift+&lt;</code></p><p><code>top -c</code></p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">top - 23:56:31 up  8:20, <span class="number"> 1 </span>user,  load average: 0.95, 0.97, 1.00</span><br><span class="line">Tasks:<span class="number"> 439 </span>total,  <span class="number"> 2 </span>running,<span class="number"> 437 </span>sleeping,  <span class="number"> 0 </span>stopped,  <span class="number"> 0 </span>zombie</span><br><span class="line">%Cpu(s):  1.4 us,  1.5 sy,  0.0 ni, 96.8 id,  0.0 wa,  0.0 hi,  0.4 si,  0.0 st</span><br><span class="line">KiB Mem : 13183891+total, 12377344+free, <span class="number"> 3892304 </span>used, <span class="number"> 4173168 </span>buff/cache</span><br><span class="line">KiB Swap:       <span class="number"> 0 </span>total,       <span class="number"> 0 </span>free,       <span class="number"> 0 </span>used. 12718340+avail Mem </span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                               </span><br><span class="line">11746 jenkins  <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 159972 </span> <span class="number"> 4760 </span> <span class="number"> 1600 </span>R 100.0  0.0 402:57.42 root/2                                                                                                                </span><br><span class="line">  <span class="number"> 42 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   3.3  0.0  16:21.24 [rcu_sched]                                                                                                           </span><br><span class="line">  <span class="number"> 57 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.7  0.0   1:03.01 [rcuos/14]                                                                                                            </span><br><span class="line">  <span class="number"> 63 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:29.22 [rcuos/20]                                                                                                            </span><br><span class="line"><span class="number"> 7933 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:05.50 [kworker/20:0]                                                                                                        </span><br><span class="line">11414 jenkins  <span class="number"> 20 </span> <span class="number"> 0 </span>42.134g 1.661g <span class="number"> 24516 </span>S   0.3  1.3   2:47.29 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -j+ </span><br><span class="line">14702 root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:01.48 [kworker/2:0]                                                                                                         </span><br><span class="line">15098 root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.3  0.0   0:01.37 [kworker/6:2]                                                                                                         </span><br><span class="line">18465 txq      <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 158088 </span> <span class="number"> 2720 </span> <span class="number"> 1640 </span>R   0.3  0.0   0:00.18 top -c                                                                                                                </span><br><span class="line">   <span class="number"> 1 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span> <span class="number"> 45892 </span> <span class="number"> 8580 </span> <span class="number"> 3908 </span>S   0.0  0.0   0:13.78 /usr/lib/systemd/systemd --switched-root --system --deserialize<span class="number"> 21 </span>                                                   </span><br><span class="line">   <span class="number"> 2 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.06 [kthreadd]                                                                                                            </span><br><span class="line">   <span class="number"> 3 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.34 [ksoftirqd/0]                                                                                                         </span><br><span class="line">   <span class="number"> 5 </span>root      <span class="number"> 0 </span>-20      <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.00 [kworker/0:0H]                                                                                                        </span><br><span class="line">   <span class="number"> 8 </span>root      rt  <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.35 [migration/0]                                                                                                         </span><br><span class="line">   <span class="number"> 9 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.00 [rcu_bh]                                                                                                              </span><br><span class="line">  <span class="number"> 10 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.00 [rcuob/0]                                                                                                             </span><br><span class="line">  <span class="number"> 11 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.00 [rcuob/1]</span><br></pre></td></tr></table></figure><p><code>q</code></p><p></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> cpu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NumPy </title>
      <link href="/2019/03/13/NumPy-%E5%89%AF%E6%9C%AC%E5%92%8C%E8%A7%86%E5%9B%BE/"/>
      <url>/2019/03/13/NumPy-%E5%89%AF%E6%9C%AC%E5%92%8C%E8%A7%86%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="NumPy-"><a href="#NumPy-" class="headerlink" title="NumPy "></a>NumPy </h1><p><strong></strong></p><p><strong></strong></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><strong></strong></p><ul><li>1numpy </li><li>2 ndarray  view() </li></ul><p><strong></strong></p><ul><li>Python deepCopy()</li><li> ndarray  copy() </li></ul><h2 id="yaya-"><a href="#yaya-" class="headerlink" title="yaya "></a>yaya </h2><p><strong></strong></p><ul><li>1numpy </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">6</span>)  <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b = a[:]   <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b[<span class="number">0</span>] = <span class="number">10</span>  <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line">print(a)   <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line"><span class="comment"># ba</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">6</span>)  <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b = a[:]   <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b.shape = <span class="number">2</span>,<span class="number">3</span>  <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line">print(b)  </span><br><span class="line"><span class="comment"># [[0 1]</span></span><br><span class="line"><span class="comment">#  [2 3]</span></span><br><span class="line"><span class="comment">#  [4 5]]</span></span><br><span class="line">print(a)   <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line"><span class="comment"># ba</span></span><br></pre></td></tr></table></figure><ul><li>2 ndarray  view() <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">6</span>)  <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b = a.view()   <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b[<span class="number">0</span>] = <span class="number">10</span>  <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line">print(a)   <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line"><span class="comment"># ba</span></span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">6</span>)  <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b = a[:]   <span class="comment"># [0 1 2 3 4 5]</span></span><br><span class="line">b.shape = <span class="number">2</span>,<span class="number">3</span>  <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line">print(b)  </span><br><span class="line"><span class="comment"># [[0 1]</span></span><br><span class="line"><span class="comment">#  [2 3]</span></span><br><span class="line"><span class="comment">#  [4 5]]</span></span><br><span class="line">print(a)   <span class="comment"># [10 1 2 3 4 5]</span></span><br><span class="line"><span class="comment"># ba</span></span><br></pre></td></tr></table></figure><p><strong></strong></p><ul><li>Python deepCopy()</li><li> ndarray  copy() </li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="-"><a href="#-" class="headerlink" title=" ()"></a> ()</h3><p> id() id() Python  C </p><p> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np    </span><br><span class="line">a = np.arange(<span class="number">6</span>)   </span><br><span class="line"><span class="keyword">print</span> (<span class="string">''</span>) </span><br><span class="line"><span class="keyword">print</span> (a) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">' id() '</span>) </span><br><span class="line"><span class="keyword">print</span> (id(a)) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a  b'</span>) </span><br><span class="line">b = a  <span class="keyword">print</span> (b) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'b  id()'</span>) </span><br><span class="line"><span class="keyword">print</span> (id(b)) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">' b '</span>) </span><br><span class="line">b.shape =  <span class="number">3</span>,<span class="number">2</span>   </span><br><span class="line"><span class="keyword">print</span> (b) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a '</span>) </span><br><span class="line"><span class="keyword">print</span> (a)</span><br></pre></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line"> id() </span><br><span class="line"><span class="number">4349302224</span></span><br><span class="line">a  b</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line">b  id()</span><br><span class="line"><span class="number">4349302224</span></span><br><span class="line"> b </span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span>]]</span><br><span class="line">a </span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>ndarray.view() </p><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  numpy  <span class="keyword">as</span>  np  </span><br><span class="line">a = np.arange(<span class="number">6</span>)  </span><br><span class="line"><span class="keyword">print</span>  (<span class="string">''</span>)  </span><br><span class="line"><span class="keyword">print</span>  (a)  </span><br><span class="line"><span class="keyword">print</span>  (<span class="string">' id() '</span>)  </span><br><span class="line"><span class="keyword">print</span>  (id(a))  </span><br><span class="line"><span class="keyword">print</span>  (<span class="string">'a  b'</span>)  </span><br><span class="line">b = a  <span class="keyword">print</span>  (b)  </span><br><span class="line"><span class="keyword">print</span>  (<span class="string">'b  id()'</span>)  </span><br><span class="line"><span class="keyword">print</span>  (id(b))  </span><br><span class="line"><span class="keyword">print</span>  (<span class="string">' b '</span>)  </span><br><span class="line">b.shape = <span class="number">3</span>,<span class="number">2</span>  </span><br><span class="line"><span class="keyword">print</span>  (b)  </span><br><span class="line"><span class="keyword">print</span>  (<span class="string">'a '</span>)  </span><br><span class="line"><span class="keyword">print</span>  (a)</span><br></pre></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> a</span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span>]]</span><br><span class="line"> a </span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span>]]</span><br><span class="line"> id() </span><br><span class="line">a  id()</span><br><span class="line"><span class="number">4314786992</span></span><br><span class="line">b  id()</span><br><span class="line"><span class="number">4315171296</span></span><br><span class="line">b </span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]]</span><br><span class="line">a </span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure><p></p><h2 id="-2"><a href="#-2" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np   </span><br><span class="line">arr = np.arange(<span class="number">12</span>) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">''</span>) </span><br><span class="line"><span class="keyword">print</span> (arr) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">''</span>) </span><br><span class="line">a=arr[<span class="number">3</span>:] </span><br><span class="line">b=arr[<span class="number">3</span>:] </span><br><span class="line">a[<span class="number">1</span>]=<span class="number">123</span> </span><br><span class="line">b[<span class="number">2</span>]=<span class="number">234</span> </span><br><span class="line">print(arr) </span><br><span class="line">print(id(a),id(b),id(arr[<span class="number">3</span>:]))</span><br></pre></td></tr></table></figure><p></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[ <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>  <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span> <span class="number">10</span> <span class="number">11</span>]</span><br><span class="line"></span><br><span class="line">[  <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span> <span class="number">123</span> <span class="number">234</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>]</span><br><span class="line"><span class="number">4545878416</span> <span class="number">4545878496</span> <span class="number">4545878576</span></span><br></pre></td></tr></table></figure><p> a,b  arr  a,b  id</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>ndarray.copy()  </p><h2 id="-3"><a href="#-3" class="headerlink" title=""></a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np    </span><br><span class="line">a = np.array([[<span class="number">10</span>,<span class="number">10</span>],  [<span class="number">2</span>,<span class="number">3</span>],  [<span class="number">4</span>,<span class="number">5</span>]])   </span><br><span class="line"><span class="keyword">print</span> (<span class="string">' a'</span>) </span><br><span class="line"><span class="keyword">print</span> (a) <span class="keyword">print</span> (<span class="string">' a '</span>) </span><br><span class="line">b = a.copy()   </span><br><span class="line"><span class="keyword">print</span> (<span class="string">' b'</span>) </span><br><span class="line"><span class="keyword">print</span> (b) <span class="comment"># b  a    </span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">' b  a '</span>) </span><br><span class="line"><span class="keyword">print</span> (b <span class="keyword">is</span> a) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">' b '</span>) </span><br><span class="line">b[<span class="number">0</span>,<span class="number">0</span>]  =  <span class="number">100</span>   </span><br><span class="line"><span class="keyword">print</span> (<span class="string">' b'</span>) </span><br><span class="line"><span class="keyword">print</span> (b) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a '</span>) </span><br><span class="line"><span class="keyword">print</span> (a)</span><br></pre></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> a</span><br><span class="line">[[<span class="number">10</span> <span class="number">10</span>]</span><br><span class="line"> [ <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line"> [ <span class="number">4</span>  <span class="number">5</span>]]</span><br><span class="line"> a </span><br><span class="line"> b</span><br><span class="line">[[<span class="number">10</span> <span class="number">10</span>]</span><br><span class="line"> [ <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line"> [ <span class="number">4</span>  <span class="number">5</span>]]</span><br><span class="line"> b  a </span><br><span class="line"><span class="literal">False</span></span><br><span class="line"> b </span><br><span class="line"> b</span><br><span class="line">[[<span class="number">100</span>  <span class="number">10</span>]</span><br><span class="line"> [  <span class="number">2</span>   <span class="number">3</span>]</span><br><span class="line"> [  <span class="number">4</span>   <span class="number">5</span>]]</span><br><span class="line">a </span><br><span class="line">[[<span class="number">10</span> <span class="number">10</span>]</span><br><span class="line"> [ <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line"> [ <span class="number">4</span>  <span class="number">5</span>]]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> numpy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python  </title>
      <link href="/2019/03/12/python-%E9%9D%A2%E8%AF%95/"/>
      <url>/2019/03/12/python-%E9%9D%A2%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p><a href="https://juejin.im/post/5b6bc1d16fb9a04f9c43edc3" target="_blank" rel="noopener">https://juejin.im/post/5b6bc1d16fb9a04f9c43edc3</a></p><p><a href="https://juejin.im/post/5b8505b6e51d4538884d22bf" target="_blank" rel="noopener">https://juejin.im/post/5b8505b6e51d4538884d22bf</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python  python </title>
      <link href="/2019/03/12/python%E5%9F%BA%E7%A1%80%EF%BC%9A-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-python-%E4%B8%AD%E7%9A%84%E8%B5%8B%E5%80%BC%E3%80%81%E5%BC%95%E7%94%A8%E3%80%81%E6%8B%B7%E8%B4%9D%E3%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F/"/>
      <url>/2019/03/12/python%E5%9F%BA%E7%A1%80%EF%BC%9A-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-python-%E4%B8%AD%E7%9A%84%E8%B5%8B%E5%80%BC%E3%80%81%E5%BC%95%E7%94%A8%E3%80%81%E6%8B%B7%E8%B4%9D%E3%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F/</url>
      
        <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul><li></li><li>b = a[ : ]<h3 id=""><a href="#" class="headerlink" title=""></a></h3></li></ul><p><strong>-  <a href="https://draapho.github.io/2016/11/21/1618-python-variable/" target="_blank" rel="noopener">https://draapho.github.io/2016/11/21/1618-python-variable/</a></strong></p><h3 id="list-dict-set-"><a href="#list-dict-set-" class="headerlink" title="list dict set  "></a>list dict set  </h3><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">   <span class="meta"># list</span></span><br><span class="line">a= [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">b = a</span><br><span class="line">b[<span class="number">0</span>] = <span class="number">9</span></span><br><span class="line"><span class="keyword">print</span>(b) <span class="meta"># [9, 2, 3]</span></span><br><span class="line"><span class="keyword">print</span>(a) <span class="meta"># [9, 2, 3]</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># dict</span></span><br><span class="line">a = &#123;&#125;</span><br><span class="line">a['key1'] = <span class="number">1</span></span><br><span class="line">b = a</span><br><span class="line">b['key1'] = <span class="number">9</span></span><br><span class="line"><span class="keyword">print</span>(b) <span class="meta"># &#123;'key1': 9&#125;</span></span><br><span class="line"><span class="keyword">print</span>(a) <span class="meta"># &#123;'key1': 9&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">values = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]  </span><br><span class="line">values[<span class="number">1</span>] = values  </span><br><span class="line">values  </span><br><span class="line">[<span class="number">0</span>, [...], <span class="number">2</span>] # , ?  </span><br><span class="line">[<span class="number">0</span>, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], <span class="number">2</span>] # </span><br></pre></td></tr></table></figure><p>   Python </p><h3 id="tuple-string-int-float-bool-"><a href="#tuple-string-int-float-bool-" class="headerlink" title="tuple string int float bool "></a><strong><em>tuple</em></strong> string int float bool </h3><p></p><pre><code>def func_int(a):    a += 4def func_list(a_list):    a_list[0] = 4t = 0func_int(t)print t# output: 0t_list = [1, 2, 3]func_list(t_list)print t_list# output: [4, 2, 3]</code></pre><h3 id="Dictionary--List--Tuple"><a href="#Dictionary--List--Tuple" class="headerlink" title="Dictionary  List  Tuple"></a>Dictionary  List  Tuple</h3><p></p><p><strong>Dictionary</strong> </p><ol><li>Dictionary  Python , </li><li> key-value , </li><li> key ,  key</li><li> dictionary  key key  <a href="file:///home/echo/.chmsee/bookshelf/4791a2294b7b1d4cf68b0e1df606181d/native_data_types/index.html#odbchelper.dict.2.2" target="_blank" rel="noopener"><img src="file:///home/echo/.chmsee/bookshelf/4791a2294b7b1d4cf68b0e1df606181d/images/callouts/2.png" alt="2"></a>  key-value </li><li> dictionary , : dictionary  key </li><li>Dictionary Dictionary , , , ,  dictionary dictionary , dictionary ,  Dictionary  key , ,  ()  dictionary  key </li><li><code>del</code>  key  dictionary </li><li><code>clear</code>  dictionary  dictionary</li></ol><hr><p><strong>List</strong> </p><ol><li>list</li><li>List  0  list  <code>li[0]</code></li><li><code> list  list </code> li[-1] <a href="file:///home/echo/.chmsee/bookshelf/4791a2294b7b1d4cf68b0e1df606181d/native_data_types/lists.html#odbchelper.list.2.2" target="_blank" rel="noopener"><img src="file:///home/echo/.chmsee/bookshelf/4791a2294b7b1d4cf68b0e1df606181d/images/callouts/2.png" alt="2"></a>, : <code>li[-n] == li[len(li) - n]</code>  list , <code>li[-3] == li[5 - 3] == li[2]</code></li><li><code> 2  list ,  slice  list,  list  slice  (</code> li[1]) ,  slice  (<code>li[3]</code>) </li><li><code>,  list </code> li  list ,  list,  <code>li</code> <code>li[:]</code>  list </li><li><code>``append</code>  list </li><li><code>insert</code>  list , list ,  <code>&#39;new&#39;</code> <code></code></li><li><code>extend</code>  list <code>extend</code>,  list </li><li>Lists  <code>extend</code>  <code>append</code> ,  <code>extend</code> ,  list,  list  list </li><li>, <code>append</code> , ,  list   3  list  <code>append</code> </li><li><code>index</code>  list </li><li> list ,  <code>in</code>, ,  <code>True</code>,  <code>False</code> </li><li><code>remove</code>  list </li><li><code>pop</code> :  list , ,  <code>li[-1]</code> ,  list  <code>li.remove(*value*)</code>,  list </li><li>Lists  <code>+</code>  <code>*list* = *list* + *otherlist*</code>  <code>*list*.extend(*otherlist*)</code>  <code>+</code> ()  list ,  <code>extend</code>  list ,  list , <code>extend</code> </li><li>Python  <code>+=</code>  <code>li += [&#39;two&#39;]</code>  <code>li.extend([&#39;two&#39;])</code> <code>+=</code>  list, , </li><li><code>*</code>  list <code>li = [1, 2] * 3</code>  <code>li = [1, 2] + [1, 2] + [1, 2]</code>,  list </li></ol><hr><p><strong>Tuple</strong></p><ol><li>    Tuplelist.tuple.</li><li>    tuplelist,.</li><li> Tuplelist.Tupleslist0,tuplet[0].</li><li>     list  tuple </li><li>     list  (slice)  list ,  list  tuple ,  tuple</li><li>    Tuple  <code>append</code>  <code>extend</code>  <code>remove</code>  <code>pop</code>  <code>index</code>  <code>in</code>  tuple </li></ol><hr>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(LSTM_TSA)Video Captioning with Transferred Semantic Attributes</title>
      <link href="/2019/03/03/LSTM-TSA-Video-Captioning-with-Transferred-Semantic-Attributes/"/>
      <url>/2019/03/03/LSTM-TSA-Video-Captioning-with-Transferred-Semantic-Attributes/</url>
      
        <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p> Long Short-Term Memory with Transferred Semantic Attributes LSTM-TSAmodelimages  videos transferred semantic attributes   encoder - decoder </p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch-Multi-Gpus</title>
      <link href="/2019/03/02/pytorch-Multi-Gpus/"/>
      <url>/2019/03/02/pytorch-Multi-Gpus/</url>
      
        <content type="html"><![CDATA[<ul><li>pytorch</li><li><a href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html" target="_blank" rel="noopener">website</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters and DataLoaders</span></span><br><span class="line">input_size = <span class="number">5</span></span><br><span class="line">output_size = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">30</span></span><br><span class="line">data_size = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># Our model</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, output_size)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.fc = nn.Linear(input_size, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        output = self.fc(input)</span><br><span class="line">        print(<span class="string">"\tIn Model: input size"</span>, input.size(),</span><br><span class="line">              <span class="string">"output size"</span>, output.size())</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, length)</span>:</span></span><br><span class="line">        self.len = length</span><br><span class="line">        self.data = torch.randn(length, size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.len</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model = Model(input_size, output_size)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>)</span><br><span class="line">    <span class="comment"># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span></span><br><span class="line">    model = nn.DataParallel(model)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br><span class="line">    print(<span class="string">"Outside: input size"</span>, input.size(),</span><br><span class="line">          <span class="string">"output_size"</span>, output.size())</span><br></pre></td></tr></table></figure><h2 id="-PyTorch-pytorchBUG-https-www-cnblogs-com-kk17-p-10139884-html"><a href="#-PyTorch-pytorchBUG-https-www-cnblogs-com-kk17-p-10139884-html" class="headerlink" title="[[PyTorch]pytorchBUG]](https://www.cnblogs.com/kk17/p/10139884.html)"></a>[[PyTorch]pytorchBUG]](<a href="https://www.cnblogs.com/kk17/p/10139884.html" target="_blank" rel="noopener">https://www.cnblogs.com/kk17/p/10139884.html</a>)</h2><ul><li>Multi-GPUs</li></ul><p></p><ul><li><a href="https://www.cnblogs.com/kk17/p/10139884.html#zip-argument-1-must-support-iteration" target="_blank" rel="noopener">1. zip argument #1 must support iteration</a></li><li><a href="https://www.cnblogs.com/kk17/p/10139884.html#torch.nn.dataparallel" target="_blank" rel="noopener">2. torch.nn.DataParallel</a></li><li><a href="https://www.cnblogs.com/kk17/p/10139884.html#model.state_dict" target="_blank" rel="noopener">3. model.state_dict()</a></li></ul><h1 id="1-zip-argument-1-must-support-iteration"><a href="#1-zip-argument-1-must-support-iteration" class="headerlink" title="1. zip argument #1 must support iteration"></a>1. zip argument #1 must support iteration</h1><p>gpubatch_sizen_gpugpu bug </p><h1 id="2-torch-nn-DataParallel"><a href="#2-torch-nn-DataParallel" class="headerlink" title="2. torch.nn.DataParallel"></a>2. torch.nn.DataParallel</h1><p>torch.nn.DataParallelgpuparallel</p><h1 id="3-model-state-dict"><a href="#3-model-state-dict" class="headerlink" title="3. model.state_dict()"></a>3. model.state_dict()</h1><p>modelmodelbug  buggpugpu module. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">pretrained_dict = checkpoint[<span class="string">'state_dict'</span>]</span><br><span class="line">model_dict = self.model.state_dict()</span><br><span class="line"><span class="keyword">if</span> checkpoint[<span class="string">'config'</span>][<span class="string">'n_gpu'</span>] &gt; <span class="number">1</span> <span class="keyword">and</span> self.config[<span class="string">'n_gpu'</span>] == <span class="number">1</span>:</span><br><span class="line">    new_dict = OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items():</span><br><span class="line">        name = k[<span class="number">7</span>:]</span><br><span class="line">        new_dict[name] = v</span><br><span class="line">    pretrained_dict = new_dict</span><br><span class="line"><span class="keyword">elif</span> checkpoint[<span class="string">'config'</span>][<span class="string">'n_gpu'</span>] == <span class="number">1</span> <span class="keyword">and</span> self.config[<span class="string">'n_gpu'</span>] &gt; <span class="number">1</span>:</span><br><span class="line">    new_dict = OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items():</span><br><span class="line">        name = <span class="string">"module."</span>+k</span><br><span class="line">        new_dict[name] = v</span><br><span class="line">    pretrained_dict = new_dict</span><br><span class="line">print(<span class="string">"The pretrained model's para is following"</span>)</span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items():</span><br><span class="line">    print(k)</span><br><span class="line">pretrained_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125;</span><br><span class="line">model_dict.update(pretrained_dict)</span><br><span class="line">self.model.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coco-detection</title>
      <link href="/2019/03/02/coco-detection/"/>
      <url>/2019/03/02/coco-detection/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</title>
      <link href="/2019/03/01/Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning/"/>
      <url>/2019/03/01/Spatio-Temporal-Dynamics-and-Semantic-Attribute-Enriched-Visual-Encoding-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>nltk-tokenize</title>
      <link href="/2019/02/28/nltk-tokenize/"/>
      <url>/2019/02/28/nltk-tokenize/</url>
      
        <content type="html"><![CDATA[<p><a href="https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/" target="_blank" rel="noopener">https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/</a></p><p>Next, youre going to need NLTK 3. The easiest method to installing the NLTK module is going to be with pip.</p><p>For all users, that is done by opening up cmd.exe, bash, or whatever shell you use and typing:<br><code>pip install nltk</code></p><p>These are the words you will most commonly hear upon entering the Natural Language Processing (NLP) space, but there are many more that we will be covering in time. With that, lets show an example of how one might actually tokenize something into tokens with the NLTK module.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from nltk<span class="selector-class">.tokenize</span> import sent_tokenize, word_tokenize</span><br><span class="line"></span><br><span class="line">EXAMPLE_TEXT = <span class="string">"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard."</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(sent_tokenize(EXAMPLE_TEXT)</span></span>)</span><br></pre></td></tr></table></figure><p>At first, you may think tokenizing by things like words or sentences is a rather trivial enterprise. For many sentences it can be. The first step would be likely doing a simple .split(. ), or splitting by period followed by a space. Then maybe you would bring in some <a href="https://pythonprogramming.net/regular-expressions-regex-tutorial-python-3/" target="_blank" rel="noopener"><strong>regular expressions</strong></a> to split by period, space, and then a capital letter. The problem is that things like Mr. Smith would cause you trouble, and many other things. Splitting by word is also a challenge, especially when considering things like concatenations like we and are to were. NLTK is going to go ahead and just save you a ton of time with this seemingly simple, yet very complex, operation.</p><p>The above code will output the sentences, split up into a list of sentences, which you can do things like iterate through with a <a href="https://pythonprogramming.net/loop-python-3-basics-tutorial/" target="_blank" rel="noopener"><strong>for loop</strong></a>.<br><code>[&#39;Hello Mr. Smith, how are you doing today?&#39;, &#39;The weather is great, and Python is awesome.&#39;, &#39;The sky is pinkish-blue.&#39;, &quot;You shouldn&#39;t eat cardboard.&quot;]</code></p><p>So there, we have created tokens, which are sentences. Lets tokenize by word instead this time:</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="name">word_tokenize</span>(<span class="name">EXAMPLE_TEXT</span>))</span><br></pre></td></tr></table></figure><p>Now our output is: <code>[&#39;Hello&#39;, &#39;Mr.&#39;, &#39;Smith&#39;, &#39;,&#39;, &#39;how&#39;, &#39;are&#39;, &#39;you&#39;, &#39;doing&#39;, &#39;today&#39;, &#39;?&#39;, &#39;The&#39;, &#39;weather&#39;, &#39;is&#39;, &#39;great&#39;, &#39;,&#39;, &#39;and&#39;, &#39;Python&#39;, &#39;is&#39;, &#39;awesome&#39;, &#39;.&#39;, &#39;The&#39;, &#39;sky&#39;, &#39;is&#39;, &#39;pinkish-blue&#39;, &#39;.&#39;, &#39;You&#39;, &#39;should&#39;, &quot;n&#39;t&quot;, &#39;eat&#39;, &#39;cardboard&#39;, &#39;.&#39;]</code></p><p>There are a few things to note here. First, notice that punctuation is treated as a separate token. Also, notice the separation of the word shouldnt into should and nt. Finally, notice that pinkish-blue is indeed treated like the one word it was meant to be turned into. Pretty cool!</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Maxout Networks</title>
      <link href="/2019/02/27/Maxout-Networks/"/>
      <url>/2019/02/27/Maxout-Networks/</url>
      
        <content type="html"><![CDATA[<p>2013ICMLmaxoutk(kmaxout)12dropout</p><p>dropoutdropoutdropout</p><p>Dropout</p><ul><li>dropoutMLPCNNdropoutdropoutdropoutSGDdropoutbaggingSGDdropoutdropout</li><li>dropoutdropoutbaggingdropout</li><li>baggingdropout <img src="https://www.zhihu.com/equation?tex=p%28y+%7C+v%3B%CE%B8%29%3Dsoftmax%28v%5E%7BT%7D%2Bb%29" alt="p(y | v;)=softmax(v^{T}+b)">p(y | v;) <img src="https://www.zhihu.com/equation?tex=softmax%28v%5E%7BT%7DW%2F2%2Bb%29" alt="softmax(v^{T}W/2+b)">softmaxMLP</li></ul><p>Maxoutmaxout X=x1,x2,xddMaxout</p><p><img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D%3D%5Cmax_%7Bj+%5Cin+%5B1%2Ck%5D%7D%7Bz_%7Bij%7D%7D" alt="h_{i}=\max_{j \in [1,k]}{z_{ij}}"></p><p>maxoutikmaxoutdropoutp(dropout)maxoutkZ <img src="https://www.zhihu.com/equation?tex=z_%7Bij%7D%3Dx%5E%7BT%7DW_%7B..ij%7D%2Bb_%7Bij%7D" alt="z_{ij}=x^{T}W_{..ij}+b_{ij}"> w(d,m,k)b(m,k)k=1MLP</p><p>MLPii+1n</p><p>1MLP<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0ldm6b5ujj30ix08mdg0.jpg"></p><p> f SigmodReluTanh</p><p>(2)Maxout maxoutk=5maxout<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0ldmxgg2zj30n60e33zh.jpg"></p><p>5<br>maxoutkmaxoutk</p><ul><li>MLP255<strong></strong><code>maxout</code><code>relu</code><code>relu</code>max(x,0)0<code>maxout</code>520<code>maxout</code>20545max pooling stride5202201202054</li><li>CNN24255affine feature maps5pool across channels<strong></strong><code>relu</code>max(x,0)0<code>maxout</code>5520<code>maxout</code>205452020233120112054<strong></strong> CNNmaxoutmaxout</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ol><li>MNIST</li></ol><p>MNISTMNIST with permutation invariant2maxoutsoftmaxdropout1000050000L60000<strong></strong>L<em>0.94%</em></p><p>MNISTMNIST without permutation invariant3maxoutsoftmax<em>0.45%</em></p><p>\2. CIFAR-10</p><p>ZCA</p><p>MNIST<strong></strong></p><p>maxoutmaxoutsoftmax<em>13.2%</em><em>11.68%</em><em>9.35%</em></p><p>\3. CIFAR-100</p><p>CIFAR-10</p><p><em>41.48%</em><em>38.57%</em></p><p>\4. SVHN</p><p>400200</p><p></p><p>maxoutmaxoutsoftmaxCIFAR-10<em>2.47%</em></p><h2 id="maxoutrelu"><a href="#maxoutrelu" class="headerlink" title="maxoutrelu"></a>maxoutrelu</h2><ul><li></li><li>maxoutrelurelu</li><li>relumaxoutmaxoutkkrelukmaxoutk</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li>softmaxdropout</li><li>dropoutmaxoutmaxoutdropout maskdropoutmaxoutdropout maskmaxout</li><li>maxoutdropoutdropout</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li>dropoutmaxoutrelu+max pooling</li><li>dropoutSGDdropoutSGD</li><li>SGDrelu05%dropout60%relu0maxoutmaxoutmaxout00maxout0</li><li>dropoutdropout maskdropout maskdropoutSGDrelumaxoutdropoutbaggingreludropoutSGD</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul><li><code>maxout</code>kk</li><li>MLPmaxout<code>maxout</code>maxout</li><li>maxout</li><li>maxoutdropout</li><li>maxout</li><li>dropoutdropout<code>max</code>dropout</li><li>maxout</li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python: yield </title>
      <link href="/2019/02/25/Python-%E7%90%86%E8%A7%A3-yield-%E5%85%B3%E9%94%AE%E5%AD%97/"/>
      <url>/2019/02/25/Python-%E7%90%86%E8%A7%A3-yield-%E5%85%B3%E9%94%AE%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<pre><code>https://liam.page/2017/06/30/understanding-yield-in-python/</code></pre><h1 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h1><p><a href="https://github.com/sususushi/reconstruction-network-for-video-captioning" target="_blank" rel="noopener">reconstruction-network</a> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cycle</span><span class="params">(iterable)</span>:</span>  </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> iterable:  </span><br><span class="line">            <span class="keyword">yield</span> x</span><br><span class="line"></span><br><span class="line">train_data_loader = iter(cycle(MSVD.train_data_loader))</span><br><span class="line"><span class="keyword">for</span> iteration, batch <span class="keyword">in</span> enumerate(train_data_loader, <span class="number">1</span>):</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> iteration == C.train_n_iteration:  </span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p><strong>iter()</strong> pythoncycleforwhile truen_epoch train_n_iteration</p><hr><p>Python  <code>yield</code> </p><p> <code>yield</code> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="iterationiterable"><a href="#iterationiterable" class="headerlink" title="iterationiterable"></a>iterationiterable</h3><blockquote><p></p></blockquote><p><strong></strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># iteration</span></span><br><span class="line">a_list = [1, 2, 3]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a_list:</span><br><span class="line">    <span class="builtin-name">print</span>(i)</span><br></pre></td></tr></table></figure><p></p><p>Python <code>list</code>, <code>tuple</code>, <code>string</code> <code>dict</code>, <code>set</code>, <code>file</code>  <code>__iter__()</code>  <code>__getitem__()</code> </p><h3 id="iterator"><a href="#iterator" class="headerlink" title="iterator"></a>iterator</h3><blockquote><p></p></blockquote><p> <code>next()</code>  <code>next()</code>  <code>StopIteration</code>  <code>__iter__()</code> </p><h3 id="iterator-protocol"><a href="#iterator-protocol" class="headerlink" title="iterator protocol"></a>iterator protocol</h3><blockquote><p></p></blockquote><p> <code>__iter__()</code> </p><p>Python  Python  <code>for</code> </p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">iterator</span> protocol <span class="keyword">and</span> <span class="keyword">for</span> <span class="keyword">loop</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> something:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><p>Python  <code>for</code>  <code>iter(something)</code> <code>something.__iter__()</code> <code>something</code> <code>for</code>  <code>next()</code> <code>x</code>Python </p><h2 id="yield-"><a href="#yield-" class="headerlink" title="yield "></a><code>yield</code> </h2><h3 id="generator-functiongenerator"><a href="#generator-functiongenerator" class="headerlink" title="generator functiongenerator"></a>generator functiongenerator</h3><blockquote><p></p></blockquote><p> <code>yield</code> </p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def <span class="built_in">func</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">def <span class="built_in">gen</span>():</span><br><span class="line">    yield <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span>(<span class="built_in">type</span>(func))   <span class="meta"># &lt;class 'function'&gt;</span></span><br><span class="line"><span class="keyword">print</span>(<span class="built_in">type</span>(gen))    <span class="meta"># &lt;class 'function'&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span>(<span class="built_in">type</span>(<span class="built_in">func</span>())) <span class="meta"># &lt;class 'int'&gt;</span></span><br><span class="line"><span class="keyword">print</span>(<span class="built_in">type</span>(<span class="built_in">gen</span>()))  <span class="meta"># &lt;class 'generator'&gt;</span></span><br></pre></td></tr></table></figure><p> <code>gen</code>  <code>return</code>  <code>yield</code> <code>type()</code> <code>func</code>  <code>gen</code> <code>func()</code>  <code>int</code>  <code>gen()</code> </p><h3 id="yield-"><a href="#yield-" class="headerlink" title="yield "></a><code>yield</code> </h3><p> <code>yield</code> <code>yield</code> </p><p>generator-iterator</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">yield</span> x ** <span class="number">2</span></span><br><span class="line">square_gen = square()</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> square_gen:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><p><code>for</code>  <code>iter()</code>  <code>next()</code>  <code>x</code> <code>for</code> </p><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">genitor = square_gen.__iter__()</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    x = geniter.<span class="keyword">next</span>()<span class="meta"> # Python 3  __next__()</span></span><br><span class="line">    <span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><p><code>square</code> <code>square_gen</code>  <code>__iter__()</code>  <code>geniter</code>  <code>square</code></p><p> <code>x = geniter.next()</code> <code>square</code>  <code>yield</code>  <code>yield</code> <strong></strong></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p> <code>ValueError</code> </p><ul><li><code>generator.next()</code> <code>yield</code>  <code>yield</code>  <code>yield</code>  <code>None</code> <code>yield</code>  <code>yield</code>  <code>StopIterator</code> </li><li><code>generator.send(value)</code> <code>generator.next()</code>  <code>yield</code>  <code>value</code></li><li><code>generator.throw(type[, value[, traceback]])</code> <code>type</code>  <code>value</code>  <code>traceback</code>  <code>yield</code>  <code>generator.next()</code> </li><li><code>generator.close()</code></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><p></p><ul><li> <code>result = list()</code></li><li> <code>yield</code>  <code>yield expr</code>  <code>result.append(expr)</code></li><li> <code>return result</code></li></ul><h4 id="yield-"><a href="#yield-" class="headerlink" title="yield "></a><code>yield</code> </h4><p> <code>generator.next()</code>  <code>yield</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f123</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> f123(): <span class="comment"># 1, 2, and 3, will be printed</span></span><br><span class="line">    print(item)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f13</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">False</span>:</span><br><span class="line">        <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> f13(): <span class="comment"># 1 and 3, will be printed</span></span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure><h4 id="-send-"><a href="#-send-" class="headerlink" title=" send() "></a> <code>send()</code> </h4><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def <span class="function"><span class="keyword">func</span><span class="params">()</span>:</span></span><br><span class="line">    x = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        y = (yield x)</span><br><span class="line">        x += y</span><br><span class="line"></span><br><span class="line">geniter = <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line">geniter.<span class="keyword">next</span>()  <span class="meta"># 1</span></span><br><span class="line">geniter.<span class="built_in">send</span>(<span class="number">3</span>) <span class="meta"># 4</span></span><br><span class="line">geniter.<span class="built_in">send</span>(<span class="number">10</span>)<span class="meta"># 14</span></span><br></pre></td></tr></table></figure><p> <code>func</code>  <code>yield</code>  <code>x</code>  <code>send</code>  <code>yield</code>  <code>y</code> </p><p> <code>yield</code>  Python </p><h2 id="yield-"><a href="#yield-" class="headerlink" title="yield "></a><code>yield</code> </h2><p>Python  Python 2  <code>range</code>  <code>xrange</code><code>range</code>  <code>xrange</code> </p><blockquote><p> Python 3 <code>range</code>  Python 2  <code>xrange</code> Python 2  <code>range</code>  <code>list(range())</code> </p></blockquote><p>Python  5 </p><ul><li> 5 </li><li> 5 </li></ul><p> <code>10 ** 8</code> </p><p> <code>yield</code> </p><p>  10% </p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Video captioning summary</title>
      <link href="/2019/02/23/Video-captioning-summary/"/>
      <url>/2019/02/23/Video-captioning-summary/</url>
      
        <content type="html"><![CDATA[<ul><li>encodermodelC3DC3D,16n_frames/16 video <br>## </li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>The training process predicts the next word given the previous words from groundtruth, while the generation process conditions the prediction on the ones previously generated by itself.  </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0iyn2xsz9j30r00higpg.jpg" style="zoom:70%"><h2 id="Code-"><a href="#Code-" class="headerlink" title="Code "></a>Code </h2><table><thead><tr><th>model</th><th>batch_size</th><th>epoch</th><th>learning_rate</th><th>MSVD<br>train-dataset</th><th>MSR-train-dataset</th></tr></thead><tbody><tr><td>video-caption.pytorch</td><td>128</td><td>6001MSR</td><td>0.0004 (200epoch0.8)</td><td></td><td>6513 pairs<br>(captionslabel)</td></tr><tr><td>SA-tensorflow</td><td>100</td><td>200</td><td>0.0001</td><td>120041pairs</td><td></td></tr><tr><td>reconstruction-network</td><td>100</td><td>iter=100000  epoch=100000100/(1200*41=203</td><td>0.00001</td><td>120041pairs</td><td></td></tr><tr><td>saliency-based</td><td>100</td><td>100</td><td>0.0003</td><td></td><td></td></tr><tr><td>HRNE</td><td>200</td><td>128</td><td>0.0002</td><td></td><td></td></tr></tbody></table><table><thead><tr><th>model</th><th>construct vocab use which dataset</th></tr></thead><tbody><tr><td>video-caption.pytorch</td><td>MSR: all</td></tr><tr><td>SA-tensorflow</td><td>MSVD: train</td></tr><tr><td>reconstruction-network</td><td>MSVD: all</td></tr><tr><td>saliency-based</td><td></td></tr><tr><td>HRNE</td><td></td></tr></tbody></table><table><thead><tr><th>model</th><th>loss function</th><th>input of decoder</th></tr></thead><tbody><tr><td>video-caption.pytorch</td><td>output of decoderbs, hidden size,one-hot(bs, n_vocabF.log_softmax nn.NLLLoss</td><td>rnn1video feature;<br>rnn2rnn1cancatenate ground truthword embedding<br> output1, state1 = self.rnn1(vid_feats, state1)<br> input2 = torch.cat((output1, padding_words), dim=2)<br>          output2, state2 = self.rnn2(input2, state2)</td></tr><tr><td>SA-tensorflow</td><td><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0izmumz8sj30ry01l74i.jpg">LSTMoutput/hidden stateattentionvideofeaturestepgroundtruth word embeddingconcatenatetf.nn.softmax_cross_entropy_with_logits</td><td>LSTMconcatenate(video_feature, ground truthword embdedding</td></tr><tr><td>reconstruction-network</td><td>output of decoderbs, hidden size,one-hot(bs, n_vocabdropout   nn.CrossEntropyLoss()</td><td>LSTMconcatenate(video_feature, ground truthword embdedding</td></tr></tbody></table><hr><h2 id="Paper-"><a href="#Paper-" class="headerlink" title="Paper "></a>Paper </h2><table><thead><tr><th>model</th><th>dataset</th><th>n_frames</th></tr></thead><tbody><tr><td>S2VT</td><td>MSVD</td><td>101</td></tr><tr><td>SA</td><td>MSVD</td><td>24026</td></tr><tr><td>h-RNN</td><td>MSVD</td><td>(  )</td></tr><tr><td>HRNE</td><td>MSVD</td><td>fixed 160</td></tr><tr><td>LSTM-TSA</td><td>MSVD</td><td>25</td></tr><tr><td>LSTM-E</td><td>MSVD</td><td>all frames</td></tr><tr><td>Reconstruction</td><td>MSVD  MSR-VTT</td><td>28</td></tr><tr><td>M3</td><td>MSVD  MSR-VTT</td><td>28for MSVD; 40for MSR-VTT</td></tr></tbody></table><table><thead><tr><th>model</th><th></th><th>MSVD  vocabulary</th><th>MSR-VTT  vocabulary</th></tr></thead><tbody><tr><td>Hierarchical Boundary-Aware Neural Encoder for Video Captioning</td><td>5</td><td>4215</td><td></td></tr><tr><td>Multimodal Memory Modelling for Video Captioning</td><td></td><td>13,000</td><td>29,000</td></tr><tr><td>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</td><td></td><td>9450</td><td>23500</td></tr><tr><td>Describing Videos by Exploiting Temporal Structure</td><td></td><td>16,000</td><td></td></tr><tr><td>Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks</td><td></td><td>12, 7661, 297 and 670 videos </td><td></td></tr></tbody></table><table><thead><tr><th>model</th><th>feature</th><th>METER</th></tr></thead><tbody><tr><td>Mean Pool + LSTM</td><td>COCOAlex net</td><td>29.1</td></tr><tr><td>S2VT</td><td>RGB frames on VGG Net<br>optical flows on AlexNet</td><td>29.8</td></tr><tr><td>SA</td><td>GoogLeNet and 3D-CNN</td><td>29.6</td></tr><tr><td>LSTM-E</td><td>VGGNet and C3D</td><td>31.0</td></tr><tr><td>h-RNN</td><td>VGGNet and C3D</td><td>32.6</td></tr><tr><td>HRNE</td><td>GooLeNet</td><td>33.1</td></tr><tr><td>Reconstruction</td><td>Inception-V4<br> last pooling layer</td><td>34.1</td></tr></tbody></table><h2 id="frames-features-video-feature"><a href="#frames-features-video-feature" class="headerlink" title="frames features video feature"></a>frames features video feature</h2><p><strong>1. Mean pooling</strong></p><ul><li>Translating videos to natural language using deep recurrent neural networks. NACACL, 2015</li><li>Jointly modeling embedding and translation to bridge video and language. CoRR,  2015  </li></ul><p><strong>2. Weighted mean Pooling with an attention model</strong>    </p><ul><li>Describing videos by exploiting temporal structure. ICCV, 2015  </li><li>Exploring Visual Relationship for Image Captioning</li><li>2LSTMLSTMobject/frames featuresLSTMhidden state attention object/frames features  global feture global feature</li></ul><p><strong>3. Taking the last output from an RNN encoder which summarizes the feature sequence</strong>    </p><ul><li>Long-term recurrent convolutional networks for visual recognition and description. CVPR, 2015</li><li>Sequence to sequence - video to tex. ICCV, 2015</li><li>A multi-scale multiple instance video description network. CoRR, 2015  </li></ul><h2 id="video-captioning-extract-object-proposal"><a href="#video-captioning-extract-object-proposal" class="headerlink" title="video captioning extract object proposal"></a>video captioning extract object proposal</h2><ul><li>Video paragraph captioning using hierarchical recurrent neural networks.  CVPR, 2016.  </li><li>object-aware aggregation with bidirectional temporal graph for video capioning. CVPR, 2019</li></ul><h2 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h2><ul><li>decoderloss, encodermodelfinetune</li></ul><h2 id="objects-feature-"><a href="#objects-feature-" class="headerlink" title="objects feature "></a>objects feature </h2><ul><li></li><li>video as graph : charades 50objects(objects 25score0.2), something2 :10objects</li><li>msr-vtt: 5</li><li>==videoobjects objects==  </li></ul><table><thead><tr><th></th><th>charades( 30s)</th><th></th><th>something-something( 3-6s )</th><th>activity</th><th>MSVD10-25s</th></tr></thead><tbody><tr><td>video as graph</td><td>16 *50</td><td></td><td>16* 10</td><td>10*100</td><td></td></tr><tr><td>HTM video captioning)</td><td>80 *30</td><td></td><td></td><td></td><td>28*30</td></tr></tbody></table><table><thead><tr><th></th><th>object detector</th><th>return</th></tr></thead><tbody><tr><td>(ACM 2019)Hierarchical Global-Local Temporal Modeling for VideoCaptioning</td><td>Faster rcnn rcnn</td><td>_head_to_tail 2048</td></tr><tr><td>(CVPR 2019)Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</td><td>YoLo</td><td></td></tr><tr><td>(CVPR 2019)Grounded Video Description</td><td>a Faster RCNN model [24] with a ResNeXt-101 FPN backbone (VGcoco )</td><td>fc6,_head_to_tail</td></tr><tr><td>( ECCV 2018)Videos as Space-Time Region Graph</td><td>the RPN with ResNet-50 backbone and FPN ==(I3DTHWd322116bboxbboxpooled_featsI3Dbbox, Roi Alignbbox  region feat) ==</td><td>roi_pooling7*7</td></tr><tr><td>(CVPR 2019)Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning</td><td>MASK RCNNCOCO</td><td>regions ResNet-200res-layer5c</td></tr><tr><td>CVPR 2019Auto-Encoding Scene Graphs for Image Captioning</td><td>faster rcnn ,  r-cnn  rois  base feat roi pooling  pooled feats</td><td> 7*7pooled feats</td></tr></tbody></table><ul><li>faster r-cnn rpnbboxrcnnbboxrcnn</li><li> object rpnbbox,  why bboxbbox feats pooled_feats</li><li>mmdetection rpnmax_region_per</li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(h-RNN)Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks</title>
      <link href="/2019/02/23/h-RNN-Video-Paragraph-Captioning-Using-Hierarchical-Recurrent-Neural-Networks/"/>
      <url>/2019/02/23/h-RNN-Video-Paragraph-Captioning-Using-Hierarchical-Recurrent-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><ul><li>video intervalcaption<strong></strong></li><li>MSVDvideosentence<strong>decodermodel</strong>video feature decoder  RNNRNNhidden state MultimodalMultimodal( concatenate( hidden statevideo feature ) )</li></ul><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p><strong>RNN</strong><strong><em></em></strong><strong><em></em></strong>parahraph state ~ </p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><strong></strong><br>(vggnet c3d)<br>1[1, 2]<br>2attention [3]<br>3RNN encoder [4, 5, 6]<br> video feature  short video clips where there is only one major event recurrent encoder  attention model<br>attention 1. <strong></strong>frames object proposals proposal features of one frames frames features object <strong></strong>features of frames  video feature <strong></strong>MKobject, M*K object attention 2.  </li><li><strong>Motivation</strong><br>video <strong></strong>one sentence<strong></strong></li><li><strong>Idea</strong><br><br>RNNRNN layers<br>RNN  </li></ul><h2 id="Hierarchical-RNN-for-Video-Captioning"><a href="#Hierarchical-RNN-for-Video-Captioning" class="headerlink" title="Hierarchical RNN for Video Captioning"></a>Hierarchical RNN for Video Captioning</h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0gmi1zayjj314o0h2n1f.jpg">***designed by yaya:***<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0k7r1p5ygj316f0jyq47.jpg">****1) RNN  2)  3) <ul><li>RNN1word embedding RNN hidden state </li><li>Attention layer: RNN hidden state attention layer weight:   <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0gohii8woj30xx02saab.jpg" style="zoom:30%"><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0gom9zybsj30kg04mwes.jpg" style="zoom:45%">MKobjectsfeatures  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0go2kemkqj30bq01pt8m.jpg" style="zoom:50%">:  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0go382u2qj309m0250so.jpg" style="zoom:50%"> video feature  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0go5n8g7dj30if036mx8.jpg" style="zoom:30%">video feature object appearance action </li><li>Multimodal<br>RNN hidden state <strong>concate</strong> 2Attention Ua  C3Daction featureUo aggregate object appearance<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0gpaasqgmj30sb022dg0.jpg" style="zoom:50%"></li><li>Hidden layer<br>-512  word embdeding </li><li>Softmax layer<br>vocabulary size </li><li>Maxid layer<br>Maxid layer softmax layer predicted word id(vocabulary  )</li><li>testground truth/ reference</li></ul><p><strong></strong> : RNN1. 2. paragraph history  <br>RNNGRU</p><ul><li>Word Embedding<br>1) sentencesembedding embedding vector<br>2) RNN1 hidden state  <br>concatenated </li><li>Sentences Embedding<br>concatenated 512</li><li>RNN2</li><li>Paragraph State layer<br>RNN2hidden state  sentence embedding<br>RNN1<br></li></ul><h2 id="Training-and-Generation"><a href="#Training-and-Generation" class="headerlink" title="Training and Generation"></a>Training and Generation</h2><p><strong></strong></p><ul><li>RNN1hidden stateRNN2hidden state</li><li>RNN1 beam search  J sequence cost 1RNN2RNN2RNN1 when the sentence received by the paragraph generator is the EOP (end-of-paragraph) which consists of only the BOS and the EOS</li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p><strong></strong><br>two benchmark datasets: YouTubeClips and TACoS-MultiLevel<br>YouTubeClips video sentencessentencesvideovideoparagraph length N=1.<br><strong>Encoder</strong></p><ul><li>YouTubeClipsobject objectframe attention temporal attention  spatial attention</li><li>TACoS-MultiLevel boundinig boxbounding box 220*220image patchesbox 50%VGGpatchattentionpatchesattentiontemporal  spatial</li><li>C3D  action/motion feature of video<br>C3D frames of video 16attentionC3Dpolling<br><strong></strong></li><li>YouTubeClips  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0hdv8rde9j30i7099jtg.jpg">   **LSTM-E[2]**VGGC3D**SA[3]**temporal attentionRNN hidden statevideo featurevideo featuremultimodal layer</li><li>TACoS-MultiLevel<br></li></ul><h2 id="Discussions-and-Limitations"><a href="#Discussions-and-Limitations" class="headerlink" title="Discussions and Limitations"></a>Discussions and Limitations</h2><ol><li>small objectorange mango</li><li>RNNyaya: sorry , i dont kow whats meanBiRNNRNN</li><li>/groundtruthgroundtruth</li></ol><ul><li>Scheduled Sampling<br>Scheduled Samplingwords of groundtruthmodel</li><li>metric(BLEU CIDER, etc)</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <strong><em>Translating videos to natural language using deep recurrent neural networks</em></strong>. NACACL, 2015<br>[2] <strong><em>Jointly modeling embedding and translation to bridge video and language</em></strong>. CoRR,  2015<br>[3] <strong><em>Describing videos by exploiting temporal structure</em></strong>. ICCV, 2015<br>[4] <strong><em>Long-term recurrent convolutional networks for visual recognition and description</em></strong>. CVPR, 2015<br>[5] <strong><em>Sequence to sequence - video to text</em></strong>. ICCV, 2015<br>[6]  <strong><em>A multi-scale multiple instance video description network</em></strong>. CoRR, 2015</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hierarchical Boundary-Aware Neural Encoder for Video Captioning</title>
      <link href="/2019/02/22/Hierarchical-Boundary-Aware-Neural-Encoder-for-Video-Captioning/"/>
      <url>/2019/02/22/Hierarchical-Boundary-Aware-Neural-Encoder-for-Video-Captioning/</url>
      
        <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0g5c5cwmxj30l00mh45o.jpg">  In this paper, we focus on the video encoding stage. we propose a recurrent network which can learn to adapt its temporal structure to input data.Our network is the first proposal which exploits temporal segments invideo captioningLSTM /Encoder Model---------<img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0g57reyepj316c0m7k74.jpg">   - **traditional lstm network**LSTMvideo featureframes time step LSTMLSTM cell hidden state video feature  - **Time Boundary-aware LSTM network** ***(ours)***figure1  figure2 BDboundary detection an appearance or action changeBD**LSTM**LSTMhidden state and the cell memory all frames of video  (s1; s2; ...; sm), msegmentsLSTMLSTMLSTMhidden state figure1Decoder model-------------A Gated Recurrent Unit (GRU) layer]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>video-caption-dataset</title>
      <link href="/2019/02/22/video-caption-dataset/"/>
      <url>/2019/02/22/video-caption-dataset/</url>
      
        <content type="html"><![CDATA[<h2 id="Youtube2Text-MSVD-1"><a href="#Youtube2Text-MSVD-1" class="headerlink" title="Youtube2Text MSVD[1]"></a>Youtube2Text MSVD[1]</h2><ul><li> 196710-25s9s</li><li>41 annotated sentences per clip 80839 sentences8words16000 unique words</li><li>captionlaguage = english caption [3][4]</li><li>split [2]  1,200 videos for training, 100 for validation and 670 for testing.<br><a href="https://github.com/ShiYaya/video_captioning/tree/master/MSVD" target="_blank" rel="noopener"></a></li></ul><ul><li></li><li><a href="https://www.microsoft.com/en-us/download/details.aspx?spm=a2c4e.11153940.blogcont209612.6.42ba7e9eAA1K2o&id=52422&from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2F38cf15fd-b8df-477e-a4e4-a4680caa75af%2Fdefault.aspx" target="_blank" rel="noopener">[website]</a></li><li>video_id,strart and end time , videourl</li><li><a href="https://github.com/sinyeratlantis/sinyeratlantis.github.io/blob/master/content/dl/%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E6%96%87%E7%8C%AE%E8%B0%83%E7%A0%94.md" target="_blank" rel="noopener">MSVD</a>(video)<br><br><a href="http://www.cs.utexas.edu/users/ml/clamp/videoDescription/YouTubeClips.tar" target="_blank" rel="noopener"></a><strong>[]</strong></li><li>github MSVD(Youtube2Text)<a href="https://github.com/yaoli/arctic-capgen-vid" target="_blank" rel="noopener">[preproceed dataset]</a><br><br><a href="http://lisaweb.iro.umontreal.ca/transfert/lisa/users/yaoli/youtube2text_iccv15.zip" target="_blank" rel="noopener"></a>()</li><li>github<a href="https://github.com/ShiYaya/Video-Description-with-Spatial-Temporal-Attention#video-datas-and-pre-extracted-features-on-msvd-dataset" target="_blank" rel="noopener">MSVD</a><br><br><a href="https://www.multcloud.com/share/050e69cd-cab9-4ba3-a671-ed459341ab41" target="_blank" rel="noopener"></a></li><li>caption : 1) verting all text to lower case, 2) tokenizing the sentences, 3) removing punctuation.</li></ul><h2 id="MSR-VTT-dataset"><a href="#MSR-VTT-dataset" class="headerlink" title="MSR-VTT dataset"></a>MSR-VTT dataset</h2><p> 10000video, video20sentences, 20 video/sentence pair10-30s</p><ul><li>split:  train:6513, val:497, test2990</li><li>MSR-VTT dataset v2 , just video url: <a href="http://ms-multimedia-challenge.com/2017/dataset" target="_blank" rel="noopener">http://ms-multimedia-challenge.com/2017/dataset</a></li><li>author split train test val by himself and provied video data :<a href="https://github.com/xiadingZ/video-caption.pytorch" target="_blank" rel="noopener">https://github.com/xiadingZ/video-caption.pytorch</a>  <br></li></ul><p><strong>split!</strong><br></p><ul><li>MSR VTT split 2016<strong>2016</strong></li><li><a href="https://github.com/adi-dhal/In_Depth_Video_Analysis/tree/master/msr-vtt/2016" target="_blank" rel="noopener">[split]</a><br>MSR-VTT. Test video doesnt have captions, so I spilit train-viedo to train/val/test. Extract and put them in <code>./data/</code> directory</li></ul><p>train-video: <a href="https://drive.google.com/file/d/1Qi6Gn_l93SzrvmKQQu-drI90L-x8B0ly/view?usp=sharing" target="_blank" rel="noopener">download link</a> <br><br>test-video: <a href="https://drive.google.com/file/d/10fPbEhD-ENVQihrRvKFvxcMzkDlhvf4Q/view?usp=sharing" target="_blank" rel="noopener">download link</a> <br><br>json info of train-video: <a href="https://drive.google.com/file/d/1LcTtsAvfnHhUfHMiI4YkDgN7lF1-_-m7/view?usp=sharing" target="_blank" rel="noopener">download link</a> <br><br>json info of test-video: <a href="https://drive.google.com/file/d/1Kgra0uMKDQssclNZXRLfbj9UQgBv-1YE/view?usp=sharing" target="_blank" rel="noopener">download link</a> <br></p><ul><li><p>download.py MSR-VTT(step by video)<a href="https://github.com/OSUPCVLab/VideoToTextDNN" target="_blank" rel="noopener">[]</a></p></li><li><p>msr-vtt 2017 vs 2016<br>In the 2nd MSR Video to Language Challenge, we have combined the training set, validation set, and testing data in the 1st MSR Video to Language Challenge as the new training data. An additional test set of around 3K video clips will be released on June 1st as the final evaluation set. As such, we have 10K video clips for training and 3K video clips for testing this year. Each video is annotated with 20 natural sentences.<br><br>2016train val and test 2017 10000videotrain 2000test video<br><br>2016</p></li></ul><ul><li>In MSR-VTT dataset, we provide the category information for each video clip and the video clip contains audio information as well.</li></ul><h2 id="VATEX"><a href="#VATEX" class="headerlink" title="VATEX"></a>VATEX</h2><ul><li><p>41269video 10s, video1010105</p></li><li><p>1encoder-decoder2</p></li><li><p>kineticsvalidation dataset, caption41269video 4train, validation, public test, secret test()</p></li><li><p></p></li></ul><h2 id="caption-length-"><a href="#caption-length-" class="headerlink" title="caption length "></a>caption length </h2><ul><li>eg, 10 captions    </li><li>msvd : len=6 <br><img src="https://i.loli.net/2019/09/07/jJ7ztsQb9MUR15X.png" alt="msvd_cap_length_.png"></li><li>msr-vttlen=9 <br><img src="https://i.loli.net/2019/09/07/SNYoIqHxPLWmU9D.png" alt="msr-vtt_cap_length_.png"></li><li>vatexlen=15<br><img src="https://i.loli.net/2019/09/07/he7KYqMt8xj5pUs.png" alt="vatex_cap_length_.png"></li></ul><p>[1] Youtube2text: Recognizing and describing arbitrary activities using semantic hierarchies and zero-shot recognition. In ICCV 2013</p><p>[2] Translating videos to natural language using deep recurrent neural networks. NAACL, 2015.<br>[3] (ICCV 2015)Sequence to Sequence  Video to Text<br>[4] Jointly Modeling Embedding and Translation to Bridge Video and Language</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown</title>
      <link href="/2019/02/22/Markdown%E7%94%A8%E6%B3%95/"/>
      <url>/2019/02/22/Markdown%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<ul><li><p><br><a href="https://www.kancloud.cn/wizardforcel/markdown-simple-world/97375" target="_blank" rel="noopener">https://www.kancloud.cn/wizardforcel/markdown-simple-world/97375</a></p></li><li><p><br><a href="https://stackedit.io/editor" target="_blank" rel="noopener">https://stackedit.io/editor</a></p></li><li><p><br>shift+space space</p></li></ul>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(LSTM-E)Jointly Modeling Embedding and Translation to Bridge Video and Language</title>
      <link href="/2019/02/22/LSTM-E-Jointly-Modeling-Embedding-and-Translation-to-Bridge-Video-and-Language/"/>
      <url>/2019/02/22/LSTM-E-Jointly-Modeling-Embedding-and-Translation-to-Bridge-Video-and-Language/</url>
      
        <content type="html"><![CDATA[<h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><p></p><ol><li>action feature of C3D and frames featuresC3Dmean poolingaction </li><li>relevance loss    </li></ol><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>words<br> figure1LSTM model a man is riding a horsewoman man<br><br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0f0qr6d2ij30lq0biq8s.jpg" width="500" hegiht="313" align="center"></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>  LSTM-ELSTM-ELSTM-embeddingLSTM -embedding<br>  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0f87gorc9j316d0kr11m.jpg" title="overview">  </p><ul><li><strong>Overview</strong><br>2D/3D frames/clips<br><strong><em>v</em></strong><strong><em>s</em></strong>sentences<strong>LSTM model</strong> <strong>-embeddeing model</strong> </li><li><strong>The sprit of LSTM-E</strong><br>coherencerelevancesentences<strong><em>coherence:</em></strong>wordsLSTM<strong><em>relevance:</em></strong>-embeddeing modelcoherencerelevance</li><li><strong></strong><br>modelsequence learning coherence loss next wordrelevance lossvideo</li><li><strong>contribution</strong><br>relevance loss !  </li></ul><h2 id="Video-Description-with-Relevance-and-Coherence"><a href="#Video-Description-with-Relevance-and-Coherence" class="headerlink" title="Video Description with Relevance and Coherence"></a>Video Description with Relevance and Coherence</h2><ul><li><strong>Visual-Semantic Embedding: Relevance</strong><br><strong><em>v</em></strong>  <strong><em>s</em></strong> sentencesTsTvembeddingrelevance loss:<br><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0f8zoni8tj30bc01pmx2.jpg" style="zoom:45%"></li><li><strong>Translation by Sequence Learning: Coherence</strong><br>coherence losssentences  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0f9l8bbvoj30ph02pglq.jpg" style="zoom:50%">  overviewLSTMLSTMtime step traincaptionttesttime step   <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0f9lgy6nfj317806fgm5.jpg" style="zoom:40%"></li></ul><h2 id="Joint-Modeling-Embedding-and-Translation"><a href="#Joint-Modeling-Embedding-and-Translation" class="headerlink" title="Joint Modeling Embedding and Translation"></a>Joint Modeling Embedding and Translation</h2><ul><li><p><strong>simultaneously minimizing the relevance loss and coherence loss.</strong>  </p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0fa1y3nkgj30nu05pq3p.jpg" style="zoom:70%"></li><li><p>*<em>LSTM *</em><br>visual content  word of last time stepeach time step [ 1 ] v  sentence W  [w0, w1, , wNs]LSTM  </p><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0fcc8tiqej30z708l0t3.jpg">  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0faic2fuzj30n508njs2.jpg" style="width: 50%; height: 50%">  LSTM<#start#>LSTMhidden state, cell stateword <#end#>LSTM cell hidden state  word( LSTM output  hidden[0] [https://mp.csdn.net/postedit/87516958](https://mp.csdn.net/postedit/87516958))<blockquote><p><code>output, hidden = self.rnn(input, hidden)</code></p></blockquote></#end#></#start#></li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ul><li><strong>dataset</strong><br>MSVD:<br>Microsoft Research Video Description Corpus (YouTube2Text) , which contains 1,970 YouTube snippets. There are roughly 40 available English descriptions per video. In our experiments, we follow the setting used in prior works, taking 1,200 videos for training, 100 for validation and 670 for testing.</li><li><strong>result</strong><img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0fcs7kt8cj31ap0bhgow.jpg"></li><li><strong>The effect of hidden layer size</strong>  <img src="http://ww1.sinaimg.cn/large/006uWRWVly1g0fcvqbzvsj30qz09x760.jpg" style="width: 70%; height: 70%">  </li></ul><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>a visual-semantic embedding space is additionally incorporated into LSTM learning. In this way, <strong>a global relationship between the video content and sentence semantics</strong> is simultaneously measured in addition to <strong>the local contextual relationship between the word at each step and the previous ones</strong> in LSTM learning. On the popular YouTube2Text dataset, the results of our experiments demonstrate the success of our approach, outperforming the current state-ofthe-art models </p><h2 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h2><p>RNNvideo sentences pairs RNN</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and tell: A neural image caption generator. In CVPR, 2015.</p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag>  </tag>
            
            <tag>  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GitHub+Hexo </title>
      <link href="/2019/02/21/GitHub-Hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/"/>
      <url>/2019/02/21/GitHub-Hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26625249</a></p><p><a href="https://blog.csdn.net/xuezhisdc/article/details/53130328" target="_blank" rel="noopener">https://blog.csdn.net/xuezhisdc/article/details/53130328</a></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><ol><li><p> hexo-generator-searchdb</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm <span class="keyword">install</span> hexo-generator-searchdb <span class="comment">--save</span></span><br></pre></td></tr></table></figure></li><li><p></p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">search:</span></span><br><span class="line"><span class="symbol">      path:</span> search.xml</span><br><span class="line"><span class="symbol">      field:</span> post</span><br><span class="line"><span class="symbol">      format:</span> html</span><br><span class="line"><span class="symbol">      limit:</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure></li><li><p></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Local search</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ol><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p><a href="https://www.jianshu.com/p/44e211829447" target="_blank" rel="noopener">https://www.jianshu.com/p/44e211829447</a></p><p><a href="http://npm.taobao.org/package/hexo-blog-encrypt" target="_blank" rel="noopener">http://npm.taobao.org/package/hexo-blog-encrypt</a></p><p><a href="https://github.com/MikeCoder/hexo-blog-encrypt/" target="_blank" rel="noopener">https://github.com/MikeCoder/hexo-blog-encrypt/</a></p>]]></content>
      
      
      <categories>
          
          <category>  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
