<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ShiYaya</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-03-15T08:11:54.636Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ShiYaya</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Beam Search</title>
    <link href="http://yoursite.com/2021/03/15/Beam-Search/"/>
    <id>http://yoursite.com/2021/03/15/Beam-Search/</id>
    <published>2021-03-15T07:44:10.000Z</published>
    <updated>2021-03-15T08:11:54.636Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. <strong>前言</strong></h2><p>自然语言处理任务中，如机器翻译、对话、文本摘要等，都涉及到序列生成。文本序列生成解码过程中有用到 greedy search、维特比算法、beam search等。</p><h2 id="2-Beam-Search-介绍"><a href="#2-Beam-Search-介绍" class="headerlink" title="2. Beam Search 介绍"></a>2. Beam Search 介绍</h2><p>beam search尝试在广度优先基础上进行进行搜索空间的优化（类似于剪枝）达到减少内存消耗的目的。</p><ul><li><strong>算法过程</strong></li></ul><p>定义词表大小是V，beam size是 B，序列长度是L。</p><p>假设V=100，B=3：</p><ol><li><p>生成第1个词时，选择概率最大的3个词（假设是a，b，c），即从100个中选了前3个；</p></li><li><p>生成第2个词时，将当前序列a/b/c分别与词表中的 100个词组合，得到 3*100个序列，从中选 3个概率最大的，作为当前序列（假设现在是am，bq，as）；</p></li><li><p>持续上述过程，直到结束。最终输出3个得分最高的。</p></li></ol><ul><li><strong>算法复杂度</strong> $O(B<em>V</em>L)$</li></ul><p>在第2步，要计算 $B<em>V$ 次。序列长度是L，生成长度为L的序列，计算  $B</em>V*L$ 次。</p><h2 id="3-算法评价"><a href="#3-算法评价" class="headerlink" title="3. 算法评价"></a>3. 算法评价</h2><ul><li><strong>优点</strong></li></ul><p>(1) 减少计算开销。相对于广度优先搜索，广搜每次都要保留所有可能的结果，复杂度是  $O(V^L)$指数级。</p><ul><li><strong>缺点（第3部分详细讲）</strong></li></ul><p>(1) 数据下溢</p><p>(2) 倾向于生成短的序列</p><p>(3) 单一性问题</p><ul><li><strong>Beam size 设置</strong></li></ul><p>(1) B越大</p><p>优点：可考虑的选择越多，能找到的句子越好</p><p>缺点：计算代价更大，速度越慢，内存消耗越大</p><p>(2) B越小</p><p>优点：计算代价小，速度快，内存占用越小</p><p>缺点：可考虑的选择变少，结果没那么好</p><h2 id="4-问题解决"><a href="#4-问题解决" class="headerlink" title="4. 问题解决"></a>4. 问题解决</h2><h3 id="4-1-数据下溢"><a href="#4-1-数据下溢" class="headerlink" title="4.1 数据下溢"></a>4.1 数据下溢</h3><p>求序列概率的时候，序列概率是多个条件概率的乘积$P\left(y^{<1>} y^{<2>} \ldots y^{T_{y}}\right)=P\left(y^{<1>} \mid x\right) P\left(y^{<2>} \mid x, y^{<1>}\right) \ldots P\left(y^{T_{y}} \mid x, y^{<1>} \ldots, y^{T_{y}-1}\right)$.</1></1></2></1></2></1></p><p>每个概率都小于1甚至远远小于1，很多概率相乘起来，会得到很小很小的数字，会造成数据下溢，即数值太小，计算机的浮点表示不能精确储存。</p><p><strong>解决</strong>：<strong>将最大化的乘积式取对数</strong>，由 $\log M^{*} N=\log M+\log N$ 公式可得，上述需要最大化的王积式可以转化为: $\arg \max _{y} \sum_{y=1}^{T_{y}} \log P\left(y^{<t>} \mid x, y^{<1>}, \ldots, y^{<t-1>}\right)$</t-1></1></t></p><p>即乘积的log变成了log的求和，最大化这个log的求和值能够得到同样的结果，并且不会出现 数值下溢和四舍五入。</p><h3 id="4-2-倾向于生成短的序列"><a href="#4-2-倾向于生成短的序列" class="headerlink" title="4.2 倾向于生成短的序列"></a>4.2 倾向于生成短的序列</h3><p>生成的句子序列越长，对数概率相加的结果就越小（越为负值）, 所以倾向于生成短序列。 对序列长度进行惩罚，降低生成短序列的倾向。</p><p><strong>解决方法：</strong> 对数概率相加的结果, 除以序列长度 $L$ 。<br>实践中，通常采用更柔和的方法, 在 $L$ 上加上指数 $a \in(0,1),$ 即 $L^{a},$ 例如 $a=0.7$ 。如果 $a=1, \quad L^{a}=L$ 就相当于完全用长度来归一化; 如果 $a=0, \quad L^{a}=1$ 就相当于完全没有 归一化, $a \in(0,1)$ 就是在完全归一化和没有归一化之间。</p><p>或者更加复杂一点：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">norm</span> = self.opt.beam_search_norm</span><br><span class="line"><span class="attr">candidate_logprob</span> = (beam_logprobs_sum[q] * t ** norm + local_logprob) / ((t+<span class="number">1</span>) ** norm)</span><br></pre></td></tr></table></figure><h3 id="4-3-单一性问题"><a href="#4-3-单一性问题" class="headerlink" title="4.3 单一性问题"></a><strong>4.3 单一性问题</strong></h3><p>beam search 有一个大问题是输出的 $B$ 个句子的差异性很小，无法体现语言的多样性（比如文本摘要、机器翻译的生成文本，往往有不止一种表述方式）。</p><p><strong>解决方法：</strong> 分组 加入相似性惩罚。diverse beam search 来自<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1610.02424.pdf" target="_blank" rel="noopener">论文</a></p><p>具体如下：选择 Beam size 为 $B$，然后将其分为 $G$组，每一组就有 $B/G$个beam。每个单独的组内跟 beam search很像，不断延展序列。同时通过引入一个dissimilarity 项来保证组与组之间有差异。</p><p><img src="https://i.loli.net/2021/03/15/VQDxijZcGtzlEph.png" alt="image-20210315161115581" style="zoom: 50%;"></p><p>如上图所示，B = 6, G=3，每一组的beam width为2。</p><p>组内与 beam search 很像：从t-1到 t 时刻，不断的减少搜索空间（如同beam search一样）。</p><p>组间差异：对于t=4时刻，我们先对第一组输出y（t=4），然后我们开始对第二组输出y（t=4），但是第二组y（t=4）的score不仅取决于第二组之前的y（t=3），也取决于其与第一组的相似程度。以此类推，在t=4时刻对于第三组的输出，我们从上图可以看到其score的打分标准。这儿对于其 dissimilarity 项的计算采用的办法是 hamming diversity，这个理解起来很简单，比如这个时刻可能输出的词在上面的组出现过，我们就对这个词的分数-1，如果这个时刻可能输出的词在上面组没有出现过，我们就对这个词的分数不惩罚。</p><ul><li><strong>DBS算法：</strong></li></ul><p><img src="https://i.loli.net/2021/03/15/DdS1XPZvoEptVgw.png" alt="image-20210315161139107" style="zoom: 50%;"></p><p>DBS算法</p><ul><li><strong>附：</strong>很多论文里有对 beam search的改进，主要是针对生成序列的<strong>多样性</strong>的。多样性问题，在对话里很常见。</li></ul><h2 id="5-其他相关问题："><a href="#5-其他相关问题：" class="headerlink" title="5. 其他相关问题："></a><strong>5. 其他相关问题</strong>：</h2><h3 id="5-1-训练的时候需要-Beam-Search-吗？"><a href="#5-1-训练的时候需要-Beam-Search-吗？" class="headerlink" title="5.1 训练的时候需要 Beam Search 吗？"></a><strong>5.1 训练的时候需要 Beam Search 吗？</strong></h3><p>不需要。因为训练的时候知道每一步的正确答案，没必要进行这样的搜索。</p><p>5.2 为什么不用贪心搜索？**</p><p>贪心搜索相当于 Beam Search 中 B=1的情况，每次只选择概率最大的词，容易陷入局部最优，但我们真正需要的是一个序列，我们希望整个序列的概率最大。</p><h3 id="5-3-维特比算法"><a href="#5-3-维特比算法" class="headerlink" title="5.3 维特比算法**"></a>5.3 维特比算法**</h3><p>维特比算法是用动态规划的思想。简单来说就是：从开始状态之后每走一步，就记录下<strong>到达该状态的所有路径的概率最大值</strong>，然后以此最大值为基准继续向后推进。显然，如果这个最大值都不能使该状态成为最大似然状态路径上的结点的话，那些小于它的概率值（以及对应的路径）就更没有可能了。</p><p>Beam Search与Viterbi算法虽然都是解空间的剪枝算法，但它们的思路是不同的。Beam Search是对状态迁移的路径进行剪枝，而 Viterbi 算法是合并不同路径到达同一状态的概率值，用最大值作为对该状态的充分估计值，从而在后续计算中，忽略历史信息（这种以偏概全也就是所谓的Markov性），以达到剪枝的目的。<br>从状态转移图的角度来说，Beam Search是空间剪枝，而Viterbi算法是时间剪枝。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1. 前言&quot;&gt;&lt;/a&gt;1. &lt;strong&gt;前言&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;自然语言处理任务中，如机器翻译、对话、文本摘要等，都涉及到序列生成。文本序列生成解码过
      
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</title>
    <link href="http://yoursite.com/2021/03/15/Bottom-Up-and-Top-Down-Attention-for-Image-Captioning-and-Visual-Question-Answering/"/>
    <id>http://yoursite.com/2021/03/15/Bottom-Up-and-Top-Down-Attention-for-Image-Captioning-and-Visual-Question-Answering/</id>
    <published>2021-03-15T07:06:11.000Z</published>
    <updated>2021-03-15T07:07:24.413Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>人类视觉系统存在两种attention机制。Top-down attention由当前任务所决定，我们会根据当前任务（即VQA中的问题），聚焦于与任务紧密相关的部分。Bottom-up attention指的是我们会被显著的、突出的、新奇的事物给吸引。</p><p>以前的方法用到的visual attention mechanisms大都属于top-down类型，即取问题作为输入，建模attention分布，然后作用于CNN提取的图像特征（image features）。然而，这种方法的attention作用的图像对应于下图的左图，没有考虑图片的内容。对于人类来说，注意力会更加集中于图片的目标或其他显著区域，所以作者引进Bottom-up attention机制，如下图的右图所示，attention作用于object proposal。</p><p><img src="https://i.loli.net/2021/03/15/p8WFURqkGw6iIfC.png" alt="image-20210315150105258" style="zoom:50%;"></p><h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p>Bottom-Up注意力机制: 即基于目标（objects）或显著区域（salient image regions）来计算attention。具体来说，bottom-up机制基于Faster R-CNN，得到图片中每个目标或显著区域的特征向量（feature vector）表示。</p><p>Top-Down机制: 取question作为输入，建模特征权重（feature weightings）或者说attention分布。</p><h2 id="概括："><a href="#概括：" class="headerlink" title="概括："></a>概括：</h2><p><strong>（1）Bottom-Up</strong><br>使用Faster R-CNN 中的R-CNN来得到object feature。<br><strong>（2）Top-Down Attention</strong><br>得到了该层的隐层状态，并与object features  中的每一个<strong>v<sub>i</sub></strong>来计算一个attention 系数。<br><strong>（3）对object features 进行attention 权重求和</strong><br>得到image feature<br><strong>（4）Decoder：language LSTM</strong><br>输出预测单词</p><p><img src="https://i.loli.net/2021/03/15/IcK4HYAsGwjzPqv.jpg" alt="img" style="zoom: 67%;"><br><img src="https://i.loli.net/2021/03/15/lqZx5tngfd9r2Gs.jpg" alt="img" style="zoom:50%;"></p><h2 id="Bottom-Up"><a href="#Bottom-Up" class="headerlink" title="Bottom-Up"></a>Bottom-Up</h2><ul><li><strong>主要介绍一下Faster R-CNN 的训练过程</strong><br>（1）首先Resnet-101 是在ImageNet上预训练的<br>（2）Faster R-CNN在MS COCO上进行预训练<br>rpn 的score classification loss，bbox regression loss<br>r-cnn 的score classification loss，bbox regression loss<br>（3）Faster R-CNN在Visual Genome上再进行预训练<br>为了得到更好的特征表达，增加一个预测属性的输出： </li><li><strong>具体的网络：</strong><br>To predict attributes for region i, we concatenate the mean  pooled convolutional feature vi with a learned embedding  of the ground-truth object class, and feed this into an additional output layer defining a softmax distribution over each  attribute class plus a ‘no attributes’ class.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;p&gt;人类视觉系统存在两种attention机制。Top-down attenti
      
    
    </summary>
    
      <category term="图像描述" scheme="http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0/"/>
    
    
      <category term="图像描述" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>Gumbel-Softmax Trick和Gumbel分布</title>
    <link href="http://yoursite.com/2021/03/15/Gumbel-Softmax-Trick%E5%92%8CGumbel%E5%88%86%E5%B8%83/"/>
    <id>http://yoursite.com/2021/03/15/Gumbel-Softmax-Trick和Gumbel分布/</id>
    <published>2021-03-15T02:02:30.000Z</published>
    <updated>2021-03-15T03:14:54.797Z</updated>
    
    <content type="html"><![CDATA[<h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><ul><li><p>由于最近看到的几篇论文中都有提及到gumble softmax的操作，因此想要具体了解一下。</p></li><li><p>用到gumbel softmax 的论文包括以下几篇</p><ul><li><p>解决不可微分问题</p><p>【ICCV 2019】Learning to Assemble Neural Module Tree Networks for Visual Grounding</p><p>【arXiv:2101.12059v1】VX2TEXT: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs</p><blockquote><p><strong>Categorical reparameterization with gumbel-softmax.</strong>  ICLR 2017</p></blockquote></li><li><p>在概率分布上添加gumble noise，再从新的概率分布上以概率检索样本</p><p> Bridging the Gap between Training and Inference for Neural Machine Translation</p><blockquote><p><strong>A* sampling.</strong> NIPS 2017</p></blockquote></li></ul></li></ul><p>来源:  <a href="https://www.cnblogs.com/initial-h/p/9468974.html" target="_blank" rel="noopener">https://www.cnblogs.com/initial-h/p/9468974.html</a></p><p>之前看MADDPG论文的时候，作者提到在离散的信息交流环境中，使用了Gumbel-Softmax estimator。于是去搜了一下，发现该技巧应用甚广，如深度学习中的各种GAN、强化学习中的A2C和MADDPG算法等等。只要涉及在离散分布上运用重参数技巧时(re-parameterization)，都可以试试Gumbel-Softmax Trick。</p><p>  这篇文章是学习以下链接之后的个人理解，内容也基本出于此，需要深入理解的可以自取。</p><ul><li><a href="http://amid.fish/humble-gumbel" target="_blank" rel="noopener">The Humble Gumbel Distribution</a></li><li><a href="https://hips.seas.harvard.edu/blog/2013/04/06/the-gumbel-max-trick-for-discrete-distributions/" target="_blank" rel="noopener">The Gumbel-Max Trick for Discrete Distributions</a></li><li><a href="https://casmls.github.io/general/2017/02/01/GumbelSoftmax.html" target="_blank" rel="noopener">The Gumbel-Softmax Trick for Inference of Discrete Variables</a></li><li><a href="https://www.zhihu.com/question/62631725/answer/201338234" target="_blank" rel="noopener">如何理解Gumbel-Max trick？</a></li></ul><p>  这篇文章从直观感觉讲起，先讲Gumbel-Softmax Trick用在哪里及如何运用，再编程感受Gumbel分布的效果，最后讨论数学证明。</p><h2 id="一、Gumbel-Softmax-Trick用在哪里"><a href="#一、Gumbel-Softmax-Trick用在哪里" class="headerlink" title="一、Gumbel-Softmax Trick用在哪里"></a>一、Gumbel-Softmax Trick用在哪里</h2><h3 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h3><p>  通常在强化学习中，如果动作空间是离散的，比如上、下、左、右四个动作，通常的做法是网络输出一个四维的one-hot向量(不考虑空动作)，分别代表四个动作。比如 [1,0,0,0] 代表上，[0,1,0,0] 代表下等等。而具体取哪个动作呢，就根据输出的每个维度的大小，选择值最大的作为输出动作, 即argmax(v)。</p><p>  例如网络输出的四维向量为v=[−20,10,9.6,6.2]，第二个维度取到最大值10，那么输出的动作就是[0,1,0,0]，也就是下，这和多类别的分类任务是一个道理。但是这种取法有个问题是不能计算梯度，也就不能更新网络。通常的做法是加softmax函数，把向量归一化，这样既能计算梯度，同时值的大小还能表示概率的含义。softmax函数定义：$\sigma\left(z_{i}\right)=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}$</p><p>  那么将v=[−20,10,9.6,6.2]通过softmax函数后有σ(v)=[0,0.591,0.396,0.013]，这样做不会改变动作或者说类别的选取，同时softmax倾向于让最大值的概率显著大于其他值，比如这里10和9.6经过softmax放缩之后变成了0.591和0.396，6.2对应的概率更是变成了0.013，这有利于把网络训成一个one-hot输出的形式，这种方式在分类问题中是常用方法。</p><p>  但是这么做还有一个问题，这个表示概率的向量σ(v)=[0,0.591,0.396,0.013]并没有真正显示出概率的含义，因为一旦某个值最大，就选择相应的动作或者分类。比如σ(v)=[0,0.591,0.396,0.013]和σ(v)=[0,0.9,0.1,0]在类别选取的结果看来没有任何差别，都是选择第二个类别，但是从概率意义上讲差别是巨大的。所以需要一种方法不仅选出动作，而且遵从概率的含义。</p><p>  很直接的方法是依概率分布采样就完事了，比如直接用<code>np.random.choice</code>函数依照概率生成样本值，这样概率就有意义了。这样做确实可以，但是又有一个问题冒了出来：这种方式怎么计算梯度？不能计算梯度怎么用BP的方式更新网络？</p><p>  这时重参数(re-parameterization)技巧解决了这个问题，<a href="https://casmls.github.io/general/2017/02/01/GumbelSoftmax.html" target="_blank" rel="noopener">这里</a>有详尽的解释，不过比较晦涩。简单来说重参数技巧的一个用处是把采样的步骤移出计算图，这样整个图就可以计算梯度BP更新了。之前我一直在想分类任务直接softmax之后BP更新不就完事了吗，为什么非得采样。后来看了VAE和GAN之后明白，还有很多需要采样训练的任务。这里举简单的VAE(变分自编码器)的例子说明需要采样训练的任务以及重参数技巧，详细内容来自<a href="https://www.bilibili.com/video/av20165127" target="_blank" rel="noopener">视频</a>和<a href="http://kvfrans.com/variational-autoencoders-explained/" target="_blank" rel="noopener">博客</a>。</p><h3 id="Re-parameterization-Trick"><a href="#Re-parameterization-Trick" class="headerlink" title="Re-parameterization Trick"></a>Re-parameterization Trick</h3><p>  最原始的自编码器通常长这样：</p><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165000500-1207992534.jpg" alt="img" style="zoom: 67%;"></p><p>  左右两边是端到端的出入输出网络，中间的绿色是提取的特征向量，这是一种直接从图片提取特征的方式。<br>  而VAE长这样:</p><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165407236-1369432498.png" alt="img" style="zoom: 67%;"></p><p>  VAE的想法是不直接用网络去提取特征向量，而是提取这张图像的分布特征，也就把绿色的特征向量替换为分布的参数向量，比如说均值和标准差。然后需要decode图像的时候，就从encode出来的分布中采样得到特征向量样本，用这个样本去重建图像，这时怎么计算梯度的问题就出现了。<br>  重参数技巧可以解决这个问题，它长下面这样:</p><p><img src="https://images2018.cnblogs.com/blog/1428973/201808/1428973-20180813165432014-1972855862.png" alt="img" style="zoom:67%;"></p><p>假设图中的 $x$ 和 $\phi$ 表示VAE中的均值和标准差向量, 它们是确定性的节点。而需要输出的样本 $z$ 是带有随机性的节点， 重参数就是把带有随机性的 $z$ 变成确定性的节点, 同时随机性用另一个输入节点 $\epsilon$ 代替。<br>例如，这里用正态分布采样, 原本从均值为 $x$ 和标准差为 $\phi$ 的正态分布 $N\left(x, \phi^{2}\right)$ 中采样得到 $z_{\circ}$ 现在将其转化成从标准正态分布 $N(0,1)$ 中采样得到 $\epsilon$ , 再计算得到 $z=x+\epsilon \cdot \phi_{\circ}$ 这样一来, 采样的过程移出了计算图, 整张计算图就可以计算梯度进行更新了，而新加的 $\epsilon$ 的输入分支不 做更新，只当成一个没有权重变化的输入。</p><p>到这里，需要采样训练的任务实例以及重参数技巧基本有个概念了。</p><h3 id="Gumbel-Softmax-Trick"><a href="#Gumbel-Softmax-Trick" class="headerlink" title="Gumbel-Softmax Trick"></a>Gumbel-Softmax Trick</h3><p>VAE的例子是一个连续分布(正态分布)的重参数，离散分布的情况也一样，首先需要可以采样，使得离散的概率分布有意义而不是只取概率最大的值，其次需要可以计算梯度。那么怎么做到的，具体操作如下：</p><p>对于n维概率向量$\pi$, 对$\pi$对应的离散随机变量 $x_{\pi}$ 添加Gumbel噪声，再取样$x_{\pi}=\arg \max \left(\log \left(\pi_{i}\right)+G_{i}\right)$<br>其中, $G_{i}$ 是独立同分布的标准Gumbel分布的随机变量，标准Gumbel分布的CDF为$F(x)=e^{-e^{-x}}$</p><p>这就是<strong style="color:red;">Gumbel-Max trick</strong>。可以看到由于这中间有一个argmax操作，这是不可导的。所以用softmax函数代替之，也就是<strong style="color:red;">Gumbel-Softmax Trick</strong>，而$G_{i}$ 可以通过Gumbel分布求逆从均匀分布生成，即 $G_{i}=-\log \left(-\log \left(U_{i}\right)\right), U_{i} \sim U(0,1)$</p><p>算法流程如下：</p><ul><li><p>对于网络输出的一个 $n$ 维向量 $v$ （predict logits）, 生成 $n$ 个服从均匀分布 $U(0,1)$ 的独立样本 $\epsilon_{1}, \ldots, \epsilon_{n}$</p></li><li><p>通过 $G_{i}=-\log \left(-\log \left(\epsilon_{i}\right)\right)$ 计算得到 $G_{i}$</p></li><li><p>对应相加得到新的值向量 $v^{\prime}=\left[v_{1}+G_{1}, v_{2}+G_{2}, \ldots, v_{n}+G_{n}\right]$</p></li><li><p>通过Softmax函数</p></li></ul><script type="math/tex; mode=display">\sigma_{\tau}\left(v_{i}^{\prime}\right)=\frac{e^{v_{i}^{\prime} / \tau}}{\sum_{j=1}^{n} e^{v_{j}^{\prime} / \tau}}</script><p>计算概率大小得到最终的类别。其中 $\tau$ 是温度参数。</p><p>temperature控制着softmax的soft程度，温度越高，生成的分布越平滑（接近这里的均匀分布）；温度越低，生成的分布越接近离散的one-hot分布（argmax）。因此，<strong>训练时可以逐渐降低温度，以逐步逼近真实的离散分布。</strong></p><p>直观上来说，Gumbel-Softmax就是在原来的输出上加入了一个噪声，对于强化学习来说，在选择动作之前加一个Gumbel扰动，相当于增加了探索度，感觉上是合理的，而同时他又能保证采样是对原分布的逼近。对于深度学习的任务来说，添加随机性去模拟分布的样本生成，也是合情合理的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;yaya&quot;&gt;&lt;a href=&quot;#yaya&quot; class=&quot;headerlink&quot; title=&quot;yaya&quot;&gt;&lt;/a&gt;yaya&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;由于最近看到的几篇论文中都有提及到gumble softmax的操作，因此想要具体了解一下。&lt;/p&gt;
&lt;/
      
    
    </summary>
    
      <category term="杂类" scheme="http://yoursite.com/categories/%E6%9D%82%E7%B1%BB/"/>
    
    
      <category term="杂类" scheme="http://yoursite.com/tags/%E6%9D%82%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>Object Relational Graph with Teacher-Recommended Learning for Video Captioning</title>
    <link href="http://yoursite.com/2021/03/13/Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning/"/>
    <id>http://yoursite.com/2021/03/13/Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning/</id>
    <published>2021-03-13T11:13:46.000Z</published>
    <updated>2021-03-15T01:32:56.252Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Just can be seen by yaya.
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="video captioning" scheme="http://yoursite.com/categories/cross-modal/video-captioning/"/>
    
    
      <category term="cross-modal,video captioning" scheme="http://yoursite.com/tags/cross-modal-video-captioning/"/>
    
  </entry>
  
  <entry>
    <title>[VATEX Captioning Challenge 2019] Multi-modal Information Fusion and Multi-stage Training Strategy for Video Captioning</title>
    <link href="http://yoursite.com/2021/03/13/VATEX-Captioning-Challenge-2019-Multi-modal-Information-Fusion-and-Multi-stage-Training-Strategy-for-Video-Captioning/"/>
    <id>http://yoursite.com/2021/03/13/VATEX-Captioning-Challenge-2019-Multi-modal-Information-Fusion-and-Multi-stage-Training-Strategy-for-Video-Captioning/</id>
    <published>2021-03-13T07:39:13.000Z</published>
    <updated>2021-03-14T12:22:13.259Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX1+PKyzZ0pzbjk2NgHenbyxAl8ZYe+UDxQt7r2CWoHWy4yM0ugQ8p6Xld1/WiZovzqZDGmAuOI0PMLbV1GkzBKGp3L4UR+qfkGc5T1jVfPQumD0E/NoU+Lel/mIdjL/TQbBhh+tmiENMD1j8cx4NZ3G1yxQ0Gvo7GsQ5JUKeKIof8Ri2Y7q4EaMvnTXQDHgVRPss/HAwKHuFr9CS0u/sLvWdjON77nbPdgiL05kkkRdEAXxKFRxnf/LbJR4kL2tO3iMoZqF1lWvMB+I1xv4od7Kv77S5A7N8qfo7gbWduqnagiP/SIenwjKcprbu+W8OjTofV1BMw95XQUsWVfQllMy0bROHvfHEStX0Ozw3UHgGaiF4mz4kByhbadAI25WqZp4cy7Xf4NWHhScqYoXwFF8Z1BYBxwUgnjn9DiK4lP73YbiO6AUeQHJj0cwymJ9s3e0aNYU2DnwFCj7Y7ZDn9NalZYKpZ1Pk4hIx2POqsi2cv8pEoW3984XFcp4Bowj0UGJzSCOa5HdmxOqylCp/szZ0U3brAZxs+/aXjsc18PT2drtrmwoRLvmdEV4kVl+jlA+TWVaa0UFeiF9YIZytsLL9kScGmReqiLzqjfe9yWSFrG403azhlbPcvHu/0F+zkxRxeAaos7OYp9THi/zlV+v5tR/TKO5oMUqgqkBwjO7bJZlMFR4fAwEPXB9K7VMtb/l3KoepCvPpwILAEwe6dw6U2cpWz94Sg2l8r7NlpqxSWK0lnjsRFyE7zlcZmHb6BeaJ/le3oYVc6E4fwVWK0RFtEwrTUuxkmDMcsvEp7MZr7L6IJfIUsBbMaBChV7lCFs7JFGNGJ4QwoOpy2TPVn7H6SE2nwok8QuEd9Dwos1Ke+Th3Nc2g8s9w76vJ5r5gzmKhEDA/buD0r10lHrnd2LTPpFN7jelBoF22WkTFg8+X2OEZCmQW0r1yPi3SGQzgfBC2c2392gcMi6Q4HkBHnAkMI3st53bVlhBzX7XE6J+PhfWxhNiiklsb13g/7IKM1t/9xckFnEfplwrQ8vQS9SSZlXfdNDDPHMNoZJlsJQrNA0Lkv2wdokmr7mvMaUG10wJWjMvepsMWxShYIybdsOfyuzQRSlel9xzFpvPD8GAdKmv8OiXd0JySVPqX8/kGoBFkEDDZKAXWP2qz2blWu5ZvZ+XgBZz64EJsDAPSfRpJUEq3BEMhylQ7P829mMIvlGAn3X0Pt4WSOqTuIvKvp2F8liIBJr2F47/c5hU2bmYT2nnCN8zvfikGiv7AsCWok2dwpqyz9DMUESUUxXGmccAS8Grki5O8e6chmgqU/ojxaS/VQE9gffzorfj460OzLTUWcvqiTNJujO3afNA+sq8VN3PnCyq/6cwq/7vIn1R4X4ncZG9fDyd7wsaWtb54V7Rt46XxPSI2y4yi9c/zlZxwFVteOp7Lz8FOaWOyq8NqroBYPIkr9C2k5wPd3AEfPooLe8Pbov6eOb1h5xpaTt4+q1gjQd3llZub98UD1+HCgnbU64SKmSXL+WPU6CyFi9Z9COczAXOkqjzCVrP06Xb27cu5XAiBOPw+Un2kFoUdPTYuUs5ryzsVIR1vOoB1JblY+epZwKJjZStrFjjPSMvmigYxhUBQHfaitT5JOdtC4KMOU5VIIX4M+wSSauFt960UT9QUw+4Uljrj1m0jlBdS81y4YESaDilPXa0KgbCbAfxwm6HeZQWg54FgoDDeIvIoCOSe5FXsM+oqTsivAMcD4g2wuHR6A3rPh6nuE/Zw4VvsSdoyBPk26T18OnXmPb1XNSi2xboB+I48X8m8zSviFsqzwB0fK/kswnp/feV6Far9cknffb7UQtJytYXsyaOA9PVGSGt7VKjPgIIIV/caZH3cd4aaGW6BGRzdYFF8JWDNXCtklceLAQnuGdmAOCB/kqLnEU/nPkIRUXn4s8nGprwep+1YxwZUmCD1kb6RGQMoYCGAh9FDkkTf8ofIWBcZ50oPhF8Uegr0IbQG4RDFjBAqapUHfF67b3UUZr3Sm66PyaBOaO4vGi5CIKaGbx9xk5dwsW9mv8s0bj7zCdgAY/WfktJP8yGTik57N0XdTv1402LtCsDuTd14yDQ6AUXI52Ov6OMpFN4r8pso5oCa5RltIWg2M3P1ZPpu46FxHmUj1Wy84hZ4umDsAd2PGFldaczAmmC8qdKeMT6cP3kNmC/Mv0jSEKQMDg1jEv5p77QszkzYS31RsFekixDX4sOYrN1BIKhqFjIGWxlXPCKfmqoBg9yTsq1KZulUQ1QVynVU2PKTv6evMU6tPvuoCksjdr+j9XjcDZM63mYJgezkXyJwYNp6z6llb1Q3zNLiTgCZ8PH23CbTxWSL74uFkPoul08T2qtkQslmO1g6aYaba4EZ7aWjMSwyLbRVlVsoOJx1x5DbjO5qDBQq5olAHfbHRz3O8kQVF89F0Y1C9MSe6EGv+3wtxCgiO9SYecW714Lxtge8GrV+g0oUWnPsGEyB5IHQvdtvW5MbXKe+A951MHES19HyCHwj3aTKzrJ8xSVpW5khVp7LdwV4wnMmWieA1oKxh1sSPSBYb1HeoGMUPjOldhROWBUWEeIqXk+PNGaaQFuKF3NgdFG13obzZqEioJvXwYDH/YpiWfDJ2LQGGeMV6+ren6njbo2vmB+HZsJsEGgDmyc9h+/BLBKX4oh673yLd6ln8Ht6CyVrYCQasyFwSqFcFLQfZFJMDy6yWL/t339QNp31DrnlFz+2cy2c+Eut3W18oSGCDhtrzor/5J5H9lGx3wv+0t032LDN9tPPMLqNTBgw9ZaHfAzZBHs59NSnFcBsPS25+/3I20Bu16LXCqeZ0pWx/pKnh22fiCBYizRftqN9iHBdpdG243LLZu4vvs6Ol26vHgl7aFroO1MfV9i1PV/Lf4eVa3kmPaQuOEoyGfCGI+0aOw/yloU/S3E2EtbgLDr2dnEBn2q1ovNdhLwoQETBCzG7GhNm8ABROlrTU8Xnh9nI2jrQDWsj8UMTuZmebxkXIjIQrxwpRbXvzpJwUL/MSwEMGW6Zp+qgYuHSFqZ48UdPkkm1VslKh7HCj0DfRe+haAI2AguusjL9AePQu/hOMhes7kUIKNuxqmg5TXNXKSOf9F+cVudtMRu0IL8ikTfQjDqkR4zmUmu2mbBffxAB5KpJULhS+qYjV4jBf0B+RaSHc+CJ75kS6TvlW7NC6wBtPAhImFAldW21ng+IjWwbe9O/ctrEU8MqJ0ZFlJGDVUWysFBkjcpCFL3ZMgJxOsWOrH+RYmxC0DoqrEjKN049KH/tWlYKa0aGElpnIFWAh+bF58ACSkrZmm4noxABK0NT03hyTJMLjYDfSh1arffzvnyXR3mNwXVeTfl9kubB/gC8s1sSBd4tVPQST1yOyLqQ0tRPoS5K326TXBZbT4ymCbW51Oyy5mVS/mzRRKDQHSVjK6ld4PcWmTbaraThdbBvUb5iXSsZnYDQynYlQ9JQ4oSG1qMpq1Xreny9KEEStb9RUumoxR2/4/Tw9tjlalEGwOLVbjimwTpfetvJsHVavFEsHy7C8qhJ5LAG/GwoazO7iSjquhC/1EjLKGqiUsXjx5RorDdbgJpvM7S/vQ8egsyPAmTqHl5BNnNl6nQbbjt9fhmMnd0dZCjT91x6tn5QW+r7gGfGyDJ1DhqzJiUO7OHSk4yuBY0LwUIHuV+JclUiK7f3s0n7yg9Sbh68DI3pZTp/AXUGDMoydxl7dK0Kyu2rzM25UcnqJ+f5J86fRjLETJkHNY3lxCAkmiqfhudYm/I5fCK1Lm1iQAjBumfIAdFeTpopB3mZ/Zc4G2Krg2NsQienG5wntdOt4JMb23W840t5mBzb7oYDteKmlckPkKdJpSjkv+BzE0fCvujx3qthzVa2mIYzSqL4/N6Eor3x8wwKL1Lkqza65Ut6bEBZGYpOJwYB7FHvn/EUZz64zIBBN+t4tX+zo6jm/Ukwj48alijdbcIHQdPV+2qGrjp0c2FLYJR5aM6ymewgReFjIp0gZhBEk8/+m2cd5SiMueyiMx02VdBzA5HfpnPQ4+0lixp5h+DBb+28DPG6VjkJIzpOwnMDbOrZ27gDLbnzxeDP3duuiwncF8wnOcbmxvEOC8r99W+S8xGBu34m+Em1iFyht12R6/5zihhxb9PuheG7CKGbcHxmspdY67Zh/ebpK6UXwQw83Utn0nYmREsi6HYt2TQCPzIeuI+FFWd3Tt/d4FWUAD7wXGMFg3EEhXYy5vMCGiRjAQTGPhX2fb1WMvDLCspgsncjSCOdCvrKSDxt3zWOUvrwmWHYNwmJ7+9kzm6qpdzeXOmYzJASzxlJ2mzHCPdD/JJ7iA49m08p1Zhlwl8iju6AjyfjsCbcKpEFCXaulwCSkHLgvcUSzSYuiT0278PnvCAz0OTmXCX5SJZ7h4jrjKTPQqRUdqQY8LE1o0nD1z/jFKJuXXuZI4myiOPYK+yaIXHdCrM3B+ep1ExwClpL/1pYITAQNos4p+nYzKkT4nmQU/W1oOX2WaGkiwazilDg3vS/ofBLqXhyLJrClfqGI6MUG3km0PwpqrrIShGwxThc21sp2ZTYtmhw5tkKVRD6IeYJUhU3dQGfv7VwVkM3NlrNAH+F06O1a4mhZN1O4TluFyOIotfK66xhl9eotScrJPxA00k8InarMtKf1lXZNvkZok88L1bwUzv+QsRhjMIbzSqcelEspmupDqtlCcfF8kwmYTLRXYFYNgDXqIjenGGeBfXX2IPjGJgjHaosLwpIpI6Y3vT05K9aUq4kgUHsfQCLPXLLbrKAdAspt21Eynb849ttvmBs72AbtqfINdwRjLc1P+Z9FG7IE7utccSe3bJ4KTyTR2Yx5E7wEqqsxp7phOMoFym85FbV1P31+8kKjlUHA+7d8mrCLUHsj4eKqL2O+HGDQRnIksARarDdjOLiIY8O38H2wYnq0umbqo2zVJNS/arshGyOTJcsReL4N/bLVw3uzKD3FIwx9cYljAQdmvDwDcCVoU0IsLbSg/sqYHJvb9Txzag/vY6UoMfE1aAVcgWLSfkMVmzePwbbh1ftrWgHO1R+ieZbH8Ykd29bIsRQcrDN/xZJPf23FQ82y7G8iZlJ0ntV4XdwYgXVxj/RcdhR0donizRDk3HAo1IW6R3738M+QBb8FfGtLt7oqQEYTTYvc9dnp75CG0yYs39houNfVMPNed2pFql6uPyQn94f5Kfv5tEcQXw2L6YInG0SrsFHgZvu7FqhgLIpBfNZYrOFaXsSipiARBX6gv0NlCrRy34oSPkn5gUt/8O2VJsXEylubsU/5isNwEaGqJsV7/OjTJcPdeqKEnDgxu1YQhmzRR/wAR9zPMKciZl78L9uiVJsXDy2vVPgFjzfEXA1uWKwYvOTzXeVFqbuQ/VGhz3PWSjfsbLov+ADvuYKqVMjQxP6Epl4/qLX8UwNC1hAW+n1r0YcKeDhkMC+WWxR2WxJPCc6d9ntnHl5p9jDjyTOn9T1YIMJHWP0CMZFiC9aXMy7Lo0N84LLc6IDHGfG5ItDCWN0OV6YsVOXlL5IsrX9QQP4rc3iSM7yiAm/WrZeZCuVL04vDrWvGcB/E8JuNSPXYdaaoU5hko3BWXX/NrVP3nPPXzpgX1Kw9qKLchoryJaKc1EuliuIIblz+Oow3ohj0cJiEyoxGGeUKKwUdT9UugzyZxgN9XQs0dujxCg31eJ933z2PVEN6St3J2hiDTyNv2suDg2+sBen7Sf4K9apbax+x2XzVFAxX+E9xxujs0NUltehxKJMTf4Fjy+BixmLWVRfikr+B6UW+YzFyCQWgXAmWDkqVU2Oq8Y+lgCa8lO9ho7CLsSlEW/O2eHiYzi8gXNA+EY8VVAd9Aa1yt8QJP347VWmnXLj6hiAq1cRKTrbJ0JRyQ1bmArqzPRrMgZFa9rVwPmKzW4cNuPMfDbpvW9kjm3zRTsAXaFmiRrlagi3M+ThjXhB68ZoOp8qiSkSX9+yF4zutmJ/GOkV3iqIzdTr6zF0KknPHbSdINVY2wkpcgqUz0pVne3RS1q5EwIx+sgp6P+2vX1l68XysxHHKm2CDTIT7vflaSvGDhUOnaLzKGQsNRlhf/1jTeDqxlglkpAL9xMsYt3lT+/EnnSLgRV4gJDHNxFWsnt8xQCQ2wkIVvG3SnaVRJbyUTYhEcqXQRk4PJKY75ealuG+YZCBz8GiEDKxm7ayXarTx7QRMNIVEzMmWuOUyLkbKU/Eh0RsOofRo/qgap8MgTyIdwpYtDsrvB9UixcJJ/iWS4NEeiEr8DXFCyO1rQkZI32+2obIg3YM+4+y72FpQRyg+gp3Bs3E0yeBhYrRM15gExJrXnSCWqiMOEE3CBtCaPEK3hizOHMS+p1polJa/+fVaEWyHZnrLCbJXg504Aio3F7G6Ogm3/lK2SfVLpfrS/WiWt8l8bIueUgwIHbaDXNAhfjZEpzsOPeXgXCsRzmFfksz48MLOXFiQkzLmBSyKxKihIGJO6DIfe35hI+DHUJXZoOlWI4wscs72cRTZZkvPdi6umoHiHhfjjyBwPldIj27PcduwcQPjlz2OV3wroarobtZzIBQPZkHNly7KoaYHxzOHKfnhquJuibkza1EVSd3SH7sspFV2b370MmAsLeC0F1GkYp/D6zMqdNoiI546PvDq8xIqdiGZ9QepPUDQqC0t6mWWY9DT5PzhaS2dMigVFGXpoY+3QIHP6abb/gmOlGPSLIon8I44YNkJHMjADkRFdfjs7TC4kr51F7KngI5gV3y8t/Q/5aXVmuCFjek8kVi24iu0uZ5i5KOXKaIUY4iYqYQpUsvCzwQ4xz3bEkDhl/8nVtNjY5YQBW3pA/RaoqgwyZkjLAsTzvtRyhrs70dhn6iImY8bSIE5VmaxwhszxB0lHjMtLmiFL9w76YaKKp43ldkptnDRLCL2aXL22cQLsfE7tkdN4YrrVKqOOC6zNA+KCnCftQk0tHKhS2KuzOmSJhudp1TAcIExYFc8+j2m+Jn8YeDxxZt+9X6NB71AVpELbaO3t0nhj/2++AQD/60Xha2EWyDfxwrpYB9g2YGdNOoszM4yHH8Xt1iq8Ni+H+Dnzv9tRfNv0wARmYIG5DfI7AjtZaIu1+1+XgaghGQArsvro+9HDtj15XEJk9mAEK8ZQKhSHVMa1yKWk/Lex1pbuIlM98lCL1r4JqNWz24zPXfHwO2PUuTpREzSp/AonI0UMj6TtdhDhQC0RjKEDT4H4kpQ+QnQbxJOgwQPEpt7J0whmG6UGK6/FVdP7Ajs37/5XAucYFFEOzdqCJtMzyQq5Hzww0Vp1s6G9j/B9ad/ffhRB+hZRAaMW6D+Pj8fY10TUDAdLItzaVo1/GonHIXsJQZAYBHSUnNt67wZi3qT3Spu82w4h7O7QSF1UtVjbwPIUTw5Z0C4DeEGmLPk5lKNDunBcmiRPwoGXYj+6zcpYh3f0BhpbxIJcI8iVrQ0HeO9DIkRGTS49pTGru0w3VK622SGQRAdAERthXYSwd8KxG/1Bx31uHFR6JOourpB3PzmT2BD03caOcsy+CiNi6J84qVwZ30ev1+jSKdD66knqfs8/689IegoLynIkHG6/Dv+e+12uJ9/LR/Nm8LBJHrrZiQBLBsDZtIiAnF9Rb7VYsQGkcJ1R9JxaGDwL1GK3Wuy+yDSTOFYbStHn7ERVYAoTGnvtHk2GKivpQXkj8W5ZJXrjL/fqD4b1yQH640VrjRxujudYwodz9cit/nfbgbBau17Vsv82tmzxTU1iC5d/fabTLPh1F/klen68ywm5CKu0nsrhvz+IHf2jkQKdPuXeM0Qt44mdKIP0gFAzvnvrjpU1SdqV5eRKZXNz3E1yrVt80s25A8c+oxCgDeIZvi+KPpt8aeVzdDy0XBDV5thFbqkRn0k59KgJDR2EnKIYWsbUGFhBreqGl4a77agEW6VVlI/VUMhL+k6Rpq9PfNms4aJ0ypGwTz4CnznJWIc6BPFY6JvuSQNzefwmoGWo3hdROp3ar0XHh2kwSnMD56hOGForb2Jdr7DI7r/738TRMpioxb8AgKT8i5bjJRio9+oUyZnJT4lOn3DSXb2tuIy2D5hUlZY1Ug8TCIL1Qorx6Tei5oijJ49N/jxjY5JRbN7loGs734tFz7OC48HJb37zaRGzeS8U8ZDZXVGAPlHO+Jl1/cVkz6Mhqux5xu9KhgpNzzMCwXTM/533vXkfVFc4nIYNkNb6hX9wWnxmJzDwmT31RpcBUKZ0nlwzVeQHBTo7XoJyZxu7yE6FXX576OJ1+OTzgNKPeyr3tzs82wuuFkIH0gGLgcGMLmDLhDYJpssl/khqiI5Xdr+OqUTUVIKvwP/0LQ1skzk/bJeHnmqY0ow3O1chKoHOpZHsLE07MEKX6TQBeo4tmKxnJP3UhWh20uoQGFxnDFzC4co0t9QLBYJY+CU6kiyBwxhklG/mmbsuzKeU9Vx93lhLkLY8ktP7TgFQ9+SqkSMagn/LTpm7UUK8+hBJZYCDyuW9GBdGNI6aQ6b8GGnVhV2dRcApwK+MsxetRbHJmj3m8gYdYsEesBvYnwxPXlLAIZi+YPYBs9kI5+9csdZrYrkk+P7rzJNBhnPnmGBbfHu1vwLJ8rBJoGpwthlVf9bWG2uw+ZMRkOPTkIEXzs/N4cWuQTf54MZ2zLLS9PBqGg9kxszdS+du0TnTM+r5vO0FABtbZcjuThXnVvZYnpxIiT8Ssq5459TUSQucf1+2azek+uYhWkChqsvuAXpLflwI91yYa6SY45XQHb8oEyPW8qnb/PVY6uq4jxgKiZ4EQ7A5ccwicMXqp+3Sd4VyyGsNXk/W/diz8ds8/LyO8VnXVJw80EQRhW+lDQXUE+30T/p9rrzSSXUsOe7USxCNb4lWissEMyE0wqaM39k5grZoSbNhOqVGVqyZq2nAH/QO41AJHBeLBXr0zHYoimbk9YhsLScSblk2Q2IdrfGlH5zw6GvlYU2MkxZnCw+BLeH7ZdN83/bA2C83x7ZcWJgGh4xKy22trvuXOrVb/zj3lONXVyDumaufRhX57/Eg8eHkClbg4q9j/eBlFY+yWL55+yqkhqPOmKJXcTfawTDaAn5tp+n9LpJ7TheyKuxS68mUN8aZJRwRLPmE7n7S1wrOVtUZJCijc4dGYja6N/U1Xnnl4lZfuCsdc7DJK+PVbRYYIyyFw+3zsBj0d6T4pV6tnUxzf3K21aC9p86l8JfSYy3LiMxMhd/dfzYJzSPFdedDG5gMLHusCJKi7cW78dEEVRGiJo3K+nqmyydNZX13FO5oR6qU8wwXz4eCFjEpo4ZQ2a/einmiNoavgtcdiOwzP/ZihY9hbr6auxjEooBrx7pYhYMjdNIco5wxvPghNDiP/0mgl/5sey2w5Ct+T35QaunBhaTY3PLmHY6MNMVWMt1+8v2dmUnxG9ld76XpiTzL40xtAjrKUtKMh5aLCRzc5TQfAdD32MIK9tojcRDPdfEFp6mTiWUJvmiXjxvRFuVFrUFzkkiMY6UBB+/nMYTKHhwuh/fY9h7xbyr857dkssDD88DC8PJXqK5CHu8rwcVpv0P7F6kqx9e0aChg7P5wk5PzY/Mqd1RtwmTdErrM+ovGQ8gFdNBCozMPdwvgKXwRYi3o9UoXuxSUdgX76uVhMDKs8wK437Kh4J9UtJ76D77k+ksh9xmUKT+OJrHTC3kNL8ntIOHoviIyQaMgKRcHYbd7wbAiYLcrvJX5bV/03A3E1goxogCZpdn+PLHegl+obznvb+YKZjQwLgKUXaf5BbnwlRr3+sW7/ISEDeKhTJ6F1HhXOekSRCApNdna0X5mVj2Ph/2B2k6TRXdgaUm2KuUhnNZRV57oTufASmYLBQCkAHdZBq1FQMY+0MIWTwUrAGZRmlDpYmg4VFI94pm5Jf2FhlaPYGjfIbgxaGnTBSTvK72/rNNmCf/7X0FTOd6oiG6L5GztQZfgPVPmEO5NiiNVPTURNP4dbdNsGisB6bic01qjfI1Wj6S1Fy9cMMl+YoAFBhCq0aInH6t/FOfz19j7E3ogUcgLyNpIfTZM8xc+nfFQ9kzu5TefX3lfWxnt4qGgeiJOiL8amcltdf91p5RhkE94EojCrBh+SGDX0odzE/AGS7o3ny3DUNF5AI+lcIWhRbEHQnzL3ZA/o3UtNopLKD6MTu+yPsR32CXQYJLPrM/ZrkqGqKfNZ+GpB/pzdN4vnrZiUifOVc3YgYWkA6BwfsBh70AfBmfjDIcNluJV0IwT7Qv3q6v00Zl4w0A6VSXqxKc7Lcio3ILzgPuO815ic1bKs6OV/3/J2xPSBLJg3LINzMqWW89M8p2EDYYXumqSAm6vvxc8IhH6fq38J483PHYxadxdRiIE1wYUPZagP/K+vVPqmd3T/ldJ4jKkRL7mDXCFOb29jjzZ3h9ZqTfMlHrtX1IJUH3bxftv4XXQUdCwKwCmz1qRHzqqlvi5t2b+7cr5EY/6BA7+e0Y10yRtTAh3Bc+K46JDiUS4i1bs6ED9bTEoOJIfDlnzddST1wUYzY3C26WVWX3gGTVZyta/mq0rPk1otBs9jPsVNLOq7gq2htdhguHLmfwzdJGjzEEErj2rfdw/8zxDjBgQpijnuyv4HoQZj7tspJS+9rDWqZmu6ppqa9/LhFziPy60yuuh3De+CIzDnlYk7MukJfz56NRGg6mkmPJMrghUlxyaX5dPWQYctFcEy/HLQL/fbwNWOBHw6FHyuSrTniFfs1Jr9LZ0ZSx2gyxqSO6NVhkA8uLHu4ZFcT+frbw3XtlmNilci5jl1uVAPaX83T3Ik5+I4n6PXa23oPa1zHbFzWi98yhk8FcE4c4rrfQTk+c9zxFAK+qV84Adg9DkyK1q8N7mOp1WEOrvVorqybjafLDOyx1RZN72tvfbPPQQrhnyLcp2Do+vkh4YandDQbIJwFVjDhbZ7MwP9yFEZ1XA4FNsRWS+zaIRVHSB2Mxy+DvzOc+6TlaKEQyxwdz+K8SkdsW9m13JaIkqrVBC1zCVvmFU8S1qMzBD6axWCrfq6gDWcLeJVgGsYv/3WgZXNyshzDjpgfTPmAKWG7gVsjzn0i8AIU/nKViLP8ZE6Df9FlFWN2p6ENi+EDUk+4+VYp3YvPTTGA9awYdzNy+iT8vIalmL451nP3cn0rn0C6WVxt+A6J1EfUkR0JMCgQxih/TDHFMFu0+WjwojhxHePdBYOAzSoLGUXeVtx+vErPYc7ofWfqfkgAeLe3aWnFQNcaW/yv1Q7vX8ZVH5mLubRbHZ8ZYsjG41OLaUSVB1IWL2IRR6lh3HECgI7jP2CPh8rWyxhm9gftreF0nbOZJc0N4KmNXckDGnj34zlnhjcHThZSviSUmOl7jV3AgwmKhTjVo3C+XEVIS8fCdGKDgyzQ46D3/XKxoXTNOPE8bB8psGQZtsmHc5cz4xIWpa4HZxUc/vvtI/1pL5B8aVBKocOifN0gAI8ZWpVV+IuIsHcz6a48tRCz+92BMTSjtQEOdMoBeomStgKsQBMpBv7BEj31eW98Yy7LtR/ChzaYbflMyUrWkXfppcUmY7WuzJ2TVIJGb76lseI+Pv8mEHxbfzLCdvCYN4mUAP6iH6h5w3x9lKIi2hIuUiJgMo9tBPim11tSXBDrYyNYT9CA+QGbI/2hg5PhlmKYqqcGN7li3tcXL8JaaYN40vehA1hp5l0atql6qi42SUK/2DbXwUoEJNLE+eBFvlOTjryDFYBYDPlbJyo7aMCdh7fIqIGvpUmqez4fgj5TIhAM4whi0qevs6hCNCb00qDea2uDJcSUk37ZdwlGUyQnzm/7S3/DTEQGv8T8mHWbUkhIGAiiFACruakhEWa3OSzRLd0PATUi4D4gCj8QBE54fd4ycmH9AzzqYJMTgiuul9L3nw7/CEmURdPo4o9hQKYTogPk7OWdRh8s2MWkuklSQYKtSMb0QEYwU6Yd+ko+dP0QAq5k2SRP9PDP0eVoAMOrPCa6YRNaOhDo0hO8ngTBgELNPhy+LEjeSXi23/woV3CnsGGONBat1ALhd1NxRMxnnorOUNmvhdKyllyX7Sg9H3wlELD2HkX+5KXxQrNyh7tk/uicDMOhGrnXR2yuZs6gTyyfy/il7A9cTNXr7PRXY+zaiQhDO9QYVrd9CAkfUMks3K6S6PJ0lojP8OFroLkHGG8XB/r33lNQ8EbUbEPfrzZEok0Nv6wzeesArgwvk1+rVD1K/lPX752oSNXJeMKeoq0ZdynhIiunFiKeSfjJjzsp+D/G643t+OXqUvHeYdxT2cK82mlUVVuE2tU2L9s4i5/82X/Yv5pSEsrOxp28+/w+rY7E3tA/NjVqTMtDX2eDsF4xrHmFxCx6pVYR+i2Gq5xF7bDwm+iclzJoiXicYRFCQVgNNaRjxbRdEmFHY4lsbDLC/p3v4cLFmHL2WviteQh1CoG34IYK9+2OK74gFpd5eBOWH1KL43BTfaFrkRTP0MB3XNo2CHQrTtGI0w1shBDK6yZYUn5pGtY5oyvH5e7pnhW/hzDSEAZ9nDycY3fSYfKjkRYNX4FSwcrMVWfa1Z+1THQnnnYBiO22Eu1aN+GcjjLBs54QIenHbMhmVzp26NV0v+IeiQCo8S0L5l3rmnlxjFkrcdagLr4gpXw0lgNP/WQw1EVlZsTOIZedroWgsRsu4/6EWbYcEOeAUjkwN0PbnxilhSUfqobu0ThG2Hau7GgIIXANMVBrY1EUH/IQIlnuYNDvAlWzzpJaz0A5KMtHgdDHHgZfrj4dcZafBQCgH5BUi+BqjHGth0rPuAuxZhh0WR8l99LfLpQhxhB/t8ZdISU9yjXeuEKCWmUic8t4R61JaQncNJ6+aN8naRTrad6UgRmOnioNN++ycTCh/vJmApyNjFIKjE3biAIf7HZ5pTWTAM60SIvQU7QEGft6exx4oPNapZNp8U3RoPl/KgcAsG4EpLnELapHbb3DNyAslRyfoxkVhoTicev8jbUVZvaz72bjsMXehdCUE+T8BwhIXRpiAYKF2Q0p2FnuaxoMn56p8UFypMwTDwmM5FP4pKZBMxvaSb2DX5XHV265cCTctvXwGpcH064bzkUuqeEHGQ9g6QUL9EAsOBB9w+PHUsQH8K3B8HqAg0zpKz3LjVx8qljOUa1qTqu32u0nOCV5shgJk0ZjvNbH/k06balpXm+glTQ52jWEXQ2MIgxHPJJrV4pm6ZR/ycg/gI/cp4uWlAAzxxX6Li6TC0QWboDiBufUs5ELUCtVD4GHLy9or7clYicGKvhSjis9QBkyjfNfKsY49lJDnCzRd+NxK5qWZQ3koRWwT4LFx1szAZpYWUGOYFIPf5mevC0+aGxMVl920vIDWjBHP26XAFwp8KFIObhBcE4yB/PLmuN+ps0DLo0bUrX6Bx/R0Nicanspr9/DBKbIXtYveMqaSsn/voJk84mJf0JVHh5ZIhiooBZwrD2QrbAGPbBvkj88SjPQXY+kBt3cV9BASsFDLpI1XBv//QC85UxpUrRaCJS1IicxrkSek8xcRAFBjv5mUKMVfSOaloeQfpNq4e8fNlVwNjIOvy94jZrSCXmV+CjmW0U1EMY93WFgt/5yEPBYOQ20UiQjfdbVR8/6tct74NKO9nH+/ueXawZG3+HygEX1fBDHzndUDEG1gNvspPBKWX9GeJHCFOV0ZDqrUqk2b4QGwPW3qD4B+dg9kb0UezAGtTbU7lll+V18oLFtNXDwNrE0nvxyW17yPdiP37nNALrIyyvS0QM5yHjUcoo8JSAEtDaydbNQ+9oLIgSedC5sGd5Umkcye6htYJFE1Zh5KUdh355qo/vLdy9hosX5gXa+0Hs4o0r0HyLr1myvFxV6rSO5MTW+PMrr8UFDd8kOv6ukbbQnH51jdWUWv+3VgBwJ+PPnG/t0JOhgPBiWpuoqsFOhm+rdxvYciFI4dpOCw6hijWbJKQPbbLUXfVAZca/JUIa2LWfTA0W0pGeiNAv7lhw8tJwKHT0ltBfmfL6fLIiAK0ZrFYehRZ28gasXwCTYHmgWbyFWLfc+qA0I4ngTjSR2mbm6kGOQnYtkUmswKjC/HnpBbCtpLceFdZ5yLBSZmx16gC+5dwJyL/R4DkBFmu7ldBImz6QctT+7cG59IOTuSWVgV94TqPH9UJfi3pJu6uZ0Hw07TJaWd+cpGF8v7tnH07PdmPj0B4S3Q9lhiH3QTQCnGum5JkTMfNhR8xyP6UdpLGyBLHfVBgLuR92UVcWSKJwUqU5JyUAVoGiNUXjXa9mIRnzetTDwOCjZLTLIS+guzZw2X08c0UlW8Ey8lqO9156PMEVND4++UnhIF9hJLd+owic92NNrJ6GLIOU91HaN7tJe/8jjmDVel7xKtF6TBHcCEFxyk88333zdAROa6nKx8equP49DVq1vWG4Z2MHtBLJPyNyWOSW+SH98CDK0/EKCszVm7Dk33UIFx8WwtmBeS+cnvrVOeildnBJobKY9pPg22EMCLNuea69xXnCao1D/FtB9ktLLVjJjOWZlRLEU6SmjxrbVVbz6EPSHclrxRIDvXEx4UHBXr/UhCVPXW+lrRifVHliis/74U3f7HKMdEngvArnqxCxEddVrf/tuv3Fg0QYyhInWEbLqKmDUR+y2ZAaZdMdfvHuTwLT2+KCKbnlT74nbZ3r4xbTmZ2PDq4sVuDHSDBdVLLRnFhJ9LAYT9mOXtOUWm6gFyG1gJRcwmUQk7dwi7uBns8UnOssKiC82MDkXdri0fPiZONYc9QmHovryZfIHMXFKkCUUYjWGOXvO+hJnR3+ptiuxBtgbtfTYMH0cenOCMt4MxPr7naFjg92qFYI7+TR/3EWW5Lx9OZNO8wjYVS/NUnRXdpgWfX8HkFqMd/xFTR9lXVeErPJlQcXUWVYQf7MVrIMnUA/OCvXodgtHDN6+zWlyedqJnZNhBqLo+wvgZnx7RsyM5WaVsieqZp592pSV3q0TMebWVJOYMntwF4QeQYfNTOZIcSMVmR/5I8D5hJJaThVLBpVVG92xXyCQlBDQg3jSmavTsT51g0PFDb46/33H/Kd/1ZhKWRmPZC4iqUa8Zae2yXEHZQVCq2ALbo6TJT6ZM0pV+MvCV+4vPb4xRwnzbfGepuDjx5SGUNYyrSIkhKtbkSJanw7Mr0JwfTpR1bH3O0G3emlb5qsOK6bLdrHjm+PHG9xY4z6d1vLAH4cEqIkL47Ojc04lR/9GE0RsfWJdzoQgXTBxcPcYYAPbKdg+Bs02BT1Z8dSJwpF+vtqSV6ibbRKF1ks1TUpOVvIhU+qjwOQCQW3cQcbB3jyD2ZSejQr1xnvr68b5L/s35nM64VYMK++PJjDKP3BbVG/5pZdD2naS7XgNoz9vFh/5XSduMOIeJxNU4QBc48xSnqy4jNX26lpT9OFb0lXH7EPqUC/wz0OcmINkaHV2BvUj9+PHFAUqk7BgmcOXicDU+20mUcd9e5mZURfDgMm5t1Qq87coFlx5ZUApTEeWl8NhGATNwBGEh3SC+w0jFdJMAdjO8Cjtpy3vfz+AylomlKDHg9RfYBG4YIBjIMMDRk71B32815JAyaCJ/BP3hFQ3NpN59aNjWpLInKHQyAkF/F2NkFSXmYoroADzQkLimK5RM4oykhPnI3ZGpeBLpSR9+3n9RMYKG/IfpTzn0YQ/GtwWYYXq76EZeA5Kr/nQNxXcApyF6MOjEmXCbDQIjIV7ZgsPWrr0VNhGoupxGpDOr6seN2j1xRhl1V0XM8vh2U3byLNZ004opXvRB3zpr17xdZVThraLDqPBas80SP4K2b1T18d8P6S51VCAt5Acg47v0NfkZydW+R1QepySHtj0klS80IkexyxvAbJWFekQ4VuDsJaMIfxAbamIIaLejf2wuD+BI0bfyTVG20mfVH7cBVA2+DkHTD4S3n0pKU76dq/yWAz6sMJU2g2axWzFe77ggcLODzPPpF+S3oAtrM0VfUpzPa/RGa7xOktqNEB5NflaOl+6V3Tdh3hLb+oK2GKmiNiwsGvjoxHJQmffZWCxJqFUW01NbWA+X3wLM6/jXlJt4MD/Qhu9IW7WCkOzpC57scDLXqp4aT7E64LqHUO4eIohHW2V3lnys3/Hb9SHSIR4MnTsOMPFvDFphHDn60tyuhtIOt4+CJjqjC3TduRTfs6pr3yFgs35gWoZc8D+b+y9VHE4Sy1rF+Re/2Ht3iMLAaXVvVuK+/97rRSrsOjNLYxiuH995Gvcz1nbiqYvjcc/8CF6dTdjD6aqO5GxW4tEke7IdZiuYFn/J+KMsoKNtMahIA3jVi1ekY5Q2MFFmpxl2zg6XEAjyjEfPh40CW756HlAf9eUpya1bEezKq4Aoy3f9Y1Nr+GzvULHd/F2yqSvByZZOGMGDenNHI5sq2VyJ5itn0w8R0peB1RpUlGLD8tl8uN7RHOFmbNs2E42yxKGDeBpeRxJtVKPreyiE9oZVxU/8mOwyXobPUG0OK/k9WYQ94ymuEEUBplp4smzppyA95Gz/KYENfVthoDno3Q6eEarFgyNORgmnUR/1CV5vnpc0/XoNIrT+hIoBdsvpWUT1sla9j09GIpDOG8Mhb6IxdWOMwmn73+3KUwxagaXmN9xBmCaJSrcrL8hmO4BFyQvX4Vqyz00GA+gWauzYXWZggloHPi1cZ01xvm6u/4JdQwbFcj8a1WzELDXYD9zo6cNSMqfkU5aZLUcX+CHe1N8wf0SyN7al0uJbFDW0O3jqKezWVSQNHWtMhCS6lCZtKD2BbCbC0/Ra1LWSg7jQfW/0T53Bw1m3kgmTDuYbt9FNLBqUh+xdiZ9fxny+YPshoIVm6qClJAxJS4Z61Vh46jG/eUUgETow3UDtb54pEaZUIHQMPh/r6xqPzRzs2Ookqxp07x7dRbHOzIl1KfVqT/xsT0J+MtmFbuvt6sMSqqeXjR0lCwBQds247D1MGpLhqp9UQrvd4rSeU1HKoe0RKyWKAUsEfARP39jmKC0FzBGR/af4mXbx6Kge3h6WAyBkAFZsIZ5hnIp/lk0vz0kf+nGapfZrLQ5GWZLH5Wg4Jr2aXq/syaMNH405/eVvaAHpM/qnt1vuUTJIMlHAECupdmDvd5EgVfoMVq2uU4dL1foHJKfHy9idcJPtxQ/WQsMSNrHHqdSRU6SaX8sjBAj2zVS9Ls5CsjfXIht8vkMqRSFwoyQTa42T5OawYW+YZfHM+JVdARVMJmOm+2P6v/ahvKXLjFgA0KSmGBvY0ao/wrlHQHpgBc5QCiKI9I0wb+iRypoi2YlIiSyRJQ7cOlxjWk85/esXFXg6ifvDH6kxrfsVTGfoBPFXxbf5CWYPLCUIOujIJ1Mmv16zzGvBnwiJZ/cxpfDRQx95MwgxiXIGg0LAyDKfIMc3PwhY2LXDy9PmPC9PmNv903OYzDsYOW43hfQ4c7rJML29Ted+ogSGFPCO+s2fJclxr3MfhO2KQLZQY2C26hWgL7VMp9oUdp9JZxilKBvv4jNVJVKlQ15q02UIA2IdIkbOX6m7BnoWK7WocMZCoL6PuVlLKXMXjvzt+NkOdcGYgS2hTm8NAI4wM1ZCpkrn6VpOmOmGs2g1VEPOMkQ8CwzRi42BFUhxGQu0HhqpGHNaPV7jwCYU1HVLsXJ37jhSwcAF5eJR6vyRerRi/Yn/rANIypi298KocQcsMSJ9DR7Z/xol3qIol0dpfM+Lc8ocNHYBHOjO6hKi72fDtqN8BpPJfOB02NsS9bnIgTkASmHktfFe2SADU0XNivZ9HAeEbZXXT+QhUIHN+p9WK7IwPVi527W5XFGmwP1Jx1tzNr9diXHbEfXIQXPvrxPzsa/APFyIRaFQAv/b859KwSjdXgmXsQlosXg9LzCH+f905ceWosPzqovkEHPU9QsCx+vQf187JjGc6u11ieSxgfZw3RjYP7Zdwdip3rIWxIGzUEOo9JtqkxF8mX2RSVMiJ9TIHSbeLbGqP9HMCebrsi6Ir0eW5PS8wtwG6IbkEQ7273hbmxxT+cRBjK5IFotBFJ7DWyLWAGrVqIVSMRHlCERASk/Qka0vgkE6qoXsIFf82A4Ryrr+erpguMNwcmNLBzdv4AZWN2oykNtUgPyiuiHksD84PKAVTb5gFpP+XNrgwo1bb6rJ+bZY7h700j1r/eYMwrcIGKeQf2ycyPcmw8/Qr7bTFGFt6d45gUFr7UXNYYVvRBToOvgPM3HNcTjFxaHzW6R8dKuPdDynl20YUXn758LGoBxk3Ya47Lg2DZS2KN/7f0tiFicAzq03KlCAY5x3A/pZZcMMgUN6ELp2rZG6saIUq/66WjBiQpZ280tdGhfLrNyVPgFAXUvYBNtlMMyJ5Yxx6QpeP3Hw8bpLdqCtWeiDB1piUtUvbpyPuvKmD58DlCG8YSKH1ZQ7zYq+u+uprZYIibOmsAc6jDfv/49tzCEb1jlvvdn3hB9uEqfSakWZaxFMn5dbP8Uo6IgnBCvbaVK7oBZO/5aSk948ti9oFqOu1a7I9B16qAPM/fJQBLZebCxxh5bx8MDtLosLuRzb3CxKQY3DAGRpeXMRnhVZR2WXnm3vvx6aakqtrxt08WV0aMFxQwsEwzaWUP+HHUk7WSRq4dIqcAzYUOo3uRxhsX78mx7prK523cUrEb5hVa3gt9NBobH+m/kS+1BMoPYfourmz97dOiVGaJMxwvgzaxAKYZqg14TAE54P+q3bVn457OI59HZn05kIhHktvXWyebVUkz+OskIWxj6u4YLug6hto81g+EnZfb/WcUiF9J19e1nsHdhWz4Qcmc2wsbG0hHiI1ccrnqPBkl9Y8CwpPrM4vfocLPwQEXW4Smq8QM2ypPxf1LQM8qDNkiNJ+M9v110EJpMAQ66RPLR0cS35ijvQ87JgY3QVGpgcJqLJV67DJV+LNoCgPy3SeeeQkRwmS6VgzhAczGujReDtN1WkMk1zKSsdnt+c850yahSYYGBQ1rbueF+v5Beh0E7/NJH64lDJrwa31vgRTg5DYV7QW0Cl2kCj3S9dWPSp78eNGXmxSjnQCupRN7BumXdj9dqqA2iEoTroi1KiprykNGDUb2vNUP3Z2HXffPibY+DnthjDbn23xMZUaVjw1SPbx7mIULJ</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Just can be seen by yaya.
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="video captioning" scheme="http://yoursite.com/categories/cross-modal/video-captioning/"/>
    
    
      <category term="cross-modal,video captioning" scheme="http://yoursite.com/tags/cross-modal-video-captioning/"/>
    
  </entry>
  
  <entry>
    <title>多模态人工智能</title>
    <link href="http://yoursite.com/2021/03/12/%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BA%A4%E4%BA%92%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    <id>http://yoursite.com/2021/03/12/多模态交互人工智能/</id>
    <published>2021-03-12T10:11:52.000Z</published>
    <updated>2021-03-12T12:22:43.491Z</updated>
    
    <content type="html"><![CDATA[<p>多模态：视觉，语音，自然语言</p><p><img src="https://i.loli.net/2021/03/12/8ObjKzRVd4UXgS3.png" alt="image-20210312202150477"></p><p><img src="https://i.loli.net/2021/03/12/IqFHGuL6ZYOKwXb.png" alt="image-20210312202209438"></p><p><img src="https://i.loli.net/2021/03/12/CsF8TR3m9UlS54N.png" alt="image-20210312202229192"></p><p><img src="https://i.loli.net/2021/03/12/HbPD8yaB3GU7IAk.png" alt="image-20210312202108780"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;多模态：视觉，语音，自然语言&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/12/8ObjKzRVd4UXgS3.png&quot; alt=&quot;image-20210312202150477&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https:
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
    
      <category term="cross-modal" scheme="http://yoursite.com/tags/cross-modal/"/>
    
  </entry>
  
  <entry>
    <title>Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering</title>
    <link href="http://yoursite.com/2021/03/12/Learning-to-Contrast-the-Counterfactual-Samples-for-Robust-Visual-Question-Answering/"/>
    <id>http://yoursite.com/2021/03/12/Learning-to-Contrast-the-Counterfactual-Samples-for-Robust-Visual-Question-Answering/</id>
    <published>2021-03-12T09:43:10.000Z</published>
    <updated>2021-03-12T10:05:32.371Z</updated>
    
    <content type="html"><![CDATA[<p>转自：<a href="https://blog.csdn.net/weixin_45347379/article/details/112182143" target="_blank" rel="noopener">https://blog.csdn.net/weixin_45347379/article/details/112182143</a></p><p>学习对比反事实样本，以实现稳健的视觉问答<br>Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering<br>在阅读本文之前，一定要阅读论文：Counterfactual Samples Synthesizing for Robust Visual Question Answering（简称CSS）</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p><img src="https://i.loli.net/2021/03/12/gODk8QFCNWaUsVP.png" alt="image-20210312175656070"></p><p>文章的方法主要包括三个部分：（1）一个基本的VQA模型。（2）一个事实和反事实样本合成（CSS）模块。（3）一个对比学习（CL）目标。</p><h4 id="第一部分和第二部分"><a href="#第一部分和第二部分" class="headerlink" title="第一部分和第二部分"></a><strong>第一部分和第二部分</strong></h4><p>属于CSS已经实现的，主要作用在于：</p><p>（1）并通过多分类的方法预测答案，并产生图中右上方基本VQAloss。</p><p><img src="https://i.loli.net/2021/03/12/z3Q52bActwqMhov.png" alt="在这里插入图片描述"></p><p>（2）得到（I, I+, I-）和（Q, Q+, Q-），</p><p><img src="https://i.loli.net/2021/03/12/din9DctNLV1EORo.png" alt="在这里插入图片描述"></p><h4 id="第三部分"><a href="#第三部分" class="headerlink" title="第三部分"></a><strong>第三部分</strong></h4><p>以（I, I+, I-）为例，将（I, I+, I-）和Q喂给VQA模型，分别产生原始样本的嵌入mm（V, Q）作为anchor（a），事实样本的嵌入mm(V+, Q)作为positive（p），反事实样本嵌入mm(V-, Q)作为negati（n）<br>利用余弦相似度作为评分函数，对正样本输出高值，对负样本输出低值，公式如下：</p><p><img src="https://i.loli.net/2021/03/12/XIjKWu7szqi3A4w.png" alt="在这里插入图片描述"></p><p>同样的方法得到anchor和negative之间的评分s(a, n), 这就相当于图中展示的，拉近原始图像与事实区域图像的关系，推远原始图像与反事实区域的距离。<br>对比损失定义为：（这就是图片下方得到的Contrastive loss）</p><p><img src="https://i.loli.net/2021/03/12/CY4OJ7PZmD9Eaud.png" alt="在这里插入图片描述"></p><p>最后，这种对比损失与基础分类损失的加权总和弥补了整体损失：</p><p><img src="https://i.loli.net/2021/03/12/8GL3BxlSEpAg951.png" alt="在这里插入图片描述"></p><p>虽然文章说，<strong style="color:red;">这种方法能够使模型学习他们之间的关系，并从更有因果关系的方面预测正确答案。</strong>但是，个人感觉如果仅仅使以上方法，并不能从理论上提高模型的能力。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p><img src="https://i.loli.net/2021/03/12/wAmbOSxRU97dN12.png" alt="在这里插入图片描述"></p><h3 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h3><ul><li>看了本文博客之后，没有看原文，个人任务这种方法有限，</li><li>可能模型的设计上，是有新意的，使用对比学习来增强VQA模型的性能，但是往往自己做的时候会收效甚微</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转自：&lt;a href=&quot;https://blog.csdn.net/weixin_45347379/article/details/112182143&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/weixin_
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="VQA" scheme="http://yoursite.com/categories/cross-modal/VQA/"/>
    
    
      <category term="cross-modal,VQA" scheme="http://yoursite.com/tags/cross-modal-VQA/"/>
    
  </entry>
  
  <entry>
    <title>Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering</title>
    <link href="http://yoursite.com/2021/03/12/Semantic-Equivalent-Adversarial-Data-Augmentation-for-Visual-Question-Answering/"/>
    <id>http://yoursite.com/2021/03/12/Semantic-Equivalent-Adversarial-Data-Augmentation-for-Visual-Question-Answering/</id>
    <published>2021-03-12T03:27:29.000Z</published>
    <updated>2021-03-12T09:31:48.943Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>受到深度学习的快速发展，VQA 近年来取得了非常成功的进展。数据增强是深度学习中的一个有用的技巧，但是，目前很少有工作关注于VQA任务的数据增强。</p><p>对于image side: 一些简单的数据增强操作不能直接应用到VQA这一场景下，比如，rotation and flipping 等操作，都可能导致<image, question, answer> 这一结构的正确性遭到破坏。</image,></p><p>对于text side (eg: questions) , it is challenging to come up with <strong>generalized rules for language transformation.</strong> 另外，有一类任务是Visual Question Generation，根据image和 answer来生成问题，但是生成的问题常常是有语法错误的，而且，他们在同一个目标数据集上进行学习，生成的数据与原始数据的分布是一致的，因此，<strong>若使用这种方案来做数据扩充，难以解决过拟合问题</strong>(通常训练数据和测试数据不是同一个分布)。</p><p>在本文中，不直接对image或者是question进行操作，而是对images 和 questions生成对抗样本作为数据增强。增强的样本不会改变image的原始语义，也不会改变questions中的semantic meaning。对抗性示例是经过<strong>策略</strong>修改的样本，可以成功地欺骗深层模型以做出不正确的预测。这种修改是难以察觉的，<strong>它在使对抗性示例的基础分布远离原始数据的同时保持了数据的语义。</strong>本文是第一个同时对image 和 text进行数据扩充的方法（已有的方法只是单独对一方面进行数据扩充）。</p><p>进而，使用本文方法产生的<strong>数据增强样本</strong>和<strong>对抗训练</strong>来训练经典的VQA model (BUTD) 。</p><p>实验结果证明，不仅可以提高 VQAv2的整体性能，而且相比于baseline还可以有效抵抗对抗攻击。</p><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p><img src="https://i.loli.net/2021/03/12/rmyqUFXQewT2PBK.png" alt="image-20210312165449352" style="zoom:50%;"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="何时加入对抗样本"><a href="#何时加入对抗样本" class="headerlink" title="何时加入对抗样本"></a>何时加入对抗样本</h4><ul><li><p>本文发现，将干净样本和对抗样本进行混合，然后<strong>从头到尾</strong>的训练，这种方案不会在干净样本上收敛。因此本文只在特定的训练时期对样本进行混合，最后使用干净样本进行微调。</p><p>本文实验中max-epoch=25.</p><p><img src="https://i.loli.net/2021/03/12/YOblV6WT4rtMkSf.png" alt="image-20210312171853940" style="zoom: 50%;"></p><p>本文的解释：与干净样本相比，对抗样本与其有不同的分布。如果把提升模型在VQA任务上的性能作为我们的主要目标，那么模型在干净样本上的拟合能力需要<strong>在结束</strong>的时候to be retrieved。而<strong>在开始</strong>时，模型需要warm up，此时不适合加入对抗样本。因此在中间阶段加入融合对抗样本的训练。</p></li><li><p>实验证明本文提出的方法不仅可以提高在干净样本上的VQA任务的性能，还能提高<strong>在对抗样本上的鲁棒性</strong>。</p></li></ul><h4 id="相比于baseline还可以有效抵抗对抗攻击"><a href="#相比于baseline还可以有效抵抗对抗攻击" class="headerlink" title="相比于baseline还可以有效抵抗对抗攻击"></a>相比于baseline还可以有效抵抗对抗攻击</h4><p><img src="https://i.loli.net/2021/03/12/np4eUgXwkz2rK5M.png" alt="image-20210312172242341" style="zoom:50%;"></p><h3 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h3><ul><li><strong>何时加入对抗样本</strong> 这个实验告诉我们：一般情况，我们提出一种数据增强方案，通常会从头到尾的使用，但是未必是好的。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h3&gt;&lt;p&gt;受到深度学习的快速发展，VQA 近年来取得了非常成功的进展。数据增强是深度学
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="VQA" scheme="http://yoursite.com/categories/cross-modal/VQA/"/>
    
    
      <category term="cross-modal,VQA" scheme="http://yoursite.com/tags/cross-modal-VQA/"/>
    
  </entry>
  
  <entry>
    <title>[Behind the Scene] Revealing the Secrets of Pre-trained Vision-and-Language Models</title>
    <link href="http://yoursite.com/2021/03/05/Behind-the-Scene-Revealing-the-Secrets-of-Pre-trained-Vision-and-Language-Models/"/>
    <id>http://yoursite.com/2021/03/05/Behind-the-Scene-Revealing-the-Secrets-of-Pre-trained-Vision-and-Language-Models/</id>
    <published>2021-03-05T09:34:24.000Z</published>
    <updated>2021-03-05T10:01:56.309Z</updated>
    
    <content type="html"><![CDATA[<h3 id="本文研究的任务"><a href="#本文研究的任务" class="headerlink" title="本文研究的任务"></a>本文研究的任务</h3><p>最近Transformer-based 大规模预训练模型推动了 多模态任务的发展，比如，ViL-BERT，LXMERT and UNITER。然而，对于使它们取得成功的<strong>内部机制</strong>知之甚少。为了揭示内部机制，本文提出了VALUE（Vision-And-Language Understanding Evaluation），一组精心设计的<strong>探测任务</strong>（probing task, eg: Visual Coreference Resolution, Visual Relation Detection），可推广到标准的预训练V + L模型， 破译多模式预训练的内部运作方式（例如，在各个attention heads 中获得的隐性知识，通过上下文化多模式嵌入学习的 inherent cross-modal alignment）。</p><h3 id="本文的实验发现"><a href="#本文的实验发现" class="headerlink" title="本文的实验发现"></a>本文的实验发现</h3><p>经由这些探测任务，通过对每个原型模型体系结构的广泛分析，我们的主要观察结果是：（i）预训练的模型在推理过程中表现出对文本而不是图像的关注。 （ii）存在专门为捕获cross-modal interactions 而设计的 a subset of attetion heads（iii）在多个预训练模型中学习的注意力矩阵显示出图像区域和文本单词之间的<strong>潜在对齐</strong>，表现出<strong>一致的模式</strong>。 （iv）绘制的注意力模式(attention patern)揭示了图像区域之间的视觉可解释的关系。 （v）纯粹的语言知识也被有效地编码在注意力集中。 这些宝贵的见解可指导未来的工作，以设计更好的模型架构和多模式预训练的目标。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;本文研究的任务&quot;&gt;&lt;a href=&quot;#本文研究的任务&quot; class=&quot;headerlink&quot; title=&quot;本文研究的任务&quot;&gt;&lt;/a&gt;本文研究的任务&lt;/h3&gt;&lt;p&gt;最近Transformer-based 大规模预训练模型推动了 多模态任务的发展，比如，ViL-BE
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[COCO-LM] Correcting and Contrasting Text Sequences for Language Model Pretraining</title>
    <link href="http://yoursite.com/2021/03/04/COCO-LM-Correcting-and-Contrasting-Text-Sequences-for-Language-Model-Pretraining/"/>
    <id>http://yoursite.com/2021/03/04/COCO-LM-Correcting-and-Contrasting-Text-Sequences-for-Language-Model-Pretraining/</id>
    <published>2021-03-04T02:59:16.000Z</published>
    <updated>2021-03-04T04:08:45.357Z</updated>
    
    <content type="html"><![CDATA[<p>转自：<a href="https://zhuanlan.zhihu.com/p/353624306" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/353624306</a></p><p>该篇文章2021年2月16日上传，提出了一种新的预训练模型的框架，个人认为<strong>COCO-LM结合了许多当下比较新进的思想，在后bert时代，一定程度上突破了对BERT模型传统的预训练方法</strong>。</p><p>We present COCO-LM, a new self-supervised learning framework that pretrains Language Models by COrrecting challenging errors and COntrasting text sequences. COCO-LM employs an auxiliary language model to mask-and-predict tokens in original text sequences. It creates more challenging pretraining inputs, where noises are sampled based on their likelihood in the auxiliary language model. COCO-LM then pretrains with two tasks: <strong style="color:blue;">The first task, corrective language modeling</strong>, learns to correct the auxiliary model’s corruptions by recovering the original tokens. <strong style="color:blue;">The second task, sequence contrastive learning</strong>, ensures that the language model generates sequence representations that are invariant to noises and transformations. In our experiments on the GLUE and SQuAD benchmarks, COCO-LM outperforms recent pretraining approaches in various pretraining settings and few-shot evaluations, with higher pretraining efficiency. Our analyses reveal that COCO-LM’s advantages come from its challenging training signals, more contextualized token representations, and regularized sequence representations.</p><p><img src="https://i.loli.net/2021/03/04/xOA857rdWJktsEY.png" alt="FireShot Capture 018 -  - arxiv.org"></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>在标准语言模型预训练框架内，可以观察到PLM在下游任务上的the empirical performance 仅随着参数大小和预训练成本的指数增长而线性提高，<strong>这是不可持续的</strong>，因为PLM已达到数万亿个参数。</p><p>最近的研究揭示了现有预训练框架的某些固有局限性，这些局限性可能导致这种亚线性效率（sublinear efficiency）。【1】一个挑战是，<strong>使用随机更改的文本</strong>（<em>例如</em>，randomly masked tokens）进行预训练会<strong>产生许多非信息性信号</strong>，经过一定程度的预训练后它们不再有用。【2】另外一个挑战是，在 token level 进行预训练不会在 sequence level 上显式学习语言语义，并且在预训练过程中，<strong>Transformers可能无法有效地推广到 higher level 的语义 。</strong></p><p>在本文中，我们旨在通过一个<strong>新的自我监督学习框架</strong>COCO-LM来克服这些限制。该框架通过使用 more challenging noises 来 COrrecting and COntrasting text sequences，进而预训练语言模型。</p><p>【1】leverages an auxiliary language model，to corrupt text sequences by <strong>sampling more contextually plausible noises</strong> from its masked language modeling (MLM) probability. COCO-LM revives a language modeling task, corrective language modeling (CLM), which pretrains the Transformer to <strong>not only detect the challenging noises in the corrupted texts, but also correct them via a multi-task setting.</strong></p><p>【2】To improve the learning of sequence level semantics, COCOLM introduces a sequence level pretraining task, sequence contrastive learning (SCL), that uses contrastive learning to enforce the pretraining model to <strong>align the corrupted text sequence and its cropped original sequence close</strong> in the representation space, while away from other random sequences.</p><h3 id="COCO-LM框架延续了ELECTRA预训练模型的思想"><a href="#COCO-LM框架延续了ELECTRA预训练模型的思想" class="headerlink" title="COCO-LM框架延续了ELECTRA预训练模型的思想"></a>COCO-LM框架延续了ELECTRA预训练模型的思想</h3><p>ELECTRA预训练模型主要应用了GAN对抗神经网络的思想，不了解的小伙伴们可以参考一些其他资料，这里我简单说一下我的理解。</p><p>GAN对抗神经网络在CV领域上应用比较成熟，在CV的应用上GAN主要包括两个神经网络模型：一个是生成式模型G，一个是判别式模型D。生成式模型的作用是通过随机噪声生成和原始样本相似的数据（注意这里是通过随机噪声），判别式模型的作用是判断给定的实例是真实实例还是人为伪造的（也就是生成式模型所生成的）。那么这里就包含了对抗的思想，即生成式模型的目的是能够生成欺骗判别式模型的实例，判别式模型的目的是判别给定的实例是否是人为伪造的。</p><p>ELECTRA当中引用了这样的“对抗”思想，将判别式模型引入到了模型的预训练之中。像BERT、ROBERTA、XLNET等等预训练模型都属于生成式模型，在输入上用 [MASK] 遮蔽掉部分 tokens，再训练一个模型以重建出原始的 tokens。而ELECTRA预训练模型使用了判别式模型，其效果也出乎意料的好。</p><blockquote><p>ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</p></blockquote><p>ELECTRA模型的主要思想也是包括了两个神经网络模型：一个生成式模型G，一个生成式模型D。生成式模型G是MLM（Masked Language Model）模型，给定一个真实样例（GAN的生成式模型给定的是随机噪声），用 [MASK] 遮蔽掉部分 tokens，生成替换的tokens；判别式模型D判断输入中每个 token 是否是由生成器生成。其过程如图所示：</p><p><img src="https://i.loli.net/2021/03/04/V7kIJGSo3L1m5ua.png" alt="image-20210304111201636" style="zoom:50%;"></p><p>通过实验表明这种新的预训练任务比 MLM 更高效，该任务定义于全部的输入 tokens，而非仅仅被遮蔽掉的那一部分小小的输入子集。</p><p>在COCO-LM模型中<strong>Corrective Language Modeling (CLM)</strong>也延续了这样的思想。</p><h3 id="COCO-LM模型引入了对比学习的思想"><a href="#COCO-LM模型引入了对比学习的思想" class="headerlink" title="COCO-LM模型引入了对比学习的思想"></a>COCO-LM模型引入了对比学习的思想</h3><p>我认为是非常非常棒的创新点。最近刚好再看对比学习的相关paper，更多的是在CV领域中使用了对比学习，而COCO-LM刚好将对比学习带入到了NLP领域中。</p><p>什么是对比学习呢？</p><p>对比学习是一种自监督的学习方法。其主要思想我的理解是，把正样本距离拉近，正样本与负样本距离拉远。对比学习的例子如下：</p><ul><li>给每个例子绘制两个独立的增强函数</li><li>使用两种增强机制，为每个示例生成两个互相关联的视图</li><li>让相关视图互相吸引，同时排斥其他示例</li></ul><p><img src="https://i.loli.net/2021/03/04/A3wEY1gPnTxIOaQ.jpg" alt="SimCLR论文解读- 知乎" style="zoom:33%;"></p><p>如上图，（Z1，Z2），（Z3，Z4）…（Z2n-1，Z2n）这些可以看作正例对，而Z1可以与除Z1、Z2的任何实例组成负例对，如（Z1，Z3）（Z1，Z4）等等。那么这样一个实例X，在一个大小为N的batch里便可以产生一个正例，以及N-1个负例，那么这个 loss 就可以看做是一个 N 分类问题，实际上就是一个交叉熵，由此可以进行网络模型的训练。</p><p>以上是我认为COCO-LM框架比较出色的地方，框架的一些细节还需要进一步的理解，之后会进一步的更新，欢迎知乎各位巨佬一起讨论~</p><h3 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h3><ul><li><p>在预训练任务中，引入了对抗扰动，且通过对比学习的思想来训练。</p></li><li><p>这种扰动+对比学习的思想，在vision-text pretraining model 中是否有使用？</p></li><li>本篇的idea 是如何来的，motivation 是什么？</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/353624306&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zhuanlan.zhihu.com/p/353624306&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;该篇文章
      
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Neural Machine Translation with universal Visual Representation</title>
    <link href="http://yoursite.com/2021/03/03/Neural-Machine-Translation-with-universal-Visual-Representation/"/>
    <id>http://yoursite.com/2021/03/03/Neural-Machine-Translation-with-universal-Visual-Representation/</id>
    <published>2021-03-03T12:14:27.000Z</published>
    <updated>2021-03-04T02:52:08.225Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>为了降低Multi-modal NMT对有图像标注的翻译数据集的依赖，本文提出通过建立Topic-image Lookup Table的方式更高效地利用已有图像文本数据，并且在训练和测试NMT的时候通过Image Retrieval的方式获得图像信息，从而在更大规模的数据上训练Multi-modal NMT。</p><p>通过Retrieval的方式来扩充数据的工作其实有很多，比如这篇：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1904.02331" target="_blank" rel="noopener">Extract and Edit: An Alternative to Back-Translation for Unsupervised Neural Machine Translation</a>。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>长期以来，机器翻译都只涉及到文本之间的转换，但实际上，人的感知功能可以是“多模态”的。</p><p><strong>本文提出一种通用的视觉表征，将图片信息融合到机器翻译模型中。</strong></p><p>使用这种视觉知识融合方法，<strong>不需要额外的<strong style="color:red;">双语-图片</strong>标注数据，模型就能够在多个数据集上取得显著的效果提升。</strong></p><h3 id="多模态与机器翻译"><a href="#多模态与机器翻译" class="headerlink" title="多模态与机器翻译"></a><strong>多模态与机器翻译</strong></h3><p>机器翻译是两种语言间的转换，比如“A dog is playing in the snow”翻译为中文就是“小狗在雪地里玩耍”。</p><p>但人类理解世界不只是用文字，还有视觉、听觉等感知能力；并且<strong style="color:blue;">翻译的过程需要保持“语义”不变</strong>。比如下面的图：</p><p><img src="https://i.loli.net/2021/03/03/31QcdLfykOoiCEX.jpg" alt="img" style="zoom:50%;"></p><p>讲中文的人会说“小狗在雪地里玩耍”，而讲英文的人会说“A dog is playing in the snow”。也就是说，人们对客观世界的本质认知是相同的，只是“方法”不同，体现在语言上，就是语法上的差异。</p><p>为此，我们可以假设<strong style="color:blue;">在机器翻译模型中，融入这种“客观的世界知识”，比如把图片信息加入，以此期望增强翻译能力。</strong>同时考虑文本和图片，这就是一种多模态。</p><p>然而，过去的翻译-图片研究大都需要大量的双语-图片标注数据，这在数据上成为一个研究的瓶颈。本文针对这种情况，<strong>提出“通用的视觉表示”，<strong style="color:red;">仅用单语-图片标注数据</strong>，就能显著提高机器翻译的效果。</strong></p><p>本文的方法<strong>在数据集EN-RO，EN-DE，EN-FR上均有约一个BLEU值的提高</strong>，这说明了本方法的有效性。</p><h3 id="本文贡献"><a href="#本文贡献" class="headerlink" title="本文贡献"></a>本文贡献</h3><ul><li>提出一种通用的视觉表示方法，无需双语-图片标注语料；</li><li>该方法<strong>可以在只有文本的数据集上使用</strong>；</li><li>实验证明了该方法效果提升的一致性。</li></ul><h3 id="通用视觉表示"><a href="#通用视觉表示" class="headerlink" title="通用视觉表示"></a><strong>通用视觉表示</strong></h3><p>首先我们有一个单语-图片数据集 $\mathcal{S}=\{X, E\}$，也就是，其中的每条数据都是一张图片 $e$ 和对图片的描述 $X_{e}=\left\{x_{1}, \cdots, x_{I}\right\},$ 把其中的停用词去掉后得到了 $X_{e}^{\prime}=\left\{x_{1}^{\prime}, \cdots, x_{J}^{\prime}\right\}$ 。</p><p>然后, 对 $X_{e}^{\prime}$ 中的每个词 $x_{j},$ 计算它在整个数据集 $\mathcal{S}$ 中的TF-IDF值， 然后取 $X_{e}^{\prime}$ 中TF-IDF值最大的前 $w$个词作为这个图片 $e$ 的主题词 $T_{e}$, 也就是和图片最相关的 $w$ 个词。</p><p>这样一来，<strong>每个图片e都有它主题词</strong> $T_{e},$ 同时，<strong>每个词都有可能同时是多个图片的主题词</strong>。我们可以把这看成一个 “主题词-图片” 查询表，输入一个词 $t$ ，就可以在表中查询以 $t$ 为主题的所有图片 $E_{t}=\left\{e_{1}, \cdots, e_{n}\right\}$。</p><p>那么，现在输入一个句子，我们就可以按照同样的步骤：</p><p>1.去除停用词；</p><p>2.计算每个词的TF-IDF；</p><p>3.取前$w$个TF-IDF最高的词；</p><p>4.在查询表中找到所有对应的图片；</p><p>5.按照出现次数的多少排序，取出前$m$个出现次数最多的图片（因为多个词可能对应同一个图片），得到集合 $G$</p><p>现在，这个图片集合 $G$ 就可以认为是和输入句子对应的视觉信息，可以用它去增强翻译效果了。下图是流程示意图：</p><p><img src="https://i.loli.net/2021/03/03/wMeWCU7jfD4NqIO.png" alt="image-20210303203731211" style="zoom: 50%;"></p><h3 id="在机器翻译中融合图片信息"><a href="#在机器翻译中融合图片信息" class="headerlink" title="在机器翻译中融合图片信息"></a><strong>在机器翻译中融合图片信息</strong></h3><p>为了把图片融合进去，我们首先用一个预训练的ResNet提取图片集$G$ 的表示，然后计算 $\bar{H}=$ Self-Attention $\left(H^{L}, K_{G}, V_{G}\right)$ 与 $H=H^{L}+\lambda \bar{H}$<br>这里, $H^{L}$ 是Transformer Encoder的最后一层, $K_{G}, V_{G}$ 是用ResNet得到的图片集的表示, $\lambda$ 使用<br>sigmoid 计算。<br>在Decoder端，直接把 $H$ 送入即可。融合步骤如下所示：</p><p><img src="https://i.loli.net/2021/03/03/SWYB4lDXt7ysVrO.png" alt="image-20210303204216912" style="zoom:50%;"></p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a><strong>实验</strong></h3><p>我们在三个数据集上进行实验：WMT16 En-RO, WMT14 EN-DE和WMT14 EN-FR。这三个数据集大小从小到大增加，从而在不同大小的数据集上都能验证该方法。</p><p>下表是在这三个数据集上的结果，++表示显著更优。</p><p>可以看到，和基线模型(Trans.(base/big))相比，本文的方法(+VR)在三个数据集上都能得到显著的提升，平均提升约一个BLEU值。同时，只引入了很少的参数量，这就不会使训练时间几乎不会增加。</p><p><img src="https://i.loli.net/2021/03/03/F8z9SReVPkuNdov.png" alt="image-20210303205316435" style="zoom:33%;"></p><p>下表是在数据集Multi30K上的结果，这是一个多模态数据集。可以看到，即使在多模态设置下，本文方法依旧能够取得显著结果。</p><p><img src="https://i.loli.net/2021/03/03/taQRuKN6ElJYbLg.png" alt="image-20210303205337060" style="zoom:33%;"></p><p>最后，我们来看看每个句子对应的图片集 $G$ 的大小 $m$, 和手动控制参数 $\lambda$ 的影响。下图分别是两个因素的影响结果。从图片数量来看，并不是越多的图片数量越好, 也不是越少越好,而是在 $m=5 \sim 15$ 的区间较好。这是因为， <strong>过少的图片信息不充分, 过多的图片噪声太多。</strong></p><p>参数$\lambda$控制的是图片信息融合的程度，可以看到，无论融合多少，效果都比不融合图片信息要好，这说明多模态是有效果的。</p><p>而且，手动控制它都没有模型自动学习好，这也说明模型对不同的输入句子，需要的视觉信息也是不同的。</p><p><img src="https://i.loli.net/2021/03/03/De8nVYPabyIrBwE.png" alt="image-20210303205616909" style="zoom:33%;"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h3><p>本文提出了一种简单、有效的多模态视觉知识融合方法——首先构建从主题词到图片的查询表，然后对输入句子找到相关的图片，然后使用ResNet提取图片信息融入到机器翻译模型中。</p><p>使用这种方法，可以避免对大规模双语-图片数据的依赖。实验结果也表明，这种方法可以一致地提高翻译效果。</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ul><li><p>如果要翻译单语-图片数据集中没有的语言，可以怎么做？</p><p>比如$S$没有日语，我们可以用一个日语的image caption模型去自动标注每个图片的描述。</p><p>或者可以用X-日语的机器翻译得到图片翻译后的描述；或者直接用一个现有的词典，把图片的主题词直接翻译成日语。其他方法亦可。</p></li><li><p>在融合步骤，是否可以有其他的方法进行融合？</p><p>另外一个简单的方法是，把ResNet得到的图片表示和句子一起，送入Encoder，再像往常一样解码。</p></li><li><p><strong>你认为本文这种方法从逻辑上是否真的有效？为什么？</strong></p><p>见仁见智，笔者倾向于有效，但是作用不大，因为只从模型的角度难以验证图片和文本之间语义的相关性，至于效果的提升，有可能是ResNet和Aggregate的共同结果。</p><p>笔者认为，可以考虑加一个图片预测描述的任务，和翻译一起学习；再将ResNet替换为普通的CNN进行实验。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;为了降低Multi-modal NMT对有图像标注的翻译数据集的依赖，本文提出通过建立Topic-image Lookup Table的方式
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="image-guided MT" scheme="http://yoursite.com/categories/cross-modal/image-guided-MT/"/>
    
    
      <category term="cross-modal,image-guided MT" scheme="http://yoursite.com/tags/cross-modal-image-guided-MT/"/>
    
  </entry>
  
  <entry>
    <title>[MultiSubs] A Large-scale Multimodal and Multilingual Dataset</title>
    <link href="http://yoursite.com/2021/03/03/MultiSubs-A-Large-scale-Multimodal-and-Multilingual-Dataset/"/>
    <id>http://yoursite.com/2021/03/03/MultiSubs-A-Large-scale-Multimodal-and-Multilingual-Dataset/</id>
    <published>2021-03-03T07:44:10.000Z</published>
    <updated>2021-03-04T02:52:19.884Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="目前存在的问题"><a href="#目前存在的问题" class="headerlink" title="目前存在的问题"></a>目前存在的问题</h3><p>使用视觉信息对 language grounding 的计算模型的研究导致了许多有趣的应用，例如图像字幕，视觉问答和视觉对话。各种各样的多模态数据集（由图片和文本组成）被构建，并且用于不同的应用。大部分数据集，图像被标注了文本标签，但是没有提供应用文本或图像的上下文。</p><p>在 image captioning dataset 中，为每张图片标注了 sentence-level text。虽然这些句子为图片提供了strong concept，但是存在一个基本的缺点：每个 sentence-level text 将 image 看做一个整体，但是实际上，text 中的内容仅仅包含了image中的部分元素。这将使得很难学到视觉和文本中的元素的对应（correspondences between elements）。图像和文本之间的连接是多样的。比如，很难用单个句子描述整个图像或用单个图像说明整个句子。因此，为了了解单词和图像之间更好的基础（grounding），需要在图像和文本段之间建立<strong>更紧密的局部对应关系</strong>。</p><p>此外，文本仅限于非常特定的领域（图像描述），而图像也仅限于极少数和非常特定的对象类别或人类活动；这使得很难概括可能的现实世界场景的多样性。</p><h3 id="本文的解决办法"><a href="#本文的解决办法" class="headerlink" title="本文的解决办法"></a>本文的解决办法</h3><p>在本文中，提出了一个新的大规模 多模态和多语言的数据集 (MultiSubs)，可以促进 <strong style="color:red;"><strong>grounding words to images</strong> </strong>in the context of their corresponding sentences。如下图1。</p><p><img src="https://i.loli.net/2021/03/03/PCQZBX2DtnaFzAu.png" alt="image-20210303162030516" style="zoom: 33%;"></p><p>与以前的数据集相比，我们的基础单词不仅针对图像，而且还针对其在语言中的上下文用法，从而有可能对现实世界中的人类语言学习产生更深刻的见解。具体来说：（1）MultiSubs中的文本片段和图像具有更紧密的局部对应，便于学习文本片段及其对应的视觉表示之间的关联；（2）与图像字幕数据集相比，图像更通用，范围更广，并且不受特定域的限制；（3）每个给定的文本片段和句子都可以有多个图像；（4）文字包含类似于自由形式的真实世界文字的grammar ot syntax；（5）文本是多语言的，而不仅仅是单语言或双语的。</p><p>从电影字幕的平行语料库开始，我们提出了一种<strong>跨语言多模态消歧方法</strong>，通过利用并行多语言文本来消歧文本中单词的含义，来说明文本片段。如图2所示。</p><p><img src="https://i.loli.net/2021/03/03/wBsAvKgbT2LSk16.png" alt="image-20210303163357136"></p><p>据我们所知，目前尚未对在文本插图的上下文中对此进行探讨。我们还通过人工判断来评估数据集和 illustrated text fragments 的质量。</p><p>使用本文提出的MultiSubs 数据集，本文提出了两个不同的多模态任务：（1）A fill-inn-the-blank task：to guess a missing word from a sentence, with or without image(s) of the word as clues。（2）Lexical translation：在给定 source sentence 和与该source word 相关联的零个或多个图像的情况下，我们将带有句子上下文的 source word 翻译为外语中的target word。</p><h2 id="语料库和文本片段选择"><a href="#语料库和文本片段选择" class="headerlink" title="语料库和文本片段选择"></a>语料库和文本片段选择</h2><p><em>MultiSubs</em>基于OpenSubtitles 2016（OPUS）语料库，该语料库是从 OpenSubtitles 中获得的，涵盖了65种语言的movie subtitles。</p><blockquote><p>OpenSubtitles2016: Extracting large parallel corpora from movie and TV subtitles.</p><p>OpenSubtitles: Subtitles - download movie and TV Series subtitles. <a href="http://www.opensubtitles.org/" target="_blank" rel="noopener">http://www.opensubtitles.org/</a></p></blockquote><p>本文挑选了5类电影：冒险，动画，喜剧，纪录片和家庭。大多数 subtitles 是对话性的（对话）或叙事性的（故事叙事或纪录片）。进一步将字幕过滤为仅在OPUS中与来自语料库的前30种非英语语言中的至少一种字幕对接的英语字幕的子集。这样一来，总共有45,482个电影实例<em>≈</em>38M个英语句子。对于前30种语言，电影的数量从2,354到31,168不等。</p><p>我们的目标是选择可能“在视觉上可描绘”的文本片段，并因此可以用图像进行说明。我们首先将英语字幕通过spacy  POS （en_core_web_md）来提取名词，动词，复合名词和简单形容词名词短语。这些 text frgments 的图像可成像性评分是通过MRC心理语言学数据库PaetzoldSpecia：2016通过引导获得的 ; 对于多词短语，我们将每个单词的图像可比性得分平均，为每个未见单词分配零得分。我们 retain text fragments 的可成像性得分至少为500，这是通过人工检查单词的子集来确定的。删除掉仅出现一次的 text fragments 后，输出为一组144,168个唯一候选片段（超过1600万个实例）<em>≈</em>1100万个句子。</p><h2 id="Illustration-of-text-fragments"><a href="#Illustration-of-text-fragments" class="headerlink" title="Illustration of text fragments"></a>Illustration of text fragments</h2><h3 id="Cross-lingual-sense-disambiguation"><a href="#Cross-lingual-sense-disambiguation" class="headerlink" title="Cross-lingual sense disambiguation"></a>Cross-lingual sense disambiguation</h3><p>本文提出的text illustration approach 的关键直觉是：一个带有歧义的英语句子，在另外一种语言的parallel sentence 中 可能没有歧义。</p><p>【1】<strong>Cross-lingual word alignment</strong> </p><p>在选择正确的图像 to illustrate our candidate text fragments (nouns) 时，我们尝试了多达四种<em>目标</em>语言：<strong>西班牙语</strong>（<strong>ES</strong>）和<strong>巴西葡萄牙语</strong>（<strong>PT</strong>），以及<strong>法文</strong>（<strong>FR</strong>）和<strong>德文</strong>（<strong>DE</strong>）。对于每种语言，选择字幕，以使（i）每个字幕都与英语字幕对齐；（ii）每个都至少包含一个感兴趣的名词。对于英语和每个目标语言，我们在全组平行句（不管句子中是否含有候选片段）中训练 <strong><em>fast_align</em></strong> DyerEtAl：2013，以获得在两种语言中词与词之间的对齐 。<strong>这将生成一个字典，该字典将英语名词映射到目标语言中的单词。</strong>我们对此字典进行过滤，以删除不常见的目标短语（语料库的1％以下）对。我们还将目标语言中具有相同lemmas 的单词归为一组。</p><p>【2】<strong>Sense disambiguation</strong></p><p>source -&gt; target </p><p>将名词翻译成不同的词(in the target language) 并不一定意味着它是模棱两可的。target phrases 可以简单地是指代相同概念的同义词。因此，我们进一步尝试在target side 对同义词进行分组，同时还通过查看跨多语言语料库的对齐短语来确定正确的词义。</p><p>对于 word senses，我们使用<strong>BabelNet</strong> NavigliPonzetto：2012，这是一个大型语义网络和涵盖多种语言的多语言百科全书，并统一了其他语义网络。</p><p>为了帮助我们确定给定上下文中英语名词的正确含义，我们使用目标语言中平行句子中的对齐词来消除歧义。我们计算两个查询返回的BabelNet同义词集ID之间的交集。比如 bank(english) -&gt; banco(spanish) ，如果使用英语bank 来查询将得到 financial-bank 和river-bank，如果用西班牙语banco查询将得到 financial-bank。取这两个查询结果的交集。</p><p>如果仅针对一种语言对执行上述操作，则该目标语言可能不足以消除英语术语的歧义，因为该术语在两种语言中可能是歧义的。对于紧密相关的语言（例如葡萄牙语和西班牙语）尤其如此。因此，<strong>我们建议利用<em>多种</em>目标语言，以进一步提高我们消除英语单词歧义的信心</strong>。我们的假设是，更多的语言最终将允许识别单词的正确上下文。</p><p>更具体地说，我们研究了包含<strong>多达四种目标语言</strong>的并行句子的字幕。对于每个英语短语，我们保留所有实例之间的同义词集ID之间<strong>至少有一个交集的实例</strong></p><p>【3】<strong>Image Selection</strong></p><p>构造<em>MultiSubs</em>的最后一步是为每个歧义的英语术语分配至少一个图像，and by design the term in the aligned target language(s)。由于BabelNet通常为给定的同义词集ID提供多个图像，因此我们用与该同义词集关联的所有Creative Commons images 说明该term。</p><h2 id="Human-evaluation"><a href="#Human-evaluation" class="headerlink" title="Human evaluation"></a>Human evaluation</h2><p>为了定量评估我们的automated cross-lingual sense disambiguation cleaning procedure，我们收集了人类注释，<strong>以确定<em>MultiSubs</em>中的图像是否确实对预测填空任务中的遗漏单词有用</strong>。<strong>注释还可以作为任务的人工上限</strong></p><p>我们将注释任务设置为<em>The Gap Filling Game</em>（图 <a href="https://www.arxiv-vanity.com/papers/2103.01910/#S5.F5" target="_blank" rel="noopener">5</a>）。在此游戏中，用户尝试进行<strong>三种尝试来猜测从<em>MultiSubs</em>的句子中删除的确切单词</strong>。在<strong>第一次尝试</strong>中，游戏仅显示句子（以及遗漏单词的空白）。在<strong>第二次尝试</strong>中，游戏还会为丢失的单词提供一个图像作为线索。在第三次也是<strong>最后一次尝试</strong>中，系统将显示与缺失单词关联的所有图像。在每次尝试中，如果用户输入的单词与原始单词完全匹配，则用户将获得1.0分；否则，将按预先训练的CBOW word2vec MikolovEtAl：2013之间的余弦相似度计算得出的部分分值（介于0.0和1.0之间） 预测词和原始词的嵌入。当用户输入完全匹配的内容时，或者在用尽所有三个尝试之后（以先发生者为准），每个“转”（一个句子）都会结束。第二次和第三次尝试的得分乘以<em>惩罚因子</em>（分别为0.90和0.80），以鼓励用户尽早正确猜出该单词。用户单回合的得分是所有三个尝试中的最高分，每个用户的最终累积得分是所有带注释的句子中分的总和。该最终分数确定了游戏结束时（在预定的截止日期之后）的获胜者和亚军，他们两人都分别获得了亚马逊代金券。在游戏过程中，不会为用户提供确切的“当前最高得分”表，而是会为他们提供比其当前得分更低的所有得分的所有用户所占的百分比</p><h3 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h3><p>visual grounding of words</p><p>language grounding</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;h3 id=&quot;目前存在的问题&quot;&gt;&lt;a href=&quot;#目前存在的问
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
    
      <category term="cross-modal" scheme="http://yoursite.com/tags/cross-modal/"/>
    
  </entry>
  
  <entry>
    <title>[The GEM Benchmark] Natural Language Generation, its Evaluation and Metrics</title>
    <link href="http://yoursite.com/2021/03/01/The-GEM-Benchmark-Natural-Language-Generation-its-Evaluation-and-Metrics/"/>
    <id>http://yoursite.com/2021/03/01/The-GEM-Benchmark-Natural-Language-Generation-its-Evaluation-and-Metrics/</id>
    <published>2021-03-01T11:10:46.000Z</published>
    <updated>2021-03-01T11:22:29.397Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Just can be seen by yaya.
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Multimodal Transformer for Multimodal Machine Translation</title>
    <link href="http://yoursite.com/2021/02/26/Multimodal-Transformer-for-Multimodal-Machine-Translation/"/>
    <id>http://yoursite.com/2021/02/26/Multimodal-Transformer-for-Multimodal-Machine-Translation/</id>
    <published>2021-02-26T09:24:51.000Z</published>
    <updated>2021-02-26T09:25:47.986Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>多模态机器翻译任务，是从其他模态中引入信息（一般是静态的图像）来提高翻译质量。先前的方法没有考虑多个模态的相对重要性，它们常常平等对待文本和图像信息，并分别编码，但是这种方式，将会导致从图像中<strong>引入许多无关的信息</strong>。</p><p>在本文中，提出了一个multi-modal self-attention in Transformer 来解决上述的问题。本文提出的方法能够based on text to encode vision, 从而避免了编码图像中与文本无关的信息。</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><ul><li>The focus of our work is to build a powerful encoder to incorporate the information from other modality.</li></ul><p><img src="https://i.loli.net/2021/02/26/4AnNwV85DpBkqZm.png" alt="image-20210226172540508" style="zoom:50%;"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h1&gt;&lt;p&gt;多模态机器翻译任务，是从其他模态中引入信息（一般是静态的图像）来提高翻译质量
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="image-guided MT" scheme="http://yoursite.com/categories/cross-modal/image-guided-MT/"/>
    
    
      <category term="cross-modal,image-guided MT" scheme="http://yoursite.com/tags/cross-modal-image-guided-MT/"/>
    
  </entry>
  
  <entry>
    <title>A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation</title>
    <link href="http://yoursite.com/2021/02/26/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation/"/>
    <id>http://yoursite.com/2021/02/26/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation/</id>
    <published>2021-02-26T09:21:24.000Z</published>
    <updated>2021-02-26T09:24:02.504Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li>当前主流的multi-modal NMT models 不能充分利用不同模态语义单元之间的<strong>细粒度的语义对应。</strong></li><li>在本文中，提出了一个新颖的graph-based  cross-modal fusion encoder 来处理NMT task。具体地，（1）首先使用一个 unified multi-modal graph来编码input sentence and image。这种方式可以捕获到多模态语义单元（words and visual objects）之间各种语义关系。（2）使用多个 graph-based multi-modal fusion layers 来迭代的执行语义交互，以学习node representations。（3）以上获得的contextual representations 送入decoder中。</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>该任务的重要性，有很多现实的应用：包括翻译多媒体新闻，Web产品信息和电影字幕。</p><blockquote><p>A visual attention grounding neural model for multimodal machine translation.</p></blockquote></li><li><p>该任务对于提高机器翻译的准确性有作用：视觉环境有助于解决歧义的多义词。</p><blockquote><p>Distilling translations with visual awareness.</p></blockquote></li></ul><p>很显然，再在 multi-modal NMT 中，如何有效的利用视觉信息是一个核心的问题。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p><img src="https://i.loli.net/2021/02/26/7IOXHm89QM5DNq4.png" alt="Untitled"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul><li><p>Multi-modal Graph</p><p><img src="https://i.loli.net/2021/02/26/w1vmXMebCR3Kt5y.png" alt="Untitled3"></p><ul><li><p>所有的单词都作为 textual nodes。使用Stanford parser来找到文本中的所有名词，然后使用 visual grounding tookit来检测 bbox，并作为visual nodes。</p><blockquote><p>visual grounding tookit: <strong>A fast and accurate one-stage approach to visual grounding</strong></p></blockquote></li><li><p>在 multi-modal graph中使用了两种类型的edges。<strong>intra-modal edge(fully-connected)</strong> and <strong>inter-modal edge(partly-connected)</strong></p></li></ul></li><li><p>Embedding Layer</p><ul><li>Before inputting the multi-modal graph into the stacked fusion layers，首先获得其初始特征。</li><li>对于textual modes， 使用word embedding 和 position embedding 的求和。</li><li>对于visual nodes，使用Faster-RCNN提取 roi pooling layer 的特征，然后使用MLP + RELU 将视觉特征映射到与文本特征相同的空间。</li></ul></li><li><p>Graph-based Multi-modal Fusion Layers</p><ul><li>On the top of embedding layer, stack multiple graph-based multimodal fusion layers to encode the above-mentioned multi-modal graph.</li><li>在每个融合层，序列地实施模态内和模态间的融合，来更新所有的节点状态。这种方式，可以使得最终的节点状态能够同时编码到相同模态和跨模态的语义信息。</li><li>由于视觉节点和文本节点是包含了不同模态信息的两种语义单元。因此，使用相同的操作，但是不同的参数（不共享）来更新它们的节点状态。</li></ul></li></ul><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><ul><li><p>Our decoder is similar to the conventional Transformer decoder。堆叠多个相同的层来生成 target-side hidden states，每一层由三个子层组成。</p><p>前两个子层是一个masked self-attention 和 一个encoder-decoder attention 来分别聚合target-side and source-side contexts。</p><p>最后由a position-wise fully-connected forward neural network 和 线性变化来生成next-step predict word。</p></li></ul><h2 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h2><ul><li>与本文类似的模型结构有以下两篇</li></ul><blockquote><p>Multi-Modality Cross Attention Network for Image and Sentence Matching</p><p>(LXMERT) LXMERT Learning Cross-Modality Encoder Representations from Transformers</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;当前主流的multi-modal NMT models 不能充分利用不同模态语义
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="image-guided MT" scheme="http://yoursite.com/categories/cross-modal/image-guided-MT/"/>
    
    
      <category term="cross-modal,image-guided MT" scheme="http://yoursite.com/tags/cross-modal-image-guided-MT/"/>
    
  </entry>
  
  <entry>
    <title>The Style-Content Duality of Attractiveness: Learning to Write Eye-Catching Headlines via Disentanglement</title>
    <link href="http://yoursite.com/2021/02/26/The-Style-Content-Duality-of-Attractiveness-Learning-to-Write-Eye-Catching-Headlines-via-Disentanglement/"/>
    <id>http://yoursite.com/2021/02/26/The-Style-Content-Duality-of-Attractiveness-Learning-to-Write-Eye-Catching-Headlines-via-Disentanglement/</id>
    <published>2021-02-26T01:46:15.000Z</published>
    <updated>2021-03-01T11:19:42.763Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2021/02/26/9xToFaqiXjyKLOU.png" alt="image-20210226094912200" style="zoom: 50%;"></p><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>抢眼的头条新闻是触发更多点击的第一个设备，在制作人和观众之间产生了相互影响。生产者可以获得更多的流量和利润，而读者可以访问优秀的文章。生成吸引人的头条新闻时，不仅要捕捉吸引人的<strong>内容</strong>，而且要遵循醒目的书面<strong>风格</strong>。</p><p>本文中，提出了一个a Disentanglement-based Attractive Headline Generator (DAHG)。该标题生成器根据有吸引力的样式来捕获有吸引力的内容的标题。具体而言，【1】我们首先设计一个解纠缠模块，将引人注目的原型标题的样式和内容划分为潜在空间，并带有两个辅助约束以确保两个空间确实被纠缠。【2】然后，潜在内容信息将用于进一步polish the document representation 并帮助捕获重要部分。【3】最后，生成器将 polished document 作为输入，以在引人注目的样式的指导下生成标题。</p><p>本文在Kuaibao dataset 上实现了最好的性能。人工评估还表明，与现有模型相比，DAHG触发的点击次数增加了22％。</p><h3 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h3><h4 id="Headline-Generation"><a href="#Headline-Generation" class="headerlink" title="Headline Generation"></a>Headline Generation</h4><p>头条生成目前是NLP中的一个研究热点，目前大部分存在的头条生成工作仅仅关注于 summarizing the document。目前在Attractive headline generation上的研究还相对较少，目前有以下几篇。据我们所知，目前没有工作considers the style-content duality of attractiveness（考虑  吸引力的 内容-风格 二重性）。</p><blockquote><p>【1】Clickbait? Sensational Headline Generation with Auto-tuned Reinforcement Learning</p><p>【2】Improving Latent Alignment in Text Summarization by Generalizing the Pointer Generator. EMNLP 2019</p><p>【3】Structure Learning for Headline Generation.</p><p>【4-（not）】Hooks in the Headline: Learning to Generate Headlines with Controlled Styles</p></blockquote><h4 id="Disentanglement"><a href="#Disentanglement" class="headerlink" title="Disentanglement."></a>Disentanglement.</h4><p>现有作品集中于学习learning the disentangled representation，并且我们进一步采取了这种方法来利用这种representation来生成attractive headlines。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/02/26/9xToFaqiXjyKLOU.png&quot; alt=&quot;image-20210226094912200&quot; style=&quot;zoom: 50%;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Abstract&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="title" scheme="http://yoursite.com/categories/title/"/>
    
      <category term="style" scheme="http://yoursite.com/categories/title/style/"/>
    
    
      <category term="title,style" scheme="http://yoursite.com/tags/title-style/"/>
    
  </entry>
  
  <entry>
    <title>[DeepFuse] HKU’s Multimodal Machine Translation System for VMT’20</title>
    <link href="http://yoursite.com/2021/02/26/DeepFuse-HKU%E2%80%99s-Multimodal-Machine-Translation-System-for-VMT%E2%80%9920/"/>
    <id>http://yoursite.com/2021/02/26/DeepFuse-HKU’s-Multimodal-Machine-Translation-System-for-VMT’20/</id>
    <published>2021-02-26T01:15:34.000Z</published>
    <updated>2021-02-26T09:16:26.077Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2021/02/26/bTNP7oqc3nxXfMV.png" alt="image-20210226154022062" style="zoom:50%;"></p><p>VATEX： video-guided machine translation(EN-&gt;CH) Challenge</p><p>ACL 2020 workshop <a href="https://alvr-workshop.github.io/2020/index.html" target="_blank" rel="noopener">https://alvr-workshop.github.io/2020/index.html</a></p><h3 id="以前方法存在的问题"><a href="#以前方法存在的问题" class="headerlink" title="以前方法存在的问题"></a>以前方法存在的问题</h3><p>以前的image-guied Machine Translations, 在encode 阶段，往往单独对 视觉信息和语言信息进行编码。然后，在decode 阶段使用attention将视觉信息结合进来。模态之间的信息仅仅进行了浅融合。</p><h3 id="本文提出的方案"><a href="#本文提出的方案" class="headerlink" title="本文提出的方案"></a>本文提出的方案</h3><p>本文中，提出了一个 video-augmented encoder，以此，获得一个multi-modal representation 来作为decoder的输入。使用attention 机器在多个层融合了多模态的表征。</p><p>实验证明，这种深融合方法相比于之前的浅融合方法要更加的有效。</p><h3 id="具体方法"><a href="#具体方法" class="headerlink" title="具体方法"></a>具体方法</h3><p><img src="https://i.loli.net/2021/02/26/7qgti5pwnDkcWNZ.png" alt="image-20210226160753355" style="zoom:50%;"></p><p>本文提出的visual-augmented encoder 如图1所示，encoder 包括L=6层相同的层。</p><p>将sentence表征为一个embedding的输入序列： $\mathbf{X}=x_{1}, x_{2}, \ldots, x_{n}$</p><p>将 video 使用I3D提取clips的特征，表征为segment-level feature 的序列：$\mathbf{E}=e_{1}, e_{2}, \ldots, e_{m}$</p><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><p>The encoder process the input X and E as follows:</p><p>【1】input X 输入<strong>Multi-Head attention and Feed Forward</strong> 这两个sub layers， 得到 $H^L$</p><p>【2】在video-encoder attention module, 使用$H^L$ 作为 query 来选择与query 相关的 video representation。 </p><p>$\overline{\mathcal{H}}=$ Attention $\left(\mathbf{H}^{L}, \mathbf{K}_{E}, \mathbf{V}_{E}\right)$</p><p>【3】使用权重求和来得到多模态特征：</p><p>$\mathcal{H}=\mathbf{H}^{L}+\lambda \overline{\mathcal{H}}$， where，$\lambda=\operatorname{sigmoid}\left(\mathbf{W}_{\lambda} \overline{\mathcal{H}}+\mathbf{U}_{\lambda} \mathbf{H}^{L}\right)$</p><p>【4】最后的输出是：$\operatorname{LayerNorm}\left(\mathbf{H}^{L}+\mathcal{H}\right)$</p><p>【yaya】最后一步，似乎是有问题，因为，这样多模态特征，似乎就是加了两遍 $H^L$</p><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>遵循transformer 中 decoder的设计，存在L=6个相同的层。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><p>学习率的变化曲线：lrate $=d_{\text {model }}^{-0.5} \cdot \min \left(K^{-0.5}, K \cdot N^{-1.5}\right)$，where K is the current number of step and N=4000 is the number of warm-up steps.</p><h4 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h4><p>（1）<strong>lstm</strong>: Text-only LSTM-based encoderdecoder NMT </p><p>（2）<strong>vatex</strong>: The LSTM-based videoguided machine translation system proposed in VATEX<br>（3）<strong>Transformer</strong>: standard text-only transformer architecture proposed by “Attention is all you need.”</p><p><img src="https://i.loli.net/2021/02/26/ZD7SxmKUBMA3tIE.png" alt="image-20210226170500065" style="zoom:33%;"></p><ul><li>相比于text-only transformer 有一个显著的提高。证明了，使用深层融合来结合视觉信息的有效性。</li></ul><h3 id="收获与总结"><a href="#收获与总结" class="headerlink" title="收获与总结"></a>收获与总结</h3><ul><li><p>本文的关键是提出了使用transformer 的结构来融合文本和视觉信息。</p></li><li><p>在image-guided machine translation 任务中，也存在两篇使用co-attention 来融合两个模态信息的。如下：</p><blockquote><p>[1] (ACL 2020) Multimodal Transformer for Multimodal Machine Translation</p><p>[2] (ACL 2020) A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation 【Graph Fusion】</p></blockquote></li></ul><p>【Graph Fusion】与本文相比，encoder 的设计方式不同，但是decoder的设计是相同的。关于不同：【Graph Fusion】首先对两个模态各自self-attention 而后再根据graph edge 进行co-attention。而本文对视觉信息没有进行self-attention，仅对语言信息进行了self-attention, 在co-attention步骤中也没有显示的graph edge,而是采用了隐式的全连接。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/02/26/bTNP7oqc3nxXfMV.png&quot; alt=&quot;image-20210226154022062&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;p&gt;VATEX： video-guided 
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="video-guided MT" scheme="http://yoursite.com/categories/cross-modal/video-guided-MT/"/>
    
    
      <category term="cross-modal,video-guided MT" scheme="http://yoursite.com/tags/cross-modal-video-guided-MT/"/>
    
  </entry>
  
  <entry>
    <title>A Closer Look at the Robustness of Vision-and-Language Pre-trained Models</title>
    <link href="http://yoursite.com/2021/02/24/A-Closer-Look-at-the-Robustness-of-Vision-and-Language-Pre-trained-Models/"/>
    <id>http://yoursite.com/2021/02/24/A-Closer-Look-at-the-Robustness-of-Vision-and-Language-Pre-trained-Models/</id>
    <published>2021-02-24T02:12:45.000Z</published>
    <updated>2021-02-26T07:01:23.540Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>大规模的预训练多模态transformer将最新的视觉-语言任务推进到了一个新的高度。虽然在标准任务上实现了令人印象深刻的性能，但是，迄今为止，任然不清楚这些预训练模型的鲁棒性。</p><p>为了进行调查，我们针对现有的预训练模型对4种不同类型的V + L特定模型的鲁棒性进行了全面的评估：(i) Linguistic Variation; (ii) Logical Reasoning; (iii) Visual Content Manipulation; and (iv) Answer Distribution Shift. 有趣的是，by standard model finetuning，预训练的V+L模型相比于task-specific 模型展示出更好的鲁棒性。</p><p>为了<strong>进一步增强模型的鲁棒性</strong>，本文提出了<strong>MANGO</strong>，一个具有泛化性且鲁棒的方法，可以在embedding space 学习a Multimodal Adversarial Noise GeneratOr 以愚弄pre-trained V+L models。与以往针对一种特定类型的鲁棒性的研究不同，MANGO具有任务不可知性，并且可以针对各种任务（旨在评估鲁棒性的广泛方面）对预训练模型进行通用性能提升。</p><p> 全面的实验表明，MANGO在9个鲁棒性基准中有7个达到了最新水平，大大超过了现有方法。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>当前的 V+L pre-tranining model取得了很大的进展在各种 V+L tasks，但是这些benchmark 在测试集和数据集上的分布常常是相似的，textual query 几乎没有 linguistic variation, 使用干净的自然图像，而没有任何visual content manipulation。 因此，尽管这些标准基准对于通用模型评估有效，但仍<strong>缺乏明确评估模型鲁棒性的能力</strong>。（在本文中，我们不关注 adversarial robustness，<strong style="color:red;">因为目前没有可用的adversarial benchmark</strong>。因此，我们在已有的robustness benchmark上进行观测，这些benchmark 设有挑战性的设置，并且经过了人类的验证）</p><p>(i) VQA-Rephrasings[56] for <strong>linguistic variation</strong>;</p><p>(ii) VQA-LOL (Compose and Supplement) [18], VQA-Introspect [54] and GQA [25] for <strong>logical reasoning</strong>; </p><p>(iii) IV-VQA and CVVQA [2] for <strong>visual content manipulation</strong>;  </p><p>(iv) VQA-CP v2 [3] and GQA-OOD [31] for <strong>answer distribution shift</strong>.</p><h3 id="当前方法存在的问题"><a href="#当前方法存在的问题" class="headerlink" title="当前方法存在的问题"></a>当前方法存在的问题</h3><p>VILLA，在multimodal embedding 加入对抗扰动，<strong>projected gradient descent（PGD） attack training（AT）</strong> 可以在 linguistic variation and visual content manipulation 增强鲁棒性，但是在训练集和测试集之间有显著的数据分布差异时，会有收效甚微的影响甚至drop model performence。</p><h3 id="本文方法简介"><a href="#本文方法简介" class="headerlink" title="本文方法简介"></a>本文方法简介</h3><p>为了在所有方面都实现鲁棒性，本文提出了 MANGO，通过在multi-modal embedding space 引入adversarial noise来增强鲁棒性。</p><p><img src="https://i.loli.net/2021/02/24/yDSgc5JwWFHCU8h.png" alt="image-20210224120151245"></p><p>如图 figure 1a所示，不使用PGD来生成对抗扰动，而是使用一个基于可训练神经网络来学习一个adversarial noise generator。与 VILLA相同，在embedding space 加入扰动，因为本文的目标 是对抗训练的最终结果，而不是制造对抗样本。</p><p>【1】本文要学习的是一个 universial noise generator，但是在VILLA中使用的PGD方法是针对每个特定样本来生成的，本文提出的noise generator 是通用的，对输入训练样本是不加区别的。【2】而PGD的方法是<strong>耗时</strong>的，而本文提出的方法是轻量级的，不需要梯度计算中的重复迭代。同时，为了使能多样性的对抗embedding，本文进一步提出随机对image regions 和 textual tokens掩码。</p><h3 id="本文的贡献"><a href="#本文的贡献" class="headerlink" title="本文的贡献"></a>本文的贡献</h3><ul><li>第一个系统性的分析pre-trained V+L 模型的鲁棒性</li><li>提出了 MANGO，一个generic and efficient 对抗训练方法来增强 V+L model 鲁棒性</li><li>实验结果证明了本文提出方法的鲁棒性。</li></ul><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h4><p>Perturbing clean images with Gaussian noise. we use Gaussian noise augmentation as a simple baseline to investigate model robustness under V+L setting. Instead of adding noise to raw image pixels as in [52], we add perturbations directly to the embeddings.</p><h4 id="Adversarial-Noise-Generator-our"><a href="#Adversarial-Noise-Generator-our" class="headerlink" title="Adversarial Noise Generator (our)"></a><strong>Adversarial Noise Generator</strong> (our)</h4><p>Adding Gaussian noise to clean image-text pairs 可以补充训练样本。但是，随着训练的持续，模型可以逐渐的适应这种扰动，因为扰动都是从同一个 Gaussian noise distribution 中采样来的。</p><p>为了得到 harder perturbations，本文提出了一个可学习的 adversarial noise generator。对抗性噪声发生器将高斯噪声样本作为输入，通过可学习神经网络产生对抗性噪声样本。</p><p>Intuitively, to maximally fool the backbone network, 【1】we want to <strong>maximize prediction errors on these adversarially perturbed samples.</strong> 【2】In the meantime, we want the model to possess <strong>less confidence in its predictions on perturbed samples</strong> than clean samples, to promote harder adversarial examples。因此，<strong>adversarial noise generator 的目标是</strong>最大化这两个损失的求和：【1】task-speficic loss 【2】KL loss, which measures the distance between the predicted answer distribution of perturbed samples and that of clean samples.</p><p>另一方面，the trained model 旨在通过将对抗性生成的嵌入作为数据增强来最大程度地减少这两种损失。</p><p>综合上述两种方面，提出了如下的min-max game:</p><script type="math/tex; mode=display">\min _{\boldsymbol{\theta}} \max _{\boldsymbol{\phi}_{v}(\boldsymbol{v}, \boldsymbol{w}, \boldsymbol{y}) \sim \mathcal{D} \boldsymbol{\alpha} \in \mathcal{N}(\mathbf{0}, \mathbf{1})} \mathbb{E}\left[\mathcal{L}_{s t d}\left(\boldsymbol{\theta}, \boldsymbol{\phi}_{v}\right)+\beta \mathcal{R}_{k l}\left(\boldsymbol{\theta}, \boldsymbol{\phi}_{v}\right)\right]</script><p>where $\beta$ is a hyper-parameter, and</p><script type="math/tex; mode=display">\begin{array}{l}\mathcal{L}_{s t d}\left(\boldsymbol{\theta}, \boldsymbol{\phi}_{v}\right)=\mathcal{L}_{\mathrm{BCE}}\left(f_{\boldsymbol{\theta}}\left(\boldsymbol{v}+g_{\boldsymbol{\phi}_{v}}(\boldsymbol{\alpha}), \boldsymbol{w}\right), \boldsymbol{y}\right) \\\mathcal{R}_{k l}\left(\boldsymbol{\theta}, \boldsymbol{\phi}_{v}\right)=\mathcal{L}_{k l}\left(f_{\boldsymbol{\theta}}\left(\boldsymbol{v}+g_{\phi_{v}}(\boldsymbol{\alpha}), \boldsymbol{w}\right), f_{\boldsymbol{\theta}}(\boldsymbol{v}, \boldsymbol{w})\right)\end{array}</script><p>在训练时，迭代跟新 an outer loop of the backbone network and an inner loop of noise generator.</p><p>本文提出的adversarial noise generator 是轻量级的，仅仅存在 a few linear layers。相比于一个深层模型，这种轻量模型更容易陷入局部最优。因此，定期地，we replace the learned noise generator with a new one trained from scratch。每次，new  generator is trained against the latese learned parameters of the backbone.</p><h4 id="Random-Masking"><a href="#Random-Masking" class="headerlink" title="Random Masking"></a>Random Masking</h4><p>虽然 adversarial noise generator 可以产生具有挑战性，更加多样化的噪声扰动，但是不会改变训练样本的内在统计（例如，问题长度和image regions的分布）。然而，实际上，在robustness benchmark 的训练和测试集中存在这种 significant mismatch。比如，the average length of questions in VQA-LOL 测试集是VQA V2 训练集的 2-3倍。</p><p>为了补偿这种统计上的不匹配，我们建议在向图像和单词嵌入中添加对抗性噪声时，<strong>随机掩盖图像区域</strong> and <strong>随机插入[MASK]令牌</strong>。</p><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>进行实验分析了 pre-trained V+L model 的鲁棒性和 本文提出的MANGO framework 的有效性。本文使用UNITER作为 backbone，并将 MANGO与 UNITER和 VILLA 在9个 robustness datasets + VQA v2 dataset上进行了比较。本文在这10个 benchmark上进行研究，<strong style="color:red;"><strong>因为目前在其他任务上没有这种 robustness dataset。</strong></strong></p><p>VILLA 在预训练阶段和微调阶段都采用了 对抗训练，而本文只是在微调阶段（即针对特定任务）</p><p><img src="https://i.loli.net/2021/02/25/HwjDn2voZfWKFOk.png" alt="image-20210225095811994"></p><h3 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h3><p>investigate the adversarial robustness of pre-trained V+L models.</p><p>（在本文中，我们不关注 adversarial robustness，<strong style="color:red;">因为目前没有可用的adversarial benchmark</strong>。因此，我们在已有的robustness benchmark上进行观测，这些benchmark 设有挑战性的设置，并且经过了人类的验证）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;大规模的预训练多模态transformer将最新的视觉-语言任务推进到了一个新的高度。虽然在
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
      <category term="对抗" scheme="http://yoursite.com/categories/cross-modal/%E5%AF%B9%E6%8A%97/"/>
    
    
      <category term="cross-modal,对抗" scheme="http://yoursite.com/tags/cross-modal-%E5%AF%B9%E6%8A%97/"/>
    
  </entry>
  
  <entry>
    <title>UNIMO Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning</title>
    <link href="http://yoursite.com/2021/02/23/UNIMO-Towards-Unified-Modal-Understanding-and-Generation-via-Cross-Modal-Contrastive-Learning/"/>
    <id>http://yoursite.com/2021/02/23/UNIMO-Towards-Unified-Modal-Understanding-and-Generation-via-Cross-Modal-Contrastive-Learning/</id>
    <published>2021-02-23T03:27:15.000Z</published>
    <updated>2021-02-23T12:00:49.165Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Welcome to my blog, enter password to read." />    <label for="pass">Welcome to my blog, enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Just can be seen by yaya.
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
    
      <category term="cross-modal" scheme="http://yoursite.com/tags/cross-modal/"/>
    
  </entry>
  
  <entry>
    <title>VX2TEXT End-to-End Learning of Video-Based Text Generation From Multimodal Inputs</title>
    <link href="http://yoursite.com/2021/02/23/VX2TEXT-End-to-End-Learning-of-Video-Based-Text-Generation-From-Multimodal-Inputs/"/>
    <id>http://yoursite.com/2021/02/23/VX2TEXT-End-to-End-Learning-of-Video-Based-Text-Generation-From-Multimodal-Inputs/</id>
    <published>2021-02-23T02:49:31.000Z</published>
    <updated>2021-03-15T01:55:51.948Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li>本文提出了一个框架 for text generation from multimodal inputs consisting of video plus text, speech, or audio。</li><li><p>为了利用 transformer networks，每个模态通过一个 learnable tokenzier 首先转换为 a set of language embeddinngs。这将使得我们的方法可以在语言空间执行多模态融合，从而消除了对ad-hoc cross-modal fusion modules 的需要。</p></li><li><p>为了解决在连续输入（例如视频或音频）上tokenization 的不可微性，我们利用了一种放松方案，该方案可进行端到端训练。</p></li><li><p>进一步地，不像先前的 encoder-only models。本文提出的网络包括一个 autoregressive decoder来生成 open-ended text。同时在语言空间执行多模态融合，这使我们的方法完全具有生成性，并使其<strong>直接适用于不同的“video + $x $ to text” 问题，而无需为每个任务设计专门的网络.</strong></p></li><li><p>本文提出的框架不仅概念简单，而且效果显着。实验结果证明，our approach based on a single architecture 在三个video basedd text-generation task （captioning, question answering and audio-visual scene-aware dialog）上实现了最好的性能，而且本文提出的方法不需要任何的预训练任务。</p></li></ul><h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>While this and a few other recent works [55] have leveraged decoders for text-generation from multimodal inputs, we believe <strong>we are the first</strong> to empirically demonstrate via systematic ablation the performance improvements achieved with generative learning with decoding, compared to discriminative learning applied to the same encoder model.</p><p>当前的multimodal transformer-based models inspired by the success of pretext tasks in the language domain（预训练任务）。这些工作，依赖消耗大的预训练任务。但是本文提出的VX2TEXT 可以在 unified language space 执行 跨模态融合，这不需要multimodal pretext pretraining.</p><blockquote><p>Hero: Hierarchical encoder for video language omni-representation pre-training</p><p>Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks.</p><p>Videobert: A joint model for video and language representation learning, 2019.</p><p>Lxmert: Learning crossmodality encoder representations from transformers.</p><p>Unified vision-language pre-training for image captioning and vqa</p></blockquote><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>本文提出的方法可以概括为三步: (1) 利用一个 预训练的 modality-specific classifiers来为每个模态获得最可能的类别预测。(2) 将预测类别的textual names 经由本文提出的可微分tokenization scheme 嵌入到一个语义语言空间，这将使得整个系统可以端到端的训练（including the modality-specific classifiers)。（3）最终，使用一个generative encoder-decoder language model 将 多个模态的，embedding vector 映射到 free-form text，这将使得 不同形式的 ”video+$x$ to text” 问题变形为一个 sequence-to-sequence task。</p><h4 id="Differentiable-Tokenization"><a href="#Differentiable-Tokenization" class="headerlink" title="Differentiable Tokenization"></a>Differentiable Tokenization</h4><ul><li>We first leverage modality-specific classifiers trained  to predict a large set of categories over <strong>predefined language vocabularies</strong>.</li><li>虽然概念上是简单的，但是这个方法有一些缺点。第一，预训练的 modality-specific classifiers 可能不能泛化到目标数据。第二，每个分类器中选择top categories，这一操作是不可微分的，这阻止我们针对 target task 来微调modality-specific classifiers。</li><li>为了解决这些限制，本文提出了一个 differentiable tokenization scheme，这个方案可以在整个系统（modality specific classifer + sequence-to-sequence model）上进行端到端的训练。</li><li><strong>将预测类别的textual names 嵌入到一个语义语言空间</strong>：（1）对于每个模态的类别概率输出，采样top $K_m$个类别。（2）将采样的类别名称嵌入到语言空间：$\mathbf{e}_{m}^{k}=\mathbf{W}_{m}^{T} \mathbf{c}_{m}^{k}$，the embedding transformation  $\mathbf{W}_{m}$ can be initialized using a pretrained language embedding space </li></ul><h3 id="Generative-Encoder-Decoder"><a href="#Generative-Encoder-Decoder" class="headerlink" title="Generative Encoder-Decoder"></a>Generative Encoder-Decoder</h3><p>上一阶段，将不同的模态嵌入到了一个相同的语言空间，因此，现在可以使用一个<strong>text encoder</strong>来融合多模态信息。将多个模态得到的embedding vectors 组成一个长为L的序列，并结合<strong>task token</strong> 输入到 <strong>text encoder</strong>，并生成一个长为L的序列，该序列从多个模态中捕捉到了task  specific information。</p><p>将得到的新序列送入 decoder 中来做text generation。本文提出的decoder使用auto-regressive的方式。</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ul><li>使用 teacher-forcing 和 cross-entropy 来训练模型</li></ul><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><ul><li>大部分先前的 multimodal transformer 依赖 task-specific heads 来处理不同的任务。具体而言，为生成式任务设计的heads 通常与 判别式任务是不同的。但是，本文提出的VX2TEXT 可以同时处理这两种任务，而不需要改变结构</li><li>对于生成式任务，captioning and video dialog，使用 beam search and greedy decoding 来生成句子。</li><li>对于判别式任务，QA on TVQA，模型需要从候选答案中挑选出一个最可能的答案。在这种情况下，本文include the entire set of candidate answers as additional input to the model (using separator tokens to mark them)。然后评估每个候选答案，根据autoregressive decoder对它们输出的概率分布。</li></ul><h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><p>We use T5-base [39] as our text transformer including the text token embedding layer, the encoder and the decoder. We use pretrained weights provided in HuggingFace [50]</p><h3 id="yaya"><a href="#yaya" class="headerlink" title="yaya"></a>yaya</h3><ul><li>简要总结本文有效的点</li><li>（1）提出将不同的模态，通过一个modality-specific classifier 映射到语言空间。（2）提出了一个端到端训练的模式，同时可以将 classifier 一起训练，这样解决了 迁移，泛化性不好的问题。（3）为了可以进行端到端的训练，采取了一些技术方案。we leverage the Gumbel-Softmax trick [18] and a differentiable approximation of tokenization [8].</li></ul><blockquote><p>Eric Jang, Shixiang Gu, and Ben Poole. <strong>Categorical reparameterization with gumbel-softmax.</strong>  arXiv preprint arXiv:1611.01144, 2016. <strong>ICLR 2017</strong></p><p>Yoshua Bengio, Nicholas L´eonard, and Aaron Courville. <strong>Estimating or propagating gradients through stochastic neurons for conditional computation.</strong> arXiv preprint arXiv:1308.3432, 2013.</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;本文提出了一个框架 for text generation from multi
      
    
    </summary>
    
      <category term="cross-modal" scheme="http://yoursite.com/categories/cross-modal/"/>
    
    
      <category term="cross-modal" scheme="http://yoursite.com/tags/cross-modal/"/>
    
  </entry>
  
</feed>
